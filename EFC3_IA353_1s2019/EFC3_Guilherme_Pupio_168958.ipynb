{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EFC3 -  Guilherme Covre Pupio - RA 168958\n",
    "\n",
    "* Este Notebook apresenta as questões 1 a 5 do EFC3.\n",
    "* Todas as Saídas geradas e entradas utilizadas neste Notebook estão disponiveis em:\n",
    "https://github.com/Guipupio/Redes_neuraias/tree/master/EFC3_IA353_1s2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 1\n",
    "\n",
    "* O código a seguir apresenta uma CNN, que é treinada com a base MNIST.\n",
    "\n",
    "## Observação\n",
    "* Esta questão apresentou problemas durante a execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Gabriel\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 141s 2ms/step - loss: 0.1887 - acc: 0.9432\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 144s 2ms/step - loss: 0.0784 - acc: 0.9772\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 140s 2ms/step - loss: 0.0611 - acc: 0.9811\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 142s 2ms/step - loss: 0.0490 - acc: 0.9848\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 140s 2ms/step - loss: 0.0425 - acc: 0.9867\n",
      "10000/10000 [==============================] - 4s 434us/step\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
    " activation='relu',input_shape=(28, 28, 1)))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.get_config()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    " loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "evaluation = model.evaluate(x_test, y_test)\n",
    "\n",
    "model.save(r'./input_Q1/mnist_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 1 - item `A` \n",
    "\n",
    "* Utilizarei as seguintes classes:\n",
    "    * Classe 0: posicao em x_test ->(3:4, 10:11)\n",
    "    * Classe 1: posicao em x_test ->(2:3, 5:6)\n",
    "    * Classe 4: posicao em x_test ->(4:5, 6:7)\n",
    "    \n",
    "## Execução parte 1\n",
    "\n",
    "* Segue abaixo a execução para o primeiro conjunto de classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 18 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#\\end{lstlisting}\n",
    "#\\end{framed}\n",
    "\n",
    "\n",
    "#Questao 1a:\n",
    "#-----------\n",
    "from tensorflow import keras\n",
    "import innvestigate\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "# mnist = keras.datasets.mnist\n",
    "# (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "# x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "# x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "# x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# model = keras.models.load_model(r'./input_Q1/mnist_model.h5')\n",
    "model_wo_sm = innvestigate.utils.keras.graph.model_wo_softmax(model)\n",
    "\n",
    "# Define conjunto de imagens\n",
    "imagens = [\n",
    "    (3,4),    # Classe 0\n",
    "    (2,3),    # Classe 1\n",
    "    (4,5),    # Classe 4\n",
    "]\n",
    "\n",
    "x_label = ['Gradient', 'SmoothGrad', 'DeepTaylor', 'LRPAlphaBeta', 'LRPEpsilon', 'LRPZ']\n",
    "\n",
    "\n",
    "for i, coordenada in enumerate(imagens):\n",
    "#     for j, coordenada in enumerate(coordenadas):\n",
    "    imagem = x_test[coordenada[0]:coordenada[1]]\n",
    "\n",
    "    ## Gradient\n",
    "    analyzer = innvestigate.analyzer.Gradient(model=model_wo_sm)\n",
    "    analysis = analyzer.analyze(imagem)\n",
    "    plot.subplot(3,6, i*6 +1)\n",
    "    # Exibe imagem\n",
    "    plot.imshow(analysis.squeeze(), cmap='seismic',\n",
    "     interpolation='nearest')\n",
    "    plot.axis('off')\n",
    "\n",
    "    ## SmoothGrad\n",
    "\n",
    "    analyzer = innvestigate.analyzer.SmoothGrad(model=model_wo_sm)\n",
    "    analysis = analyzer.analyze(imagem)\n",
    "    plot.subplot(3,6, i*6 +2)\n",
    "    # Exibe imagem\n",
    "    plot.imshow(analysis.squeeze(), cmap='seismic', interpolation='nearest')\n",
    "    plot.axis('off')\n",
    "    \n",
    "    ## DeepTaylor\n",
    "    analyzer = innvestigate.analyzer.DeepTaylor(model=model_wo_sm)\n",
    "    analysis = analyzer.analyze(imagem)\n",
    "    plot.subplot(3,6, i*6 +3)\n",
    "    # Exibe imagem\n",
    "    plot.imshow(analysis.squeeze(), cmap='seismic', interpolation='nearest')\n",
    "    plot.axis('off')\n",
    "    \n",
    "    ## LRPAlphaBeta\n",
    "    analyzer = innvestigate.analyzer.LRPAlphaBeta(model=model_wo_sm,alpha=1, beta=0)\n",
    "    analysis = analyzer.analyze(imagem)\n",
    "    plot.subplot(3,6, i*6 +4)\n",
    "    # Exibe imagem\n",
    "    plot.imshow(analysis.squeeze(), cmap='seismic', interpolation='nearest')\n",
    "    plot.axis('off')\n",
    "    \n",
    "    ## LRPEpsilon\n",
    "    analyzer = innvestigate.analyzer.LRPEpsilon(model=model_wo_sm, epsilon=1)\n",
    "    analysis = analyzer.analyze(imagem)\n",
    "    plot.subplot(3,6, i*6 +5)\n",
    "    # Exibe imagem\n",
    "    plot.imshow(analysis.squeeze(), cmap='seismic', interpolation='nearest')\n",
    "    plot.axis('off')\n",
    "    \n",
    "    ## LRPZ\n",
    "    analyzer = innvestigate.analyzer.LRPZ(model=model_wo_sm)\n",
    "    analysis = analyzer.analyze(imagem)\n",
    "    plot.subplot(3,6, i*6 +6)\n",
    "    # Exibe imagem\n",
    "    plot.imshow(analysis.squeeze(), cmap='seismic', interpolation='nearest')\n",
    "    plot.axis('off')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execução Parte 2\n",
    "\n",
    "* Segue abaixo a execução para o segundo conjunto de imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 18 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define conjunto de imagens\n",
    "imagens = [\n",
    "    (10,11),    # Classe 0\n",
    "    (5,6),    # Classe 1\n",
    "    (6,7),    # Classe 4\n",
    "]\n",
    "\n",
    "x_label = ['Gradient', 'SmoothGrad', 'DeepTaylor', 'LRPAlphaBeta', 'LRPEpsilon', 'LRPZ']\n",
    "\n",
    "\n",
    "for i, coordenada in enumerate(imagens):\n",
    "#     for j, coordenada in enumerate(coordenadas):\n",
    "    imagem = x_test[coordenada[0]:coordenada[1]]\n",
    "\n",
    "    ## Gradient\n",
    "    analyzer = innvestigate.analyzer.Gradient(model=model_wo_sm)\n",
    "    analysis = analyzer.analyze(imagem)\n",
    "    plot.subplot(3,6, i*6 +1)\n",
    "    # Exibe imagem\n",
    "    plot.imshow(analysis.squeeze(), cmap='seismic',\n",
    "     interpolation='nearest')\n",
    "    plot.axis('off')\n",
    "\n",
    "    ## SmoothGrad\n",
    "\n",
    "    analyzer = innvestigate.analyzer.SmoothGrad(model=model_wo_sm)\n",
    "    analysis = analyzer.analyze(imagem)\n",
    "    plot.subplot(3,6, i*6 +2)\n",
    "    # Exibe imagem\n",
    "    plot.imshow(analysis.squeeze(), cmap='seismic', interpolation='nearest')\n",
    "    plot.axis('off')\n",
    "    \n",
    "    ## DeepTaylor\n",
    "    analyzer = innvestigate.analyzer.DeepTaylor(model=model_wo_sm)\n",
    "    analysis = analyzer.analyze(imagem)\n",
    "    plot.subplot(3,6, i*6 +3)\n",
    "    # Exibe imagem\n",
    "    plot.imshow(analysis.squeeze(), cmap='seismic', interpolation='nearest')\n",
    "    plot.axis('off')\n",
    "    \n",
    "    ## LRPAlphaBeta\n",
    "    analyzer = innvestigate.analyzer.LRPAlphaBeta(model=model_wo_sm,alpha=1, beta=0)\n",
    "    analysis = analyzer.analyze(imagem)\n",
    "    plot.subplot(3,6, i*6 +4)\n",
    "    # Exibe imagem\n",
    "    plot.imshow(analysis.squeeze(), cmap='seismic', interpolation='nearest')\n",
    "    plot.axis('off')\n",
    "    \n",
    "    ## LRPEpsilon\n",
    "    analyzer = innvestigate.analyzer.LRPEpsilon(model=model_wo_sm, epsilon=1)\n",
    "    analysis = analyzer.analyze(imagem)\n",
    "    plot.subplot(3,6, i*6 +5)\n",
    "    # Exibe imagem\n",
    "    plot.imshow(analysis.squeeze(), cmap='seismic', interpolation='nearest')\n",
    "    plot.axis('off')\n",
    "    \n",
    "    ## LRPZ\n",
    "    analyzer = innvestigate.analyzer.LRPZ(model=model_wo_sm)\n",
    "    analysis = analyzer.analyze(imagem)\n",
    "    plot.subplot(3,6, i*6 +6)\n",
    "    # Exibe imagem\n",
    "    plot.imshow(analysis.squeeze(), cmap='seismic', interpolation='nearest')\n",
    "    plot.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise dos métodos\n",
    "\n",
    "* Cada coluna mostra os resultados visualizados para os respectivos analisadores:\n",
    "    * `Gradient`\n",
    "    * `SmoothGrad`\n",
    "    * `DeepTaylor`\n",
    "    * `LRPAlphaBeta`\n",
    "    * `LRPEpsilon`\n",
    "    * `LRPZ`\n",
    "* Cada linha representa uma classe que esta sendo analisada:\n",
    "    * Classe `0`\n",
    "    * Classe `1`\n",
    "    * Classe `4`\n",
    "* Podemos notar que os metodos de `DeepTaylor` em diante, esboçam mais claramente os atributos da imagem que mais se destacam na escolha de uma classe para a imagem, enquanto que para os metodos `Gradient` e, principalmente para o `SmoothGrad`, a análise de representatividade parece um pouco mais obscura para interpretação humana.\n",
    "\n",
    "* Podemos notar que esta análize mostra a penalização sobre os atributos, de forma que os pixels em azulados indicam atributos que tiveram \"valor positivo\" na escolha da determinada classe e os pixels avermelhados indicam atributos que tiveram \"valor negativo\" na escolha da determinada classe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 1 - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/tmp/9baimqzo.h5'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vis\\utils\\utils.py\u001b[0m in \u001b[0;36mapply_modifications\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m   1089\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1090\u001b[1;33m         \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1091\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, mode)\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to create file (unable to open file: name = '/tmp/9baimqzo.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 302)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-38cc49c02549>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mlayer_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmodel3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_modifications\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mfilter_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vis\\utils\\utils.py\u001b[0m in \u001b[0;36mapply_modifications\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/tmp/9baimqzo.h5'"
     ]
    }
   ],
   "source": [
    "# #Questao 1b:\n",
    "# #-----------\n",
    "import keras\n",
    "from vis.visualization import visualize_activation\n",
    "from vis.utils import utils\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "model3 = keras.models.load_model('./input_Q1/mnist_model.h5')\n",
    "\n",
    "## Obtem ultima camada do Model\n",
    "#layer_idx = utils.find_layer_idx(model, 'dense_2')\n",
    "layer_idx = -1\n",
    "model3.layers[layer_idx].activation = keras.activations.linear\n",
    "model3 = utils.apply_modifications(model3)\n",
    "\n",
    "filter_idx = 9\n",
    "img = visualize_activation(model3, layer_idx, filter_indices=filter_idx, input_range=(0.0, 1.0), verbose=True,\n",
    " max_iter=1000, tv_weight=1.0, lp_norm_weight=0.0)\n",
    "plot.imshow(img.squeeze(), cmap='seismic', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questao 2 \n",
    "\n",
    "##### Treinamento de GANS\n",
    "\n",
    "## Parâmetros\n",
    "* Os parâmetros utilizados para esta Rede Neural foram, os sugeridos pelo roteiro, ou seja\n",
    "    * Numero total de épocas para treinamento: 30000\n",
    "    * O Código salva imagens a cada 200 épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 533,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 784)               803600    \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,493,520\n",
      "Trainable params: 1,489,936\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class GAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        validity = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=self.img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = X_train / 127.5 - 1.\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Generate a batch of new images\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Train the generator (to have the discriminator label samples as valid)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images_Q2/%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gan = GAN()\n",
    "    gan.train(epochs=30000, batch_size=32, sample_interval=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imagens Geradas - GAN"
   ]
  },
  {
   "attachments": {
    "0.png": {
     "image/png": "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"
    },
    "15000.png": {
     "image/png": "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"
    },
    "29600.png": {
     "image/png": "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"
    },
    "29800.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagem Primeira Época\n",
    "![0.png](attachment:0.png)\n",
    "\n",
    "## Imagem Durante a Época 15000\n",
    "![15000.png](attachment:15000.png)\n",
    "\n",
    "## Penultima Imagem (Época 29600)\n",
    "![29600.png](attachment:29600.png)\n",
    "\n",
    "## Ultima imagem (Época 29800)\n",
    "![29800.png](attachment:29800.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pupio/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/pupio/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pupio/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:73: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "/home/pupio/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:77: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 2/10\n",
      "Epoch 3/10\n",
      "Epoch 4/10\n",
      "Epoch 5/10\n",
      "Epoch 6/10\n",
      "Epoch 7/10\n",
      "Epoch 8/10\n",
      "Epoch 9/10\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pupio/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:79: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "/home/pupio/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:89: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 36 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 235,
       "width": 335
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Convolution2D, MaxPooling2D, Flatten, Input\n",
    "from keras.optimizers import adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "train = pd.read_csv(r\"./input_Q3/train.csv\")\n",
    "\n",
    "X_train = train.iloc[:,1:].values\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28) #reshape to rectangular\n",
    "X_train = X_train/255 #pixel values are 0 - 255 - this makes puts them in the range 0 - 1\n",
    "\n",
    "y_train = train[\"label\"].values\n",
    "\n",
    "#define a function that allows us to see the digits:\n",
    "def show(img):\n",
    "    plt.imshow(img, cmap = \"gray\", interpolation = \"none\")\n",
    "    \n",
    "img = X_train[10]\n",
    "show(img)\n",
    "\n",
    "pd.DataFrame(img)\n",
    "\n",
    "#generating a random 28 by 28 image:\n",
    "rand_img = np.random.randint(0, 255, (28, 28))\n",
    "rand_img = rand_img/255.0\n",
    "\n",
    "show(rand_img)\n",
    "\n",
    "rand_direction = np.random.rand(28, 28) \n",
    "\n",
    "for i in range(16):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    show(img + i/4*rand_direction)    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "X_flat = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2])\n",
    "\n",
    "knn = NearestNeighbors(5000)\n",
    "\n",
    "knn.fit(X_flat[:5000])\n",
    "\n",
    "distances, neighbors = knn.kneighbors(img.flatten().reshape(1, -1))\n",
    "neighbors = neighbors[0]\n",
    "distances = distances[0]\n",
    "\n",
    "plt.hist(distances[1:])\n",
    "for digit_num, num in enumerate(neighbors[:36]):\n",
    "    plt.subplot(6,6,digit_num+1)\n",
    "    grid_data = X_train[num]  # reshape from 1d to 2d pixel array\n",
    "    show(grid_data)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(64, activation='relu')(input_img)\n",
    "\n",
    "encoded = Dense(2)(encoded) #keep it linear here.\n",
    "\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(784, activation = 'sigmoid')(decoded)\n",
    "\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "autoencoder.compile(optimizer = \"adam\", loss = \"mse\")\n",
    "autoencoder.fit(X_flat, X_flat, batch_size = 128,\n",
    "                nb_epoch = 10, verbose = 3)\n",
    "\n",
    "encoder = Model(input = input_img, output = encoded)\n",
    "\n",
    "#building the decoder:\n",
    "encoded_input = Input(shape=(2,))\n",
    "encoded_layer_1 = autoencoder.layers[-2]\n",
    "encoded_layer_2 = autoencoder.layers[-1]\n",
    "\n",
    "\n",
    "decoder = encoded_layer_1(encoded_input)\n",
    "decoder = encoded_layer_2(decoder)\n",
    "decoder = Model(input=encoded_input, output=decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fa2e3ebf0f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 402.375x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 349,
       "width": 393
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "\n",
    "X_proj = encoder.predict(X_flat[:10000])\n",
    "X_proj.shape\n",
    "\n",
    "proj = pd.DataFrame(X_proj)\n",
    "proj.columns = [\"comp_1\", \"comp_2\"]\n",
    "proj[\"labels\"] = y_train[:10000]\n",
    "sns.lmplot(\"comp_1\", \"comp_2\",hue = \"labels\", data = proj, fit_reg=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 317
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#define a function that allows us to see the digits:\n",
    "def show(img):\n",
    "    plt.imshow(img, cmap = \"gray\", interpolation = \"none\")\n",
    "    \n",
    "    \n",
    "#how well does the autoencoder decode:w1\n",
    "plt.subplot(2,2,1)\n",
    "show(X_train[160])\n",
    "plt.subplot(2,2,2)\n",
    "show(autoencoder.predict(np.expand_dims(X_train[160].flatten(), 0)).reshape(28, 28))\n",
    "plt.subplot(2,2,3)\n",
    "show(X_train[150])\n",
    "plt.subplot(2,2,4)\n",
    "show(autoencoder.predict(np.expand_dims(X_train[150].flatten(), 0)).reshape(28, 28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-9bf9ce4b84eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m121\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mpt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADkAAAA0CAYAAAAwhpBbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAAe9JREFUaIHtmT1rVEEYhZ9jJM3WVlFQQbJsmRVL62hja+pAKn+A4O+w2SLYJXWKgK2NhbuFEAsl2rgoiNhHhWOxKRYN3HcvM3fj7Dxwi7m8d+Yc5uO+MyPblM6VZQvogmqyFKrJUqgmASTtS/om6aQLQTmI9OQLYDuzjqw0mrT9CvjRgZZsrMScvJqqIkl7wB5Ar9cb9vv9VFVfyGQy+W77WijYduMD3AROIrG2GQ6Hzg0wjupZieEa+YUcAK+BTUlTSbv5ZaWlcU7a3ulCSE7qcC2FarIUqslSqCZLIWRS0rak95JOJT3NLSo1kbRuDXgOPAAGwI6kQW5hKYn05D3g1PYn2z+BQ+BRXllpiZjcAD7Plafn7/4bIptmXfDunwuU+U0zcNbBwddmNDBicgrcmCtfB778HWR7BIwAJI1t342KaIOkcTQ2MlzfAHck3ZK0DjwGjtqKWwaR/eRvSU+Al8AasG/7XXZlCQkdZNk+Bo4XqHfUTs5ChNuQ6yVsGSQ12UX61+puJnp22fQwW5Q+AreBdeAtMEhV/1w794EtFjgHTtmTnaR/bnE3k9LkpU3/UpoMpX/LIKXJUPq3DFKavLzpX+KV7yHwgdkq+yz1ynrexgHwFfjFbPTsNn1TM55SqCZLoZoshWqyFFbC5B8eL0xtDhUvhwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#define a function that allows us to see the digits:\n",
    "def show(img):\n",
    "    plt.imshow(img, cmap = \"gray\", interpolation = \"none\")\n",
    "\n",
    "#moving along both x and y axis:\n",
    "for i in range(121):\n",
    "        plt.subplot(11,11,i+1)\n",
    "        pt = np.array([[i*4/12,i%13*4]])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "#         print(pt)\n",
    "        \n",
    "        show(decoder.predict(pt).reshape((28, 28)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 4\n",
    "\n",
    "* ## Parte A:\n",
    "    * Dentre as quatro possibilidades de redes já treinadas, escolhi a `reddit_apple_android.hdf5`.\n",
    "    * Pode-se observar que a variação do parâmetro `temperature` tem bastante influência sobre o conteúdo da frase gerada. No caso observado, para valores pequenos de `temperature` a frase gerada parece mais coerente com a realidade, assim, com o aumento de `temperature`, a coerência da frase com a realidade é distorcida e com `temperature=1.0` já temos uma frase sem sentido. \n",
    "    * O sintoma é ainda mais forte quando `temperature >= 1.25` onde até mesmos caracteres não pertencentes ao ASCII são geradados na frase. Em outros testes que realizei com valores ainda mais altos de `temperature` até emojis são gerados no terminal.\n",
    "    \n",
    "    * Por fim, podemos dizer que o parâmetro `temperature` causa uma caracteristica de \"criatividade\" para a máquina. Quanto maior este parâmetro, mais \"criativa\" é a saída da máquina.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parâmetro Temperature = 0.1\n",
      "Apple Releases iOS 10.3.1 With Bug Fixes\n",
      "\n",
      "Parâmetro Temperature = 0.25\n",
      "Apple should make PiP on iOS an user option not something controlled by developer (and get abused by Youtube for example)\n",
      "\n",
      "Parâmetro Temperature = 0.5\n",
      "Apple Is Working on a Dedicated Chip to Power AI on Devices\n",
      "\n",
      "Parâmetro Temperature = 0.75\n",
      "The Tabron becamp dumbile exclusives right now now how has been tilling up by reported?\n",
      "\n",
      "Parâmetro Temperature = 1.0\n",
      "Apple Total fixed the S8 week with the FBKs 17: virtuate tab and USB-AndaeP and most lovely on Apple Watch\n",
      "\n",
      "Parâmetro Temperature = 1.25\n",
      "PSA: Google shutdo remaps angles cerentomed me\n",
      "\n",
      "Parâmetro Temperature = 1.5\n",
      "Something creepy and I wi｡hed thire, not her including , bring Explowing and auto-W×ttlracking\n",
      "\n",
      "Parâmetro Temperature = 2.0\n",
      "Alleged̫ 8 ürbe）marts off to oｏ_30-83 mill0ncing phone and 3-minute Ma High͍ndˢEgal much newerd✝el market hrleash C Turk\n",
      "\n",
      "Parâmetro Temperature = 3.0\n",
      "V\"ｅʇjfaquイ>̯r gv̥z► n͖и G★aQSD~つ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parte A - Verificando frases com base no parametro temperature\n",
    "from textgenrnn import textgenrnn\n",
    "\n",
    "## Importa Rede ja treinada\n",
    "meu_gerador = textgenrnn('./weights_Q4/reddit_apple_android.hdf5')\n",
    "\n",
    "temperatures=[0.1, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 2.0, 3.0]\n",
    "\n",
    "for temperature in temperatures:\n",
    "    print(\"Parâmetro Temperature = {}\".format(temperature))\n",
    "    meu_gerador.generate(interactive=False, temperature=temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 4\n",
    "\n",
    "## Parte B\n",
    "\n",
    "   * O objetivo desta seção é treinar uma rede neural tendo como base um livro em português. O livro escolhido foi o apresentado no exemplo `domcasmurro`.\n",
    "   * A seguir realizei o treinamento da Rede com base no livro. Ao fim do treino, salvei os pesos adquiridos ao longo do treinamento\n",
    "   * Por fim, o ultimo bloco desta questão exibe a execução de uma geração de texto iterativa.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8,547 texts collected.\n",
      "Training new model w/ 2-layer, 128-cell LSTMs\n",
      "Training on 92,383 word sequences.\n",
      "Epoch 1/20\n",
      "721/721 [==============================] - 240s 333ms/step - loss: 6.0846\n",
      "Epoch 2/20\n",
      "721/721 [==============================] - 220s 305ms/step - loss: 5.3899\n",
      "Epoch 3/20\n",
      "721/721 [==============================] - 220s 306ms/step - loss: 4.7600\n",
      "Epoch 4/20\n",
      "721/721 [==============================] - 220s 306ms/step - loss: 4.3139\n",
      "Epoch 5/20\n",
      "721/721 [==============================] - 220s 305ms/step - loss: 3.8860\n",
      "Epoch 6/20\n",
      "721/721 [==============================] - 220s 305ms/step - loss: 3.4670\n",
      "Epoch 7/20\n",
      "721/721 [==============================] - 222s 308ms/step - loss: 3.0759\n",
      "Epoch 8/20\n",
      "721/721 [==============================] - 220s 305ms/step - loss: 2.7262\n",
      "Epoch 9/20\n",
      "721/721 [==============================] - 220s 305ms/step - loss: 2.4313\n",
      "Epoch 10/20\n",
      "721/721 [==============================] - 220s 305ms/step - loss: 2.1809\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "\n",
      "\n",
      "como ambas as ponho . . . uma vigairaria mineira .\n",
      "\n",
      "acudiram - me . e _ , as mãos na mesma hora . o principal contava a tal que\n",
      "\n",
      "Epoch 11/20\n",
      "721/721 [==============================] - 220s 306ms/step - loss: 1.9696\n",
      "Epoch 12/20\n",
      "721/721 [==============================] - 220s 305ms/step - loss: 1.7878\n",
      "Epoch 13/20\n",
      "721/721 [==============================] - 220s 305ms/step - loss: 1.6263\n",
      "Epoch 14/20\n",
      "721/721 [==============================] - 221s 306ms/step - loss: 1.4913\n",
      "Epoch 15/20\n",
      "721/721 [==============================] - 220s 305ms/step - loss: 1.3729\n",
      "Epoch 16/20\n",
      "721/721 [==============================] - 220s 306ms/step - loss: 1.2737\n",
      "Epoch 17/20\n",
      "721/721 [==============================] - 220s 305ms/step - loss: 1.1878\n",
      "Epoch 18/20\n",
      "721/721 [==============================] - 220s 306ms/step - loss: 1.1167\n",
      "Epoch 19/20\n",
      "721/721 [==============================] - 220s 306ms/step - loss: 1.0562\n",
      "Epoch 20/20\n",
      "721/721 [==============================] - 220s 306ms/step - loss: 1.0079\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "entre um grande fizera mais . de noite , a necessidade de capitú cochilando , o\n",
      "\n",
      "definitiva para as virtudes que as memorias do orgulho de santa .\n",
      "\n",
      "saber de um seminarista , não só agora , a lingua que agarrado .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textgenrnn import textgenrnn\n",
    "\n",
    "# define caminho da base\n",
    "file_path = \"./input_Q4/domcasmurro.txt\"\n",
    "# Instancia a RNN\n",
    "textgen = textgenrnn()\n",
    "textgen.reset()\n",
    "# Treina RNN\n",
    "textgen.train_from_file(file_path, new_model=True, num_epochs=20,\n",
    "gen_epochs=10, word_level=True)\n",
    "\n",
    "# Salva pesos adquiridos no treinamento\n",
    "textgen.save('./weights_Q4/domcasmurro.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: <s>\n",
      "\t2: -\n",
      "\t3: que\n",
      "\t4: a\n",
      "\t5: não\n",
      "\n",
      "Progress: \n",
      "\n",
      "Your choice?\n",
      "> 4\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: minha\n",
      "\t2: verdade\n",
      "\t3: resposta\n",
      "\t4: sua\n",
      "\t5: mim\n",
      "\n",
      "Progress:  a\n",
      "\n",
      "Your choice?\n",
      "> 1\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: mãe\n",
      "\t2: vida\n",
      "\t3: gloria\n",
      "\t4: grande\n",
      "\t5: alma\n",
      "\n",
      "Progress:  a minha\n",
      "\n",
      "Your choice?\n",
      "> 2\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: era\n",
      "\t2: ;\n",
      "\t3: na\n",
      "\t4: padre\n",
      "\t5: ,\n",
      "\n",
      "Progress:  a minha vida\n",
      "\n",
      "Your choice?\n",
      "> 1\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: como\n",
      "\t2: uma\n",
      "\t3: boa\n",
      "\t4: a\n",
      "\t5: outra\n",
      "\n",
      "Progress:  a minha vida era\n",
      "\n",
      "Your choice?\n",
      "> 3\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: .\n",
      "\t2: ;\n",
      "\t3: !\n",
      "\t4: impressão\n",
      "\t5: de\n",
      "\n",
      "Progress:  a minha vida era boa\n",
      "\n",
      "Your choice?\n",
      "> 1\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: <s>\n",
      "\t2: a\n",
      "\t3: quem\n",
      "\t4: »\n",
      "\t5: ha\n",
      "\n",
      "Progress:  a minha vida era boa .\n",
      "\n",
      "Your choice?\n",
      "> 5\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: de\n",
      "\t2: dias\n",
      "\t3: muita\n",
      "\t4: tanto\n",
      "\t5: muito\n",
      "\n",
      "Progress:  a minha vida era boa . ha\n",
      "\n",
      "Your choice?\n",
      "> 4\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: de\n",
      "\t2: melhor\n",
      "\t3: muita\n",
      "\t4: dias\n",
      "\t5: bom\n",
      "\n",
      "Progress:  a minha vida era boa . ha tanto\n",
      "\n",
      "Your choice?\n",
      "> 1\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: latim\n",
      "\t2: ir\n",
      "\t3: quem\n",
      "\t4: contar\n",
      "\t5: fale\n",
      "\n",
      "Progress:  a minha vida era boa . ha tanto de\n",
      "\n",
      "Your choice?\n",
      "> x\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: de\n",
      "\t2: melhor\n",
      "\t3: muita\n",
      "\t4: dias\n",
      "\t5: bom\n",
      "\n",
      "Progress:  a minha vida era boa . ha tanto\n",
      "\n",
      "Your choice?\n",
      "> o\n",
      "> para\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: que\n",
      "\t2: me\n",
      "\t3: não\n",
      "\t4: nunca\n",
      "\t5: ir\n",
      "\n",
      "Progress:  a minha vida era boa . ha tanto para\n",
      "\n",
      "Your choice?\n",
      "> 5\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: acostumando\n",
      "\t2: ao\n",
      "\t3: contar\n",
      "\t4: ver\n",
      "\t5: atraz\n",
      "\n",
      "Progress:  a minha vida era boa . ha tanto para ir\n",
      "\n",
      "Your choice?\n",
      "> 3\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: a\n",
      "\t2: o\n",
      "\t3: que\n",
      "\t4: as\n",
      "\t5: ,\n",
      "\n",
      "Progress:  a minha vida era boa . ha tanto para ir contar\n",
      "\n",
      "Your choice?\n",
      "> s\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: a\n",
      "\t2: o\n",
      "\t3: que\n",
      "\t4: minha\n",
      "\t5: capitú\n",
      "\n",
      "Progress:  a minha vida era boa . ha tanto para ir contar <s>\n",
      "\n",
      "Your choice?\n",
      "> 3\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: a\n",
      "\t2: elle\n",
      "\t3: só\n",
      "\t4: <s>\n",
      "\t5: já\n",
      "\n",
      "Progress:  a minha vida era boa . ha tanto para ir contar <s> que\n",
      "\n",
      "Your choice?\n",
      "> 4\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: <s>\n",
      "\t2: hontem\n",
      "\t3: dentro\n",
      "\t4: a\n",
      "\t5: ir\n",
      "\n",
      "Progress:  a minha vida era boa . ha tanto para ir contar <s> que <s>\n",
      "\n",
      "Your choice?\n",
      "> p\n",
      "That's not an option!\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: <s>\n",
      "\t2: hontem\n",
      "\t3: dentro\n",
      "\t4: a\n",
      "\t5: ir\n",
      "\n",
      "Progress:  a minha vida era boa . ha tanto para ir contar <s> que <s>\n",
      "\n",
      "Your choice?\n",
      "> x\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: a\n",
      "\t2: elle\n",
      "\t3: só\n",
      "\t4: <s>\n",
      "\t5: já\n",
      "\n",
      "Progress:  a minha vida era boa . ha tanto para ir contar <s> que\n",
      "\n",
      "Your choice?\n",
      "> x\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: a\n",
      "\t2: o\n",
      "\t3: que\n",
      "\t4: minha\n",
      "\t5: capitú\n",
      "\n",
      "Progress:  a minha vida era boa . ha tanto para ir contar <s>\n",
      "\n",
      "Your choice?\n",
      "> x\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: a\n",
      "\t2: o\n",
      "\t3: que\n",
      "\t4: as\n",
      "\t5: ,\n",
      "\n",
      "Progress:  a minha vida era boa . ha tanto para ir contar\n",
      "\n",
      "Your choice?\n",
      "> 5\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: quando\n",
      "\t2: a\n",
      "\t3: capitú\n",
      "\t4: mas\n",
      "\t5: eu\n",
      "\n",
      "Progress:  a minha vida era boa . ha tanto para ir contar ,\n",
      "\n",
      "Your choice?\n",
      "> 4\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: quando\n",
      "\t2: eu\n",
      "\t3: hei\n",
      "\t4: desta\n",
      "\t5: já\n",
      "\n",
      "Progress:  a minha vida era boa . ha tanto para ir contar , mas\n",
      "\n",
      "Your choice?\n",
      "> 3\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: de\n",
      "\t2: soube\n",
      "\t3: conta\n",
      "\t4: vel\n",
      "\t5: disso\n",
      "\n",
      "Progress:  a minha vida era boa . ha tanto para ir contar , mas hei\n",
      "\n",
      "Your choice?\n",
      "> 1\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: ser\n",
      "\t2: ir\n",
      "\t3: ver\n",
      "\t4: dentro\n",
      "\t5: quem\n",
      "\n",
      "Progress:  a minha vida era boa . ha tanto para ir contar , mas hei de\n",
      "\n",
      "Your choice?\n",
      "> 2\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: ver\n",
      "\t2: <s>\n",
      "\t3: ir\n",
      "\t4: ser\n",
      "\t5: vel\n",
      "\n",
      "Progress:  a minha vida era boa . ha tanto para ir contar , mas hei de ir\n",
      "\n",
      "Your choice?\n",
      "> x\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: ser\n",
      "\t2: ir\n",
      "\t3: ver\n",
      "\t4: dentro\n",
      "\t5: quem\n",
      "\n",
      "Progress:  a minha vida era boa . ha tanto para ir contar , mas hei de\n",
      "\n",
      "Your choice?\n",
      "> 1\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: <s>\n",
      "\t2: que\n",
      "\t3: b\n",
      "\t4: padre\n",
      "\t5: já\n",
      "\n",
      "Progress:  a minha vida era boa . ha tanto para ir contar , mas hei de ser\n",
      "\n",
      "Your choice?\n",
      "> 4\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: <s>\n",
      "\t2: ?\n",
      "\t3: de\n",
      "\t4: em\n",
      "\t5: .\n",
      "\n",
      "Progress:  a minha vida era boa . ha tanto para ir contar , mas hei de ser padre\n",
      "\n",
      "Your choice?\n",
      "> 5\n",
      "Controls:\n",
      "\ts: stop.\tx: backspace.\to: write your own.\n",
      "\n",
      "Options:\n",
      "\t1: <s>\n",
      "\t2: em\n",
      "\t3: não\n",
      "\t4: já\n",
      "\t5: no\n",
      "\n",
      "Progress:  a minha vida era boa . ha tanto para ir contar , mas hei de ser padre .\n",
      "\n",
      "Your choice?\n"
     ]
    }
   ],
   "source": [
    "from textgenrnn import textgenrnn\n",
    "textgen = textgenrnn('./weights_Q4/domcasmurro.hdf5')\n",
    "textgen.generate(interactive=True, top_n=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observações Finais:\n",
    "\n",
    "* Após fazer o download do domcasmurro.txt, realizei uma alteração no arquivo. Removi uns textos em Inglês presentes tanto no início quanto no fim do arquivo. Removi esses trechos para que a rede pudesse de fato treinar apenas com o conteudo do livro.\n",
    "\n",
    "* Uma observação é que o comando `stop` da rede iterativa não pareceu funcionar muito bem, uma vez que inserir `s` inseria `<s>` ao inves de parar a geração de palavras. Dessa forma, para concluir a frase sem gerar `KeyBoard Interruption`, precisei para a execução do KERNEL.\n",
    "\n",
    "* Por fim, foi incrível iteragir com o gerador, uma vez que as todas palavras sugeridas para a frase se encaixam, ao menos, no contexto da palavra imediatamente anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 5\n",
    "\n",
    "## Metodo 1: Cross-Entropy\n",
    "\n",
    "## Desempenho:\n",
    "* O metodo Cross Entropy foi o metodo mais rapido entre os demais, sendo assim, o seu tempo de treino foi adotado como referencia para os demais metodos. A Seguir o resumo dos resultados:\n",
    "\n",
    "    * Tempo de treino aproximado: 52 segundos\n",
    "    * Recompensas:\n",
    "        * Episode 1: reward: 172.000, steps: 172\n",
    "        * Episode 2: reward: 143.000, steps: 143\n",
    "        * Episode 3: reward: 181.000, steps: 181\n",
    "        * Episode 4: reward: 200.000, steps: 200\n",
    "        * Episode 5: reward: 200.000, steps: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 658\n",
      "Trainable params: 658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training for 100000 steps ...\n",
      "    22/100000: episode: 1, duration: 0.365s, episode steps: 22, steps per second: 60, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: -0.105 [-0.935, 0.391], mean_best_reward: --\n",
      "    36/100000: episode: 2, duration: 0.008s, episode steps: 14, steps per second: 1840, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.286 [0.000, 1.000], mean observation: 0.138 [-1.137, 2.156], mean_best_reward: --\n",
      "    59/100000: episode: 3, duration: 0.012s, episode steps: 23, steps per second: 1952, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.391 [0.000, 1.000], mean observation: 0.097 [-0.944, 1.927], mean_best_reward: --\n",
      "    71/100000: episode: 4, duration: 0.007s, episode steps: 12, steps per second: 1621, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.117 [-2.212, 1.349], mean_best_reward: --\n",
      "    81/100000: episode: 5, duration: 0.006s, episode steps: 10, steps per second: 1623, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.700 [0.000, 1.000], mean observation: -0.099 [-1.911, 1.213], mean_best_reward: --\n",
      "    94/100000: episode: 6, duration: 0.008s, episode steps: 13, steps per second: 1720, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.692 [0.000, 1.000], mean observation: -0.091 [-1.766, 0.996], mean_best_reward: --\n",
      "   106/100000: episode: 7, duration: 0.007s, episode steps: 12, steps per second: 1635, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.167 [0.000, 1.000], mean observation: 0.119 [-1.524, 2.522], mean_best_reward: --\n",
      "   117/100000: episode: 8, duration: 0.006s, episode steps: 11, steps per second: 1715, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.364 [0.000, 1.000], mean observation: 0.110 [-0.984, 1.562], mean_best_reward: --\n",
      "   130/100000: episode: 9, duration: 0.007s, episode steps: 13, steps per second: 1939, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.231 [0.000, 1.000], mean observation: 0.128 [-1.331, 2.344], mean_best_reward: --\n",
      "   186/100000: episode: 10, duration: 0.029s, episode steps: 56, steps per second: 1962, episode reward: 56.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: -0.108 [-1.910, 1.696], mean_best_reward: --\n",
      "   199/100000: episode: 11, duration: 0.007s, episode steps: 13, steps per second: 1758, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.154 [0.000, 1.000], mean observation: 0.099 [-1.788, 2.784], mean_best_reward: --\n",
      "   227/100000: episode: 12, duration: 0.015s, episode steps: 28, steps per second: 1874, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.571 [0.000, 1.000], mean observation: -0.067 [-1.720, 0.844], mean_best_reward: --\n",
      "   240/100000: episode: 13, duration: 0.007s, episode steps: 13, steps per second: 1740, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.692 [0.000, 1.000], mean observation: -0.091 [-1.829, 1.030], mean_best_reward: --\n",
      "   263/100000: episode: 14, duration: 0.011s, episode steps: 23, steps per second: 2010, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.522 [0.000, 1.000], mean observation: -0.083 [-1.057, 0.427], mean_best_reward: --\n",
      "   274/100000: episode: 15, duration: 0.007s, episode steps: 11, steps per second: 1559, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.273 [0.000, 1.000], mean observation: 0.107 [-1.185, 1.974], mean_best_reward: --\n",
      "   283/100000: episode: 16, duration: 0.006s, episode steps: 9, steps per second: 1597, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.111 [0.000, 1.000], mean observation: 0.132 [-1.365, 2.274], mean_best_reward: --\n",
      "   298/100000: episode: 17, duration: 0.009s, episode steps: 15, steps per second: 1686, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.267 [0.000, 1.000], mean observation: 0.077 [-1.545, 2.383], mean_best_reward: --\n",
      "   311/100000: episode: 18, duration: 0.007s, episode steps: 13, steps per second: 1740, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.692 [0.000, 1.000], mean observation: -0.105 [-1.989, 1.169], mean_best_reward: --\n",
      "   325/100000: episode: 19, duration: 0.008s, episode steps: 14, steps per second: 1711, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.714 [0.000, 1.000], mean observation: -0.076 [-2.020, 1.205], mean_best_reward: --\n",
      "   351/100000: episode: 20, duration: 0.013s, episode steps: 26, steps per second: 1965, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: -0.058 [-1.307, 0.609], mean_best_reward: --\n",
      "   368/100000: episode: 21, duration: 0.009s, episode steps: 17, steps per second: 1828, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: 0.128 [-0.567, 0.974], mean_best_reward: --\n",
      "   385/100000: episode: 22, duration: 0.012s, episode steps: 17, steps per second: 1472, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.235 [0.000, 1.000], mean observation: 0.068 [-1.769, 2.724], mean_best_reward: --\n",
      "   402/100000: episode: 23, duration: 0.010s, episode steps: 17, steps per second: 1735, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.647 [0.000, 1.000], mean observation: -0.067 [-1.730, 1.024], mean_best_reward: --\n",
      "   416/100000: episode: 24, duration: 0.016s, episode steps: 14, steps per second: 901, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.357 [0.000, 1.000], mean observation: 0.117 [-0.973, 1.745], mean_best_reward: --\n",
      "   449/100000: episode: 25, duration: 0.017s, episode steps: 33, steps per second: 1889, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: 0.042 [-0.625, 1.452], mean_best_reward: --\n",
      "   470/100000: episode: 26, duration: 0.011s, episode steps: 21, steps per second: 1970, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: 0.107 [-0.790, 1.798], mean_best_reward: --\n",
      "   481/100000: episode: 27, duration: 0.007s, episode steps: 11, steps per second: 1578, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.134 [-2.330, 1.365], mean_best_reward: --\n",
      "   493/100000: episode: 28, duration: 0.007s, episode steps: 12, steps per second: 1700, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.120 [-1.812, 1.126], mean_best_reward: --\n",
      "   515/100000: episode: 29, duration: 0.012s, episode steps: 22, steps per second: 1805, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.682 [0.000, 1.000], mean observation: -0.019 [-2.602, 1.799], mean_best_reward: --\n",
      "   533/100000: episode: 30, duration: 0.009s, episode steps: 18, steps per second: 2063, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.073 [-1.133, 1.946], mean_best_reward: --\n",
      "   543/100000: episode: 31, duration: 0.006s, episode steps: 10, steps per second: 1629, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.127 [-1.985, 3.032], mean_best_reward: --\n",
      "   554/100000: episode: 32, duration: 0.007s, episode steps: 11, steps per second: 1528, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.182 [0.000, 1.000], mean observation: 0.109 [-1.421, 2.355], mean_best_reward: --\n",
      "   564/100000: episode: 33, duration: 0.007s, episode steps: 10, steps per second: 1483, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.900 [0.000, 1.000], mean observation: -0.130 [-2.551, 1.590], mean_best_reward: --\n",
      "   575/100000: episode: 34, duration: 0.007s, episode steps: 11, steps per second: 1553, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.182 [0.000, 1.000], mean observation: 0.139 [-1.325, 2.327], mean_best_reward: --\n",
      "   595/100000: episode: 35, duration: 0.011s, episode steps: 20, steps per second: 1786, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.078 [-1.525, 0.774], mean_best_reward: --\n",
      "   615/100000: episode: 36, duration: 0.009s, episode steps: 20, steps per second: 2153, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.087 [-1.785, 0.967], mean_best_reward: --\n",
      "   629/100000: episode: 37, duration: 0.008s, episode steps: 14, steps per second: 1736, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.143 [0.000, 1.000], mean observation: 0.101 [-1.937, 3.023], mean_best_reward: --\n",
      "   648/100000: episode: 38, duration: 0.010s, episode steps: 19, steps per second: 1925, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.263 [0.000, 1.000], mean observation: 0.070 [-1.741, 2.811], mean_best_reward: --\n",
      "   661/100000: episode: 39, duration: 0.007s, episode steps: 13, steps per second: 1908, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.154 [0.000, 1.000], mean observation: 0.101 [-1.764, 2.781], mean_best_reward: --\n",
      "   684/100000: episode: 40, duration: 0.013s, episode steps: 23, steps per second: 1838, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.522 [0.000, 1.000], mean observation: -0.087 [-1.068, 0.581], mean_best_reward: --\n",
      "   705/100000: episode: 41, duration: 0.010s, episode steps: 21, steps per second: 2072, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.524 [0.000, 1.000], mean observation: 0.108 [-0.406, 1.051], mean_best_reward: --\n",
      "   717/100000: episode: 42, duration: 0.007s, episode steps: 12, steps per second: 1701, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.167 [0.000, 1.000], mean observation: 0.094 [-1.616, 2.549], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   730/100000: episode: 43, duration: 0.008s, episode steps: 13, steps per second: 1676, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.846 [0.000, 1.000], mean observation: -0.072 [-2.654, 1.795], mean_best_reward: --\n",
      "   740/100000: episode: 44, duration: 0.006s, episode steps: 10, steps per second: 1558, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.900 [0.000, 1.000], mean observation: -0.128 [-2.587, 1.608], mean_best_reward: --\n",
      "   756/100000: episode: 45, duration: 0.015s, episode steps: 16, steps per second: 1052, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.812 [0.000, 1.000], mean observation: -0.067 [-3.029, 1.994], mean_best_reward: --\n",
      "   770/100000: episode: 46, duration: 0.008s, episode steps: 14, steps per second: 1790, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.857 [0.000, 1.000], mean observation: -0.066 [-2.985, 1.988], mean_best_reward: --\n",
      "   790/100000: episode: 47, duration: 0.011s, episode steps: 20, steps per second: 1763, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.068 [-1.197, 0.821], mean_best_reward: --\n",
      "   921/100000: episode: 48, duration: 0.072s, episode steps: 131, steps per second: 1819, episode reward: 131.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.489 [0.000, 1.000], mean observation: -0.056 [-1.179, 1.223], mean_best_reward: --\n",
      "   934/100000: episode: 49, duration: 0.009s, episode steps: 13, steps per second: 1453, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.231 [0.000, 1.000], mean observation: 0.097 [-1.380, 2.258], mean_best_reward: --\n",
      "   979/100000: episode: 50, duration: 0.021s, episode steps: 45, steps per second: 2148, episode reward: 45.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.422 [0.000, 1.000], mean observation: -0.025 [-1.383, 1.979], mean_best_reward: --\n",
      "   988/100000: episode: 51, duration: 0.006s, episode steps: 9, steps per second: 1617, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 1.000 [1.000, 1.000], mean observation: -0.143 [-2.795, 1.795], mean_best_reward: --\n",
      "  1000/100000: episode: 52, duration: 0.007s, episode steps: 12, steps per second: 1810, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.167 [0.000, 1.000], mean observation: 0.103 [-1.791, 2.678], mean_best_reward: --\n",
      "  1014/100000: episode: 53, duration: 0.008s, episode steps: 14, steps per second: 1847, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.714 [0.000, 1.000], mean observation: -0.109 [-2.121, 1.144], mean_best_reward: --\n",
      "  1043/100000: episode: 54, duration: 0.014s, episode steps: 29, steps per second: 2031, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.379 [0.000, 1.000], mean observation: 0.004 [-1.747, 2.347], mean_best_reward: --\n",
      "  1060/100000: episode: 55, duration: 0.009s, episode steps: 17, steps per second: 1859, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.294 [0.000, 1.000], mean observation: 0.090 [-1.358, 2.368], mean_best_reward: --\n",
      "  1071/100000: episode: 56, duration: 0.006s, episode steps: 11, steps per second: 1756, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.182 [0.000, 1.000], mean observation: 0.107 [-1.594, 2.449], mean_best_reward: --\n",
      "  1107/100000: episode: 57, duration: 0.027s, episode steps: 36, steps per second: 1332, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.528 [0.000, 1.000], mean observation: -0.049 [-1.349, 0.592], mean_best_reward: --\n",
      "  1119/100000: episode: 58, duration: 0.007s, episode steps: 12, steps per second: 1768, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.167 [0.000, 1.000], mean observation: 0.109 [-1.539, 2.542], mean_best_reward: --\n",
      "  1143/100000: episode: 59, duration: 0.015s, episode steps: 24, steps per second: 1567, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.085 [-0.497, 0.845], mean_best_reward: --\n",
      "  1174/100000: episode: 60, duration: 0.015s, episode steps: 31, steps per second: 2077, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.548 [0.000, 1.000], mean observation: -0.113 [-1.876, 0.587], mean_best_reward: --\n",
      "  1185/100000: episode: 61, duration: 0.006s, episode steps: 11, steps per second: 1818, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.182 [0.000, 1.000], mean observation: 0.112 [-1.387, 2.278], mean_best_reward: --\n",
      "  1205/100000: episode: 62, duration: 0.010s, episode steps: 20, steps per second: 2069, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.058 [-2.030, 1.370], mean_best_reward: --\n",
      "  1217/100000: episode: 63, duration: 0.006s, episode steps: 12, steps per second: 1855, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.111 [-1.802, 1.028], mean_best_reward: --\n",
      "  1236/100000: episode: 64, duration: 0.011s, episode steps: 19, steps per second: 1778, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.263 [0.000, 1.000], mean observation: 0.081 [-1.720, 2.826], mean_best_reward: --\n",
      "  1246/100000: episode: 65, duration: 0.008s, episode steps: 10, steps per second: 1238, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.900 [0.000, 1.000], mean observation: -0.131 [-2.538, 1.553], mean_best_reward: --\n",
      "  1271/100000: episode: 66, duration: 0.024s, episode steps: 25, steps per second: 1038, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.101 [-0.897, 0.414], mean_best_reward: --\n",
      "  1284/100000: episode: 67, duration: 0.022s, episode steps: 13, steps per second: 597, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: -0.116 [-1.267, 0.780], mean_best_reward: --\n",
      "  1294/100000: episode: 68, duration: 0.016s, episode steps: 10, steps per second: 620, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.100 [0.000, 1.000], mean observation: 0.131 [-1.546, 2.555], mean_best_reward: --\n",
      "  1306/100000: episode: 69, duration: 0.013s, episode steps: 12, steps per second: 959, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.122 [-2.040, 1.194], mean_best_reward: --\n",
      "  1318/100000: episode: 70, duration: 0.019s, episode steps: 12, steps per second: 619, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.167 [0.000, 1.000], mean observation: 0.127 [-1.551, 2.505], mean_best_reward: --\n",
      "  1326/100000: episode: 71, duration: 0.010s, episode steps: 8, steps per second: 764, episode reward: 8.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.125 [0.000, 1.000], mean observation: 0.137 [-1.415, 2.186], mean_best_reward: --\n",
      "  1346/100000: episode: 72, duration: 0.024s, episode steps: 20, steps per second: 828, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.550 [0.000, 1.000], mean observation: -0.054 [-1.264, 0.816], mean_best_reward: --\n",
      "  1397/100000: episode: 73, duration: 0.047s, episode steps: 51, steps per second: 1074, episode reward: 51.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.627 [0.000, 1.000], mean observation: 0.044 [-3.052, 2.456], mean_best_reward: --\n",
      "  1408/100000: episode: 74, duration: 0.015s, episode steps: 11, steps per second: 751, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.273 [0.000, 1.000], mean observation: 0.141 [-0.953, 1.801], mean_best_reward: --\n",
      "  1417/100000: episode: 75, duration: 0.015s, episode steps: 9, steps per second: 585, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.149 [-1.740, 2.796], mean_best_reward: --\n",
      "  1438/100000: episode: 76, duration: 0.012s, episode steps: 21, steps per second: 1690, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.091 [-1.522, 2.486], mean_best_reward: --\n",
      "  1447/100000: episode: 77, duration: 0.016s, episode steps: 9, steps per second: 559, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.889 [0.000, 1.000], mean observation: -0.151 [-2.333, 1.399], mean_best_reward: --\n",
      "  1465/100000: episode: 78, duration: 0.014s, episode steps: 18, steps per second: 1296, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.778 [0.000, 1.000], mean observation: -0.053 [-2.998, 1.993], mean_best_reward: --\n",
      "  1478/100000: episode: 79, duration: 0.007s, episode steps: 13, steps per second: 1762, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.231 [0.000, 1.000], mean observation: 0.108 [-1.339, 2.284], mean_best_reward: --\n",
      "  1489/100000: episode: 80, duration: 0.006s, episode steps: 11, steps per second: 1813, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.121 [-2.270, 1.416], mean_best_reward: --\n",
      "  1503/100000: episode: 81, duration: 0.007s, episode steps: 14, steps per second: 1898, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.286 [0.000, 1.000], mean observation: 0.114 [-1.171, 2.104], mean_best_reward: --\n",
      "  1515/100000: episode: 82, duration: 0.006s, episode steps: 12, steps per second: 1856, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.250 [0.000, 1.000], mean observation: 0.110 [-1.136, 1.944], mean_best_reward: --\n",
      "  1567/100000: episode: 83, duration: 0.022s, episode steps: 52, steps per second: 2371, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.481 [0.000, 1.000], mean observation: 0.023 [-0.877, 1.213], mean_best_reward: --\n",
      "  1579/100000: episode: 84, duration: 0.007s, episode steps: 12, steps per second: 1792, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.167 [0.000, 1.000], mean observation: 0.116 [-1.524, 2.545], mean_best_reward: --\n",
      "  1590/100000: episode: 85, duration: 0.006s, episode steps: 11, steps per second: 1805, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.118 [-2.257, 1.363], mean_best_reward: --\n",
      "  1604/100000: episode: 86, duration: 0.007s, episode steps: 14, steps per second: 1886, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.357 [0.000, 1.000], mean observation: 0.104 [-0.977, 1.732], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1617/100000: episode: 87, duration: 0.009s, episode steps: 13, steps per second: 1421, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.154 [0.000, 1.000], mean observation: 0.123 [-1.714, 2.788], mean_best_reward: --\n",
      "  1638/100000: episode: 88, duration: 0.013s, episode steps: 21, steps per second: 1644, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.571 [0.000, 1.000], mean observation: -0.088 [-1.778, 0.954], mean_best_reward: --\n",
      "  1655/100000: episode: 89, duration: 0.013s, episode steps: 17, steps per second: 1331, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.647 [0.000, 1.000], mean observation: -0.076 [-1.733, 0.962], mean_best_reward: --\n",
      "  1667/100000: episode: 90, duration: 0.009s, episode steps: 12, steps per second: 1383, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.833 [0.000, 1.000], mean observation: -0.133 [-2.673, 1.612], mean_best_reward: --\n",
      "  1677/100000: episode: 91, duration: 0.006s, episode steps: 10, steps per second: 1632, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.900 [0.000, 1.000], mean observation: -0.124 [-2.623, 1.618], mean_best_reward: --\n",
      "  1691/100000: episode: 92, duration: 0.007s, episode steps: 14, steps per second: 1891, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.571 [0.000, 1.000], mean observation: -0.103 [-1.258, 0.760], mean_best_reward: --\n",
      "  1700/100000: episode: 93, duration: 0.006s, episode steps: 9, steps per second: 1634, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.778 [0.000, 1.000], mean observation: -0.138 [-1.941, 1.175], mean_best_reward: --\n",
      "  1714/100000: episode: 94, duration: 0.007s, episode steps: 14, steps per second: 1960, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.286 [0.000, 1.000], mean observation: 0.090 [-1.394, 2.207], mean_best_reward: --\n",
      "  1727/100000: episode: 95, duration: 0.007s, episode steps: 13, steps per second: 1900, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.846 [0.000, 1.000], mean observation: -0.092 [-2.735, 1.796], mean_best_reward: --\n",
      "  1739/100000: episode: 96, duration: 0.007s, episode steps: 12, steps per second: 1827, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.833 [0.000, 1.000], mean observation: -0.112 [-2.606, 1.616], mean_best_reward: --\n",
      "  1748/100000: episode: 97, duration: 0.005s, episode steps: 9, steps per second: 1670, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.778 [0.000, 1.000], mean observation: -0.139 [-1.836, 1.160], mean_best_reward: --\n",
      "  1762/100000: episode: 98, duration: 0.007s, episode steps: 14, steps per second: 1927, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.857 [0.000, 1.000], mean observation: -0.100 [-3.033, 1.983], mean_best_reward: --\n",
      "  1781/100000: episode: 99, duration: 0.009s, episode steps: 19, steps per second: 2111, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: 0.096 [-0.596, 1.129], mean_best_reward: --\n",
      "  1796/100000: episode: 100, duration: 0.008s, episode steps: 15, steps per second: 1968, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.533 [0.000, 1.000], mean observation: -0.117 [-1.657, 0.941], mean_best_reward: --\n",
      "  1810/100000: episode: 101, duration: 0.008s, episode steps: 14, steps per second: 1818, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.643 [0.000, 1.000], mean observation: -0.119 [-1.611, 0.805], mean_best_reward: --\n",
      "  1827/100000: episode: 102, duration: 0.009s, episode steps: 17, steps per second: 1837, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.294 [0.000, 1.000], mean observation: 0.052 [-1.569, 2.287], mean_best_reward: --\n",
      "  1845/100000: episode: 103, duration: 0.009s, episode steps: 18, steps per second: 2044, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.556 [0.000, 1.000], mean observation: -0.088 [-1.376, 0.615], mean_best_reward: --\n",
      "  1857/100000: episode: 104, duration: 0.007s, episode steps: 12, steps per second: 1821, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.250 [0.000, 1.000], mean observation: 0.107 [-1.180, 2.056], mean_best_reward: --\n",
      "  1870/100000: episode: 105, duration: 0.007s, episode steps: 13, steps per second: 1853, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.692 [0.000, 1.000], mean observation: -0.119 [-1.864, 0.974], mean_best_reward: --\n",
      "  1879/100000: episode: 106, duration: 0.006s, episode steps: 9, steps per second: 1534, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 1.000 [1.000, 1.000], mean observation: -0.161 [-2.852, 1.755], mean_best_reward: --\n",
      "  1908/100000: episode: 107, duration: 0.014s, episode steps: 29, steps per second: 2135, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.379 [0.000, 1.000], mean observation: 0.046 [-1.355, 2.207], mean_best_reward: --\n",
      "  1920/100000: episode: 108, duration: 0.007s, episode steps: 12, steps per second: 1651, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.130 [-1.129, 1.818], mean_best_reward: --\n",
      "  1931/100000: episode: 109, duration: 0.006s, episode steps: 11, steps per second: 1695, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 1.000 [1.000, 1.000], mean observation: -0.130 [-3.285, 2.182], mean_best_reward: --\n",
      "  1946/100000: episode: 110, duration: 0.008s, episode steps: 15, steps per second: 1893, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.098 [-1.916, 1.178], mean_best_reward: --\n",
      "  1958/100000: episode: 111, duration: 0.007s, episode steps: 12, steps per second: 1799, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.250 [0.000, 1.000], mean observation: 0.095 [-1.190, 1.983], mean_best_reward: --\n",
      "  1967/100000: episode: 112, duration: 0.007s, episode steps: 9, steps per second: 1253, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 1.000 [1.000, 1.000], mean observation: -0.152 [-2.866, 1.782], mean_best_reward: --\n",
      "  1980/100000: episode: 113, duration: 0.011s, episode steps: 13, steps per second: 1136, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.769 [0.000, 1.000], mean observation: -0.091 [-2.278, 1.400], mean_best_reward: --\n",
      "  1988/100000: episode: 114, duration: 0.008s, episode steps: 8, steps per second: 973, episode reward: 8.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.127 [-1.601, 2.540], mean_best_reward: --\n",
      "  2008/100000: episode: 115, duration: 0.013s, episode steps: 20, steps per second: 1534, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.086 [-1.734, 0.951], mean_best_reward: --\n",
      "  2034/100000: episode: 116, duration: 0.013s, episode steps: 26, steps per second: 1979, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.577 [0.000, 1.000], mean observation: -0.093 [-1.918, 0.946], mean_best_reward: --\n",
      "  2049/100000: episode: 117, duration: 0.008s, episode steps: 15, steps per second: 1978, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.267 [0.000, 1.000], mean observation: 0.086 [-1.364, 2.210], mean_best_reward: --\n",
      "  2063/100000: episode: 118, duration: 0.007s, episode steps: 14, steps per second: 1932, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.571 [0.000, 1.000], mean observation: -0.109 [-1.253, 0.576], mean_best_reward: --\n",
      "  2086/100000: episode: 119, duration: 0.011s, episode steps: 23, steps per second: 2141, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.435 [0.000, 1.000], mean observation: 0.030 [-0.963, 1.386], mean_best_reward: --\n",
      "  2117/100000: episode: 120, duration: 0.014s, episode steps: 31, steps per second: 2236, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.323 [0.000, 1.000], mean observation: -0.021 [-2.080, 2.744], mean_best_reward: --\n",
      "  2128/100000: episode: 121, duration: 0.006s, episode steps: 11, steps per second: 1806, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.091 [0.000, 1.000], mean observation: 0.090 [-1.796, 2.741], mean_best_reward: --\n",
      "  2145/100000: episode: 122, duration: 0.008s, episode steps: 17, steps per second: 2005, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.647 [0.000, 1.000], mean observation: -0.073 [-1.766, 0.975], mean_best_reward: --\n",
      "  2158/100000: episode: 123, duration: 0.016s, episode steps: 13, steps per second: 790, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.308 [0.000, 1.000], mean observation: 0.080 [-1.404, 2.035], mean_best_reward: --\n",
      "  2167/100000: episode: 124, duration: 0.006s, episode steps: 9, steps per second: 1480, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.222 [0.000, 1.000], mean observation: 0.128 [-0.985, 1.757], mean_best_reward: --\n",
      "  2199/100000: episode: 125, duration: 0.035s, episode steps: 32, steps per second: 905, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.531 [0.000, 1.000], mean observation: -0.026 [-1.332, 0.965], mean_best_reward: --\n",
      "  2214/100000: episode: 126, duration: 0.016s, episode steps: 15, steps per second: 960, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.267 [0.000, 1.000], mean observation: 0.065 [-1.339, 2.080], mean_best_reward: --\n",
      "  2225/100000: episode: 127, duration: 0.011s, episode steps: 11, steps per second: 991, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.636 [0.000, 1.000], mean observation: -0.101 [-1.689, 1.018], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2249/100000: episode: 128, duration: 0.029s, episode steps: 24, steps per second: 823, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.375 [0.000, 1.000], mean observation: 0.051 [-1.509, 2.254], mean_best_reward: --\n",
      "  2267/100000: episode: 129, duration: 0.016s, episode steps: 18, steps per second: 1161, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.611 [0.000, 1.000], mean observation: -0.077 [-1.442, 0.957], mean_best_reward: --\n",
      "  2282/100000: episode: 130, duration: 0.008s, episode steps: 15, steps per second: 1965, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.800 [0.000, 1.000], mean observation: -0.079 [-2.725, 1.737], mean_best_reward: --\n",
      "  2293/100000: episode: 131, duration: 0.010s, episode steps: 11, steps per second: 1054, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.131 [-2.259, 1.355], mean_best_reward: --\n",
      "  2311/100000: episode: 132, duration: 0.011s, episode steps: 18, steps per second: 1572, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.389 [0.000, 1.000], mean observation: 0.116 [-0.978, 1.874], mean_best_reward: --\n",
      "  2323/100000: episode: 133, duration: 0.007s, episode steps: 12, steps per second: 1843, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.111 [-2.207, 1.402], mean_best_reward: --\n",
      "  2333/100000: episode: 134, duration: 0.006s, episode steps: 10, steps per second: 1740, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.200 [0.000, 1.000], mean observation: 0.124 [-1.348, 2.158], mean_best_reward: --\n",
      "  2342/100000: episode: 135, duration: 0.006s, episode steps: 9, steps per second: 1480, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.889 [0.000, 1.000], mean observation: -0.156 [-2.334, 1.359], mean_best_reward: --\n",
      "  2354/100000: episode: 136, duration: 0.007s, episode steps: 12, steps per second: 1828, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.098 [-1.026, 1.693], mean_best_reward: --\n",
      "  2369/100000: episode: 137, duration: 0.008s, episode steps: 15, steps per second: 1950, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.733 [0.000, 1.000], mean observation: -0.119 [-2.465, 1.384], mean_best_reward: --\n",
      "  2396/100000: episode: 138, duration: 0.013s, episode steps: 27, steps per second: 2040, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.481 [0.000, 1.000], mean observation: 0.074 [-0.764, 1.314], mean_best_reward: --\n",
      "  2405/100000: episode: 139, duration: 0.006s, episode steps: 9, steps per second: 1408, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.145 [-1.806, 2.836], mean_best_reward: --\n",
      "  2417/100000: episode: 140, duration: 0.008s, episode steps: 12, steps per second: 1552, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.125 [-2.064, 1.186], mean_best_reward: --\n",
      "  2427/100000: episode: 141, duration: 0.006s, episode steps: 10, steps per second: 1617, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.900 [0.000, 1.000], mean observation: -0.134 [-2.511, 1.546], mean_best_reward: --\n",
      "  2437/100000: episode: 142, duration: 0.006s, episode steps: 10, steps per second: 1605, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.800 [0.000, 1.000], mean observation: -0.150 [-2.314, 1.362], mean_best_reward: --\n",
      "  2449/100000: episode: 143, duration: 0.007s, episode steps: 12, steps per second: 1675, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.140 [-0.942, 1.784], mean_best_reward: --\n",
      "  2459/100000: episode: 144, duration: 0.006s, episode steps: 10, steps per second: 1604, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.800 [0.000, 1.000], mean observation: -0.122 [-1.902, 1.154], mean_best_reward: --\n",
      "  2471/100000: episode: 145, duration: 0.008s, episode steps: 12, steps per second: 1546, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.917 [0.000, 1.000], mean observation: -0.105 [-3.019, 1.974], mean_best_reward: --\n",
      "  2481/100000: episode: 146, duration: 0.006s, episode steps: 10, steps per second: 1578, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.800 [0.000, 1.000], mean observation: -0.151 [-2.288, 1.354], mean_best_reward: --\n",
      "  2500/100000: episode: 147, duration: 0.010s, episode steps: 19, steps per second: 1913, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.526 [0.000, 1.000], mean observation: -0.105 [-1.025, 0.557], mean_best_reward: --\n",
      "  2522/100000: episode: 148, duration: 0.011s, episode steps: 22, steps per second: 1970, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.409 [0.000, 1.000], mean observation: 0.083 [-0.794, 1.557], mean_best_reward: --\n",
      "  2537/100000: episode: 149, duration: 0.008s, episode steps: 15, steps per second: 1902, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.133 [0.000, 1.000], mean observation: 0.095 [-2.141, 3.250], mean_best_reward: --\n",
      "  2555/100000: episode: 150, duration: 0.009s, episode steps: 18, steps per second: 2043, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.444 [0.000, 1.000], mean observation: 0.069 [-0.792, 1.185], mean_best_reward: --\n",
      "  2570/100000: episode: 151, duration: 0.008s, episode steps: 15, steps per second: 1869, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.400 [0.000, 1.000], mean observation: 0.097 [-0.791, 1.449], mean_best_reward: 91.500000\n",
      "  2588/100000: episode: 152, duration: 0.011s, episode steps: 18, steps per second: 1656, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.101 [-2.244, 1.327], mean_best_reward: --\n",
      "  2668/100000: episode: 153, duration: 0.042s, episode steps: 80, steps per second: 1895, episode reward: 80.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.525 [0.000, 1.000], mean observation: -0.054 [-1.902, 0.819], mean_best_reward: --\n",
      "  2684/100000: episode: 154, duration: 0.009s, episode steps: 16, steps per second: 1794, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.375 [0.000, 1.000], mean observation: 0.083 [-1.001, 1.496], mean_best_reward: --\n",
      "  2736/100000: episode: 155, duration: 0.024s, episode steps: 52, steps per second: 2178, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.385 [0.000, 1.000], mean observation: -0.043 [-2.301, 2.939], mean_best_reward: --\n",
      "  2748/100000: episode: 156, duration: 0.011s, episode steps: 12, steps per second: 1116, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.583 [0.000, 1.000], mean observation: -0.107 [-1.607, 0.963], mean_best_reward: --\n",
      "  2766/100000: episode: 157, duration: 0.013s, episode steps: 18, steps per second: 1408, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.389 [0.000, 1.000], mean observation: 0.071 [-1.009, 1.784], mean_best_reward: --\n",
      "  2792/100000: episode: 158, duration: 0.013s, episode steps: 26, steps per second: 2059, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.346 [0.000, 1.000], mean observation: 0.024 [-1.550, 2.308], mean_best_reward: --\n",
      "  2801/100000: episode: 159, duration: 0.006s, episode steps: 9, steps per second: 1543, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.222 [0.000, 1.000], mean observation: 0.133 [-0.956, 1.733], mean_best_reward: --\n",
      "  2819/100000: episode: 160, duration: 0.010s, episode steps: 18, steps per second: 1886, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.444 [0.000, 1.000], mean observation: -0.092 [-0.983, 0.641], mean_best_reward: --\n",
      "  2834/100000: episode: 161, duration: 0.008s, episode steps: 15, steps per second: 1819, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: 0.122 [-0.597, 0.996], mean_best_reward: --\n",
      "  2846/100000: episode: 162, duration: 0.007s, episode steps: 12, steps per second: 1768, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.250 [0.000, 1.000], mean observation: 0.127 [-1.161, 2.062], mean_best_reward: --\n",
      "  2856/100000: episode: 163, duration: 0.006s, episode steps: 10, steps per second: 1708, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.800 [0.000, 1.000], mean observation: -0.114 [-1.963, 1.140], mean_best_reward: --\n",
      "  2864/100000: episode: 164, duration: 0.005s, episode steps: 8, steps per second: 1690, episode reward: 8.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.125 [0.000, 1.000], mean observation: 0.158 [-1.348, 2.205], mean_best_reward: --\n",
      "  2884/100000: episode: 165, duration: 0.010s, episode steps: 20, steps per second: 2076, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.350 [0.000, 1.000], mean observation: 0.081 [-1.215, 2.228], mean_best_reward: --\n",
      "  2904/100000: episode: 166, duration: 0.009s, episode steps: 20, steps per second: 2140, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.300 [0.000, 1.000], mean observation: 0.068 [-1.617, 2.567], mean_best_reward: --\n",
      "  2914/100000: episode: 167, duration: 0.006s, episode steps: 10, steps per second: 1710, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.100 [0.000, 1.000], mean observation: 0.117 [-1.555, 2.514], mean_best_reward: --\n",
      "  2925/100000: episode: 168, duration: 0.006s, episode steps: 11, steps per second: 1796, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.727 [0.000, 1.000], mean observation: -0.107 [-2.178, 1.412], mean_best_reward: --\n",
      "  2942/100000: episode: 169, duration: 0.008s, episode steps: 17, steps per second: 2077, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.294 [0.000, 1.000], mean observation: 0.071 [-1.381, 2.257], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2953/100000: episode: 170, duration: 0.007s, episode steps: 11, steps per second: 1571, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.091 [0.000, 1.000], mean observation: 0.140 [-1.742, 2.833], mean_best_reward: --\n",
      "  2972/100000: episode: 171, duration: 0.013s, episode steps: 19, steps per second: 1415, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.368 [0.000, 1.000], mean observation: 0.057 [-1.214, 1.912], mean_best_reward: --\n",
      "  2983/100000: episode: 172, duration: 0.010s, episode steps: 11, steps per second: 1103, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.273 [0.000, 1.000], mean observation: 0.151 [-1.334, 2.216], mean_best_reward: --\n",
      "  2994/100000: episode: 173, duration: 0.010s, episode steps: 11, steps per second: 1054, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.727 [0.000, 1.000], mean observation: -0.118 [-1.864, 1.035], mean_best_reward: --\n",
      "  3026/100000: episode: 174, duration: 0.015s, episode steps: 32, steps per second: 2074, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.531 [0.000, 1.000], mean observation: 0.057 [-0.807, 0.978], mean_best_reward: --\n",
      "  3064/100000: episode: 175, duration: 0.018s, episode steps: 38, steps per second: 2069, episode reward: 38.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.395 [0.000, 1.000], mean observation: -0.056 [-1.885, 2.047], mean_best_reward: --\n",
      "  3074/100000: episode: 176, duration: 0.006s, episode steps: 10, steps per second: 1601, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.800 [0.000, 1.000], mean observation: -0.144 [-2.041, 1.159], mean_best_reward: --\n",
      "  3088/100000: episode: 177, duration: 0.008s, episode steps: 14, steps per second: 1860, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.214 [0.000, 1.000], mean observation: 0.112 [-1.741, 2.708], mean_best_reward: --\n",
      "  3116/100000: episode: 178, duration: 0.012s, episode steps: 28, steps per second: 2243, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.061 [-0.911, 0.574], mean_best_reward: --\n",
      "  3134/100000: episode: 179, duration: 0.009s, episode steps: 18, steps per second: 1974, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.070 [-2.192, 1.367], mean_best_reward: --\n",
      "  3148/100000: episode: 180, duration: 0.007s, episode steps: 14, steps per second: 1918, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.214 [0.000, 1.000], mean observation: 0.086 [-1.548, 2.381], mean_best_reward: --\n",
      "  3161/100000: episode: 181, duration: 0.007s, episode steps: 13, steps per second: 1862, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.154 [0.000, 1.000], mean observation: 0.100 [-1.733, 2.760], mean_best_reward: --\n",
      "  3192/100000: episode: 182, duration: 0.014s, episode steps: 31, steps per second: 2263, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.387 [0.000, 1.000], mean observation: 0.015 [-1.405, 2.188], mean_best_reward: --\n",
      "  3211/100000: episode: 183, duration: 0.010s, episode steps: 19, steps per second: 1929, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.368 [0.000, 1.000], mean observation: 0.088 [-1.008, 1.858], mean_best_reward: --\n",
      "  3247/100000: episode: 184, duration: 0.016s, episode steps: 36, steps per second: 2230, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: -0.095 [-2.353, 2.705], mean_best_reward: --\n",
      "  3259/100000: episode: 185, duration: 0.007s, episode steps: 12, steps per second: 1831, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.097 [-1.962, 1.195], mean_best_reward: --\n",
      "  3273/100000: episode: 186, duration: 0.007s, episode steps: 14, steps per second: 1943, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.286 [0.000, 1.000], mean observation: 0.090 [-1.186, 2.083], mean_best_reward: --\n",
      "  3285/100000: episode: 187, duration: 0.007s, episode steps: 12, steps per second: 1838, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.120 [-2.071, 1.189], mean_best_reward: --\n",
      "  3297/100000: episode: 188, duration: 0.007s, episode steps: 12, steps per second: 1842, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.110 [-1.022, 1.616], mean_best_reward: --\n",
      "  3316/100000: episode: 189, duration: 0.009s, episode steps: 19, steps per second: 2051, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.737 [0.000, 1.000], mean observation: -0.049 [-2.710, 1.739], mean_best_reward: --\n",
      "  3329/100000: episode: 190, duration: 0.010s, episode steps: 13, steps per second: 1276, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.231 [0.000, 1.000], mean observation: 0.089 [-1.349, 2.225], mean_best_reward: --\n",
      "  3345/100000: episode: 191, duration: 0.013s, episode steps: 16, steps per second: 1202, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.312 [0.000, 1.000], mean observation: 0.092 [-1.182, 2.082], mean_best_reward: --\n",
      "  3365/100000: episode: 192, duration: 0.014s, episode steps: 20, steps per second: 1412, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.650 [0.000, 1.000], mean observation: -0.077 [-2.145, 1.196], mean_best_reward: --\n",
      "  3376/100000: episode: 193, duration: 0.007s, episode steps: 11, steps per second: 1624, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.126 [-2.332, 1.359], mean_best_reward: --\n",
      "  3387/100000: episode: 194, duration: 0.007s, episode steps: 11, steps per second: 1692, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.182 [0.000, 1.000], mean observation: 0.113 [-1.398, 2.282], mean_best_reward: --\n",
      "  3414/100000: episode: 195, duration: 0.013s, episode steps: 27, steps per second: 2018, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.370 [0.000, 1.000], mean observation: 0.047 [-1.325, 2.210], mean_best_reward: --\n",
      "  3426/100000: episode: 196, duration: 0.007s, episode steps: 12, steps per second: 1644, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.250 [0.000, 1.000], mean observation: 0.122 [-1.135, 2.049], mean_best_reward: --\n",
      "  3437/100000: episode: 197, duration: 0.006s, episode steps: 11, steps per second: 1755, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.132 [-2.314, 1.352], mean_best_reward: --\n",
      "  3454/100000: episode: 198, duration: 0.008s, episode steps: 17, steps per second: 2028, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.529 [0.000, 1.000], mean observation: -0.071 [-1.235, 0.756], mean_best_reward: --\n",
      "  3478/100000: episode: 199, duration: 0.012s, episode steps: 24, steps per second: 2043, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.102 [-0.567, 1.115], mean_best_reward: --\n",
      "  3490/100000: episode: 200, duration: 0.007s, episode steps: 12, steps per second: 1757, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.250 [0.000, 1.000], mean observation: 0.121 [-1.210, 2.004], mean_best_reward: --\n",
      "  3501/100000: episode: 201, duration: 0.006s, episode steps: 11, steps per second: 1698, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.091 [0.000, 1.000], mean observation: 0.142 [-1.734, 2.869], mean_best_reward: 48.500000\n",
      "  3515/100000: episode: 202, duration: 0.007s, episode steps: 14, steps per second: 1947, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.286 [0.000, 1.000], mean observation: 0.094 [-1.229, 2.016], mean_best_reward: --\n",
      "  3525/100000: episode: 203, duration: 0.006s, episode steps: 10, steps per second: 1680, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.300 [0.000, 1.000], mean observation: 0.121 [-0.989, 1.663], mean_best_reward: --\n",
      "  3688/100000: episode: 204, duration: 0.067s, episode steps: 163, steps per second: 2446, episode reward: 163.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.491 [0.000, 1.000], mean observation: -0.078 [-1.409, 1.194], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3723/100000: episode: 205, duration: 0.016s, episode steps: 35, steps per second: 2210, episode reward: 35.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.543 [0.000, 1.000], mean observation: -0.026 [-1.362, 0.767], mean_best_reward: --\n",
      "  3735/100000: episode: 206, duration: 0.008s, episode steps: 12, steps per second: 1503, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.833 [0.000, 1.000], mean observation: -0.098 [-2.542, 1.615], mean_best_reward: --\n",
      "  3744/100000: episode: 207, duration: 0.009s, episode steps: 9, steps per second: 1037, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.111 [0.000, 1.000], mean observation: 0.142 [-1.393, 2.240], mean_best_reward: --\n",
      "  3765/100000: episode: 208, duration: 0.013s, episode steps: 21, steps per second: 1580, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: 0.075 [-0.990, 1.667], mean_best_reward: --\n",
      "  3777/100000: episode: 209, duration: 0.008s, episode steps: 12, steps per second: 1451, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.083 [0.000, 1.000], mean observation: 0.131 [-1.909, 3.022], mean_best_reward: --\n",
      "  3788/100000: episode: 210, duration: 0.007s, episode steps: 11, steps per second: 1594, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.273 [0.000, 1.000], mean observation: 0.110 [-1.036, 1.791], mean_best_reward: --\n",
      "  3799/100000: episode: 211, duration: 0.007s, episode steps: 11, steps per second: 1652, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.125 [-2.304, 1.338], mean_best_reward: --\n",
      "  3831/100000: episode: 212, duration: 0.015s, episode steps: 32, steps per second: 2114, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: -0.075 [-1.112, 0.737], mean_best_reward: --\n",
      "  3861/100000: episode: 213, duration: 0.014s, episode steps: 30, steps per second: 2219, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: 0.067 [-0.946, 1.535], mean_best_reward: --\n",
      "  3878/100000: episode: 214, duration: 0.008s, episode steps: 17, steps per second: 2056, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.412 [0.000, 1.000], mean observation: 0.090 [-0.771, 1.284], mean_best_reward: --\n",
      "  3889/100000: episode: 215, duration: 0.006s, episode steps: 11, steps per second: 1713, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.182 [0.000, 1.000], mean observation: 0.135 [-1.343, 2.260], mean_best_reward: --\n",
      "  3900/100000: episode: 216, duration: 0.006s, episode steps: 11, steps per second: 1780, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.364 [0.000, 1.000], mean observation: 0.125 [-0.788, 1.360], mean_best_reward: --\n",
      "  3911/100000: episode: 217, duration: 0.006s, episode steps: 11, steps per second: 1781, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.091 [0.000, 1.000], mean observation: 0.122 [-1.782, 2.814], mean_best_reward: --\n",
      "  3923/100000: episode: 218, duration: 0.007s, episode steps: 12, steps per second: 1826, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.100 [-1.217, 1.767], mean_best_reward: --\n",
      "  3938/100000: episode: 219, duration: 0.009s, episode steps: 15, steps per second: 1742, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.200 [0.000, 1.000], mean observation: 0.084 [-1.742, 2.716], mean_best_reward: --\n",
      "  3956/100000: episode: 220, duration: 0.012s, episode steps: 18, steps per second: 1556, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.722 [0.000, 1.000], mean observation: -0.078 [-2.592, 1.576], mean_best_reward: --\n",
      "  3966/100000: episode: 221, duration: 0.007s, episode steps: 10, steps per second: 1449, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.100 [0.000, 1.000], mean observation: 0.139 [-1.608, 2.606], mean_best_reward: --\n",
      "  3978/100000: episode: 222, duration: 0.007s, episode steps: 12, steps per second: 1746, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.167 [0.000, 1.000], mean observation: 0.106 [-1.582, 2.565], mean_best_reward: --\n",
      "  3995/100000: episode: 223, duration: 0.010s, episode steps: 17, steps per second: 1726, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.765 [0.000, 1.000], mean observation: -0.067 [-2.852, 1.805], mean_best_reward: --\n",
      "  4006/100000: episode: 224, duration: 0.007s, episode steps: 11, steps per second: 1690, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.091 [0.000, 1.000], mean observation: 0.121 [-1.785, 2.856], mean_best_reward: --\n",
      "  4021/100000: episode: 225, duration: 0.009s, episode steps: 15, steps per second: 1611, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.733 [0.000, 1.000], mean observation: -0.094 [-2.339, 1.425], mean_best_reward: --\n",
      "  4039/100000: episode: 226, duration: 0.009s, episode steps: 18, steps per second: 2096, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.108 [-1.190, 2.228], mean_best_reward: --\n",
      "  4055/100000: episode: 227, duration: 0.008s, episode steps: 16, steps per second: 1970, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.312 [0.000, 1.000], mean observation: 0.083 [-1.342, 2.162], mean_best_reward: --\n",
      "  4071/100000: episode: 228, duration: 0.011s, episode steps: 16, steps per second: 1443, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.438 [0.000, 1.000], mean observation: 0.089 [-0.990, 1.472], mean_best_reward: --\n",
      "  4083/100000: episode: 229, duration: 0.011s, episode steps: 12, steps per second: 1112, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.250 [0.000, 1.000], mean observation: 0.128 [-1.158, 1.977], mean_best_reward: --\n",
      "  4095/100000: episode: 230, duration: 0.010s, episode steps: 12, steps per second: 1201, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.083 [0.000, 1.000], mean observation: 0.091 [-1.991, 3.000], mean_best_reward: --\n",
      "  4108/100000: episode: 231, duration: 0.007s, episode steps: 13, steps per second: 1798, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.154 [0.000, 1.000], mean observation: 0.087 [-1.807, 2.688], mean_best_reward: --\n",
      "  4127/100000: episode: 232, duration: 0.010s, episode steps: 19, steps per second: 1953, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.789 [0.000, 1.000], mean observation: -0.034 [-3.191, 2.173], mean_best_reward: --\n",
      "  4138/100000: episode: 233, duration: 0.006s, episode steps: 11, steps per second: 1736, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.091 [0.000, 1.000], mean observation: 0.100 [-1.799, 2.693], mean_best_reward: --\n",
      "  4150/100000: episode: 234, duration: 0.007s, episode steps: 12, steps per second: 1703, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.833 [0.000, 1.000], mean observation: -0.097 [-2.456, 1.558], mean_best_reward: --\n",
      "  4161/100000: episode: 235, duration: 0.006s, episode steps: 11, steps per second: 1701, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.727 [0.000, 1.000], mean observation: -0.106 [-1.746, 1.005], mean_best_reward: --\n",
      "  4174/100000: episode: 236, duration: 0.008s, episode steps: 13, steps per second: 1715, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.308 [0.000, 1.000], mean observation: 0.106 [-1.037, 1.796], mean_best_reward: --\n",
      "  4215/100000: episode: 237, duration: 0.018s, episode steps: 41, steps per second: 2325, episode reward: 41.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.439 [0.000, 1.000], mean observation: 0.021 [-1.330, 1.880], mean_best_reward: --\n",
      "  4226/100000: episode: 238, duration: 0.006s, episode steps: 11, steps per second: 1859, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.182 [0.000, 1.000], mean observation: 0.105 [-1.420, 2.338], mean_best_reward: --\n",
      "  4236/100000: episode: 239, duration: 0.006s, episode steps: 10, steps per second: 1634, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 1.000 [1.000, 1.000], mean observation: -0.160 [-3.132, 1.924], mean_best_reward: --\n",
      "  4255/100000: episode: 240, duration: 0.010s, episode steps: 19, steps per second: 1891, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.316 [0.000, 1.000], mean observation: 0.043 [-1.360, 2.008], mean_best_reward: --\n",
      "  4269/100000: episode: 241, duration: 0.008s, episode steps: 14, steps per second: 1737, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.214 [0.000, 1.000], mean observation: 0.104 [-1.574, 2.534], mean_best_reward: --\n",
      "  4279/100000: episode: 242, duration: 0.006s, episode steps: 10, steps per second: 1710, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.800 [0.000, 1.000], mean observation: -0.143 [-2.009, 1.132], mean_best_reward: --\n",
      "  4294/100000: episode: 243, duration: 0.007s, episode steps: 15, steps per second: 2021, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.123 [-0.949, 1.820], mean_best_reward: --\n",
      "  4305/100000: episode: 244, duration: 0.006s, episode steps: 11, steps per second: 1767, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.091 [0.000, 1.000], mean observation: 0.104 [-1.800, 2.821], mean_best_reward: --\n",
      "  4326/100000: episode: 245, duration: 0.010s, episode steps: 21, steps per second: 2010, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: 0.066 [-0.839, 1.341], mean_best_reward: --\n",
      "  4336/100000: episode: 246, duration: 0.006s, episode steps: 10, steps per second: 1686, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.200 [0.000, 1.000], mean observation: 0.130 [-1.221, 2.041], mean_best_reward: --\n",
      "  4353/100000: episode: 247, duration: 0.009s, episode steps: 17, steps per second: 1895, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.647 [0.000, 1.000], mean observation: -0.091 [-1.850, 1.014], mean_best_reward: --\n",
      "  4372/100000: episode: 248, duration: 0.010s, episode steps: 19, steps per second: 1889, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.368 [0.000, 1.000], mean observation: 0.085 [-1.036, 1.936], mean_best_reward: --\n",
      "  4384/100000: episode: 249, duration: 0.007s, episode steps: 12, steps per second: 1683, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.144 [-2.132, 1.147], mean_best_reward: --\n",
      "  4399/100000: episode: 250, duration: 0.008s, episode steps: 15, steps per second: 1836, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.267 [0.000, 1.000], mean observation: 0.098 [-1.351, 2.216], mean_best_reward: --\n",
      "  4407/100000: episode: 251, duration: 0.006s, episode steps: 8, steps per second: 1444, episode reward: 8.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.162 [-1.557, 2.562], mean_best_reward: 109.500000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4479/100000: episode: 252, duration: 0.034s, episode steps: 72, steps per second: 2100, episode reward: 72.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.417 [0.000, 1.000], mean observation: -0.170 [-2.486, 2.573], mean_best_reward: --\n",
      "  4488/100000: episode: 253, duration: 0.008s, episode steps: 9, steps per second: 1185, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.182 [-1.715, 2.869], mean_best_reward: --\n",
      "  4501/100000: episode: 254, duration: 0.011s, episode steps: 13, steps per second: 1141, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.769 [0.000, 1.000], mean observation: -0.095 [-2.215, 1.366], mean_best_reward: --\n",
      "  4521/100000: episode: 255, duration: 0.013s, episode steps: 20, steps per second: 1494, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.550 [0.000, 1.000], mean observation: 0.096 [-0.749, 1.216], mean_best_reward: --\n",
      "  4531/100000: episode: 256, duration: 0.011s, episode steps: 10, steps per second: 920, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.100 [0.000, 1.000], mean observation: 0.137 [-1.535, 2.512], mean_best_reward: --\n",
      "  4554/100000: episode: 257, duration: 0.012s, episode steps: 23, steps per second: 1925, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.696 [0.000, 1.000], mean observation: 0.004 [-2.620, 1.974], mean_best_reward: --\n",
      "  4564/100000: episode: 258, duration: 0.006s, episode steps: 10, steps per second: 1677, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.900 [0.000, 1.000], mean observation: -0.134 [-2.500, 1.584], mean_best_reward: --\n",
      "  4579/100000: episode: 259, duration: 0.009s, episode steps: 15, steps per second: 1692, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.091 [-1.488, 0.785], mean_best_reward: --\n",
      "  4597/100000: episode: 260, duration: 0.010s, episode steps: 18, steps per second: 1815, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.098 [-1.219, 0.583], mean_best_reward: --\n",
      "  4608/100000: episode: 261, duration: 0.007s, episode steps: 11, steps per second: 1487, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.273 [0.000, 1.000], mean observation: 0.121 [-1.192, 1.901], mean_best_reward: --\n",
      "  4623/100000: episode: 262, duration: 0.009s, episode steps: 15, steps per second: 1735, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.096 [-1.680, 0.957], mean_best_reward: --\n",
      "  4652/100000: episode: 263, duration: 0.016s, episode steps: 29, steps per second: 1797, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.414 [0.000, 1.000], mean observation: 0.106 [-1.017, 2.317], mean_best_reward: --\n",
      "  4661/100000: episode: 264, duration: 0.007s, episode steps: 9, steps per second: 1344, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.889 [0.000, 1.000], mean observation: -0.152 [-2.338, 1.356], mean_best_reward: --\n",
      "  4670/100000: episode: 265, duration: 0.006s, episode steps: 9, steps per second: 1578, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.222 [0.000, 1.000], mean observation: 0.141 [-1.420, 2.180], mean_best_reward: --\n",
      "  4687/100000: episode: 266, duration: 0.010s, episode steps: 17, steps per second: 1673, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: 0.076 [-0.783, 1.315], mean_best_reward: --\n",
      "  4701/100000: episode: 267, duration: 0.008s, episode steps: 14, steps per second: 1751, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.571 [0.000, 1.000], mean observation: -0.115 [-1.608, 0.965], mean_best_reward: --\n",
      "  4719/100000: episode: 268, duration: 0.010s, episode steps: 18, steps per second: 1886, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.722 [0.000, 1.000], mean observation: -0.067 [-2.371, 1.553], mean_best_reward: --\n",
      "  4735/100000: episode: 269, duration: 0.008s, episode steps: 16, steps per second: 1913, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.562 [0.000, 1.000], mean observation: -0.110 [-1.268, 0.763], mean_best_reward: --\n",
      "  4783/100000: episode: 270, duration: 0.021s, episode steps: 48, steps per second: 2236, episode reward: 48.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.479 [0.000, 1.000], mean observation: -0.028 [-0.773, 0.580], mean_best_reward: --\n",
      "  4797/100000: episode: 271, duration: 0.007s, episode steps: 14, steps per second: 1956, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.643 [0.000, 1.000], mean observation: -0.107 [-1.771, 0.983], mean_best_reward: --\n",
      "  4821/100000: episode: 272, duration: 0.019s, episode steps: 24, steps per second: 1267, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.542 [0.000, 1.000], mean observation: -0.080 [-1.176, 0.800], mean_best_reward: --\n",
      "  4903/100000: episode: 273, duration: 0.045s, episode steps: 82, steps per second: 1832, episode reward: 82.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: -0.023 [-1.276, 1.112], mean_best_reward: --\n",
      "  4934/100000: episode: 274, duration: 0.016s, episode steps: 31, steps per second: 1973, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.419 [0.000, 1.000], mean observation: -0.066 [-1.943, 2.103], mean_best_reward: --\n",
      "  4958/100000: episode: 275, duration: 0.013s, episode steps: 24, steps per second: 1851, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.542 [0.000, 1.000], mean observation: 0.118 [-0.368, 0.825], mean_best_reward: --\n",
      "  4970/100000: episode: 276, duration: 0.008s, episode steps: 12, steps per second: 1596, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.167 [0.000, 1.000], mean observation: 0.104 [-1.604, 2.573], mean_best_reward: --\n",
      "  4981/100000: episode: 277, duration: 0.007s, episode steps: 11, steps per second: 1577, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.107 [-2.166, 1.332], mean_best_reward: --\n",
      "  4989/100000: episode: 278, duration: 0.005s, episode steps: 8, steps per second: 1514, episode reward: 8.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.146 [-1.525, 2.536], mean_best_reward: --\n",
      "  5007/100000: episode: 279, duration: 0.012s, episode steps: 18, steps per second: 1515, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.057 [-2.024, 1.324], mean_best_reward: --\n",
      "  5023/100000: episode: 280, duration: 0.010s, episode steps: 16, steps per second: 1620, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.078 [-2.518, 1.581], mean_best_reward: --\n",
      "  5035/100000: episode: 281, duration: 0.010s, episode steps: 12, steps per second: 1168, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.109 [-2.073, 1.229], mean_best_reward: --\n",
      "  5045/100000: episode: 282, duration: 0.006s, episode steps: 10, steps per second: 1667, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.900 [0.000, 1.000], mean observation: -0.133 [-2.475, 1.547], mean_best_reward: --\n",
      "  5056/100000: episode: 283, duration: 0.009s, episode steps: 11, steps per second: 1194, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.364 [0.000, 1.000], mean observation: 0.116 [-1.030, 1.626], mean_best_reward: --\n",
      "  5066/100000: episode: 284, duration: 0.007s, episode steps: 10, steps per second: 1458, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.900 [0.000, 1.000], mean observation: -0.139 [-2.565, 1.554], mean_best_reward: --\n",
      "  5086/100000: episode: 285, duration: 0.013s, episode steps: 20, steps per second: 1508, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.350 [0.000, 1.000], mean observation: 0.068 [-1.160, 1.919], mean_best_reward: --\n",
      "  5102/100000: episode: 286, duration: 0.009s, episode steps: 16, steps per second: 1816, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.688 [0.000, 1.000], mean observation: -0.073 [-1.903, 1.139], mean_best_reward: --\n",
      "  5123/100000: episode: 287, duration: 0.011s, episode steps: 21, steps per second: 1907, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: 0.067 [-0.631, 1.074], mean_best_reward: --\n",
      "  5137/100000: episode: 288, duration: 0.009s, episode steps: 14, steps per second: 1606, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.643 [0.000, 1.000], mean observation: -0.102 [-1.877, 1.170], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5152/100000: episode: 289, duration: 0.010s, episode steps: 15, steps per second: 1514, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.200 [0.000, 1.000], mean observation: 0.118 [-1.736, 2.871], mean_best_reward: --\n",
      "  5179/100000: episode: 290, duration: 0.015s, episode steps: 27, steps per second: 1832, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.519 [0.000, 1.000], mean observation: 0.086 [-0.597, 0.927], mean_best_reward: --\n",
      "  5212/100000: episode: 291, duration: 0.023s, episode steps: 33, steps per second: 1426, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.364 [0.000, 1.000], mean observation: 0.079 [-1.722, 2.871], mean_best_reward: --\n",
      "  5222/100000: episode: 292, duration: 0.008s, episode steps: 10, steps per second: 1305, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.800 [0.000, 1.000], mean observation: -0.140 [-2.019, 1.160], mean_best_reward: --\n",
      "  5237/100000: episode: 293, duration: 0.011s, episode steps: 15, steps per second: 1403, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: 0.106 [-0.748, 1.166], mean_best_reward: --\n",
      "  5308/100000: episode: 294, duration: 0.035s, episode steps: 71, steps per second: 2052, episode reward: 71.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.592 [0.000, 1.000], mean observation: 0.149 [-2.446, 2.455], mean_best_reward: --\n",
      "  5388/100000: episode: 295, duration: 0.040s, episode steps: 80, steps per second: 1991, episode reward: 80.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.061 [-1.011, 1.180], mean_best_reward: --\n",
      "  5398/100000: episode: 296, duration: 0.006s, episode steps: 10, steps per second: 1678, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.100 [0.000, 1.000], mean observation: 0.131 [-1.579, 2.519], mean_best_reward: --\n",
      "  5415/100000: episode: 297, duration: 0.009s, episode steps: 17, steps per second: 1836, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.412 [0.000, 1.000], mean observation: 0.097 [-0.614, 1.415], mean_best_reward: --\n",
      "  5425/100000: episode: 298, duration: 0.006s, episode steps: 10, steps per second: 1616, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.800 [0.000, 1.000], mean observation: -0.106 [-2.162, 1.411], mean_best_reward: --\n",
      "  5440/100000: episode: 299, duration: 0.009s, episode steps: 15, steps per second: 1621, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.083 [-1.945, 1.214], mean_best_reward: --\n",
      "  5468/100000: episode: 300, duration: 0.014s, episode steps: 28, steps per second: 1981, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.571 [0.000, 1.000], mean observation: -0.049 [-1.802, 1.028], mean_best_reward: --\n",
      "  5477/100000: episode: 301, duration: 0.006s, episode steps: 9, steps per second: 1453, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.111 [0.000, 1.000], mean observation: 0.145 [-1.517, 2.447], mean_best_reward: 101.000000\n",
      "  5514/100000: episode: 302, duration: 0.020s, episode steps: 37, steps per second: 1819, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: 0.100 [-0.601, 0.978], mean_best_reward: --\n",
      "  5527/100000: episode: 303, duration: 0.008s, episode steps: 13, steps per second: 1682, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.231 [0.000, 1.000], mean observation: 0.063 [-1.610, 2.397], mean_best_reward: --\n",
      "  5544/100000: episode: 304, duration: 0.016s, episode steps: 17, steps per second: 1037, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.235 [0.000, 1.000], mean observation: 0.100 [-1.720, 2.794], mean_best_reward: --\n",
      "  5559/100000: episode: 305, duration: 0.008s, episode steps: 15, steps per second: 1858, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.800 [0.000, 1.000], mean observation: -0.089 [-2.760, 1.740], mean_best_reward: --\n",
      "  5580/100000: episode: 306, duration: 0.011s, episode steps: 21, steps per second: 1883, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: 0.083 [-0.942, 1.526], mean_best_reward: --\n",
      "  5596/100000: episode: 307, duration: 0.009s, episode steps: 16, steps per second: 1779, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.312 [0.000, 1.000], mean observation: 0.112 [-1.327, 2.298], mean_best_reward: --\n",
      "  5611/100000: episode: 308, duration: 0.009s, episode steps: 15, steps per second: 1680, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.267 [0.000, 1.000], mean observation: 0.080 [-1.389, 2.191], mean_best_reward: --\n",
      "  5626/100000: episode: 309, duration: 0.009s, episode steps: 15, steps per second: 1613, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.122 [-0.961, 1.873], mean_best_reward: --\n",
      "  5639/100000: episode: 310, duration: 0.008s, episode steps: 13, steps per second: 1609, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.154 [0.000, 1.000], mean observation: 0.101 [-1.772, 2.805], mean_best_reward: --\n",
      "  5656/100000: episode: 311, duration: 0.010s, episode steps: 17, steps per second: 1697, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.706 [0.000, 1.000], mean observation: -0.082 [-2.440, 1.560], mean_best_reward: --\n",
      "  5665/100000: episode: 312, duration: 0.006s, episode steps: 9, steps per second: 1539, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.889 [0.000, 1.000], mean observation: -0.142 [-2.301, 1.418], mean_best_reward: --\n",
      "  5675/100000: episode: 313, duration: 0.006s, episode steps: 10, steps per second: 1741, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.700 [0.000, 1.000], mean observation: -0.121 [-1.801, 1.170], mean_best_reward: --\n",
      "  5692/100000: episode: 314, duration: 0.010s, episode steps: 17, steps per second: 1735, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.235 [0.000, 1.000], mean observation: 0.076 [-1.727, 2.797], mean_best_reward: --\n",
      "  5718/100000: episode: 315, duration: 0.014s, episode steps: 26, steps per second: 1840, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: 0.119 [-0.561, 0.973], mean_best_reward: --\n",
      "  5729/100000: episode: 316, duration: 0.008s, episode steps: 11, steps per second: 1435, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.182 [0.000, 1.000], mean observation: 0.133 [-1.334, 2.321], mean_best_reward: --\n",
      "  5786/100000: episode: 317, duration: 0.028s, episode steps: 57, steps per second: 2026, episode reward: 57.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.561 [0.000, 1.000], mean observation: -0.069 [-2.345, 1.525], mean_best_reward: --\n",
      "  5800/100000: episode: 318, duration: 0.009s, episode steps: 14, steps per second: 1642, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.714 [0.000, 1.000], mean observation: -0.092 [-2.186, 1.375], mean_best_reward: --\n",
      "  5811/100000: episode: 319, duration: 0.007s, episode steps: 11, steps per second: 1559, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.909 [0.000, 1.000], mean observation: -0.136 [-2.844, 1.803], mean_best_reward: --\n",
      "  5830/100000: episode: 320, duration: 0.010s, episode steps: 19, steps per second: 1820, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.526 [0.000, 1.000], mean observation: -0.099 [-1.149, 0.604], mean_best_reward: --\n",
      "  5840/100000: episode: 321, duration: 0.006s, episode steps: 10, steps per second: 1584, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.100 [0.000, 1.000], mean observation: 0.141 [-1.531, 2.514], mean_best_reward: --\n",
      "  5851/100000: episode: 322, duration: 0.010s, episode steps: 11, steps per second: 1112, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.091 [0.000, 1.000], mean observation: 0.144 [-1.723, 2.818], mean_best_reward: --\n",
      "  5863/100000: episode: 323, duration: 0.012s, episode steps: 12, steps per second: 1011, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.833 [0.000, 1.000], mean observation: -0.116 [-2.728, 1.764], mean_best_reward: --\n",
      "  5883/100000: episode: 324, duration: 0.016s, episode steps: 20, steps per second: 1230, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.300 [0.000, 1.000], mean observation: 0.077 [-1.584, 2.579], mean_best_reward: --\n",
      "  5894/100000: episode: 325, duration: 0.007s, episode steps: 11, steps per second: 1608, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.273 [0.000, 1.000], mean observation: 0.125 [-1.023, 1.814], mean_best_reward: --\n",
      "  5904/100000: episode: 326, duration: 0.006s, episode steps: 10, steps per second: 1714, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.145 [-1.905, 3.035], mean_best_reward: --\n",
      "  5913/100000: episode: 327, duration: 0.006s, episode steps: 9, steps per second: 1455, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.111 [0.000, 1.000], mean observation: 0.155 [-1.349, 2.295], mean_best_reward: --\n",
      "  5938/100000: episode: 328, duration: 0.014s, episode steps: 25, steps per second: 1750, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.113 [-0.985, 0.586], mean_best_reward: --\n",
      "  5951/100000: episode: 329, duration: 0.008s, episode steps: 13, steps per second: 1726, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.231 [0.000, 1.000], mean observation: 0.101 [-1.366, 2.311], mean_best_reward: --\n",
      "  5964/100000: episode: 330, duration: 0.008s, episode steps: 13, steps per second: 1604, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: 0.088 [-0.828, 1.223], mean_best_reward: --\n",
      "  5975/100000: episode: 331, duration: 0.007s, episode steps: 11, steps per second: 1572, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.182 [0.000, 1.000], mean observation: 0.109 [-1.415, 2.292], mean_best_reward: --\n",
      "  5985/100000: episode: 332, duration: 0.007s, episode steps: 10, steps per second: 1431, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.100 [0.000, 1.000], mean observation: 0.137 [-1.784, 2.701], mean_best_reward: --\n",
      "  6028/100000: episode: 333, duration: 0.027s, episode steps: 43, steps per second: 1565, episode reward: 43.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.349 [0.000, 1.000], mean observation: -0.076 [-2.498, 2.848], mean_best_reward: --\n",
      "  6040/100000: episode: 334, duration: 0.008s, episode steps: 12, steps per second: 1595, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.250 [0.000, 1.000], mean observation: 0.103 [-1.402, 2.129], mean_best_reward: --\n",
      "  6052/100000: episode: 335, duration: 0.007s, episode steps: 12, steps per second: 1680, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.167 [0.000, 1.000], mean observation: 0.106 [-1.558, 2.499], mean_best_reward: --\n",
      "  6061/100000: episode: 336, duration: 0.006s, episode steps: 9, steps per second: 1420, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.111 [0.000, 1.000], mean observation: 0.115 [-1.422, 2.258], mean_best_reward: --\n",
      "  6087/100000: episode: 337, duration: 0.013s, episode steps: 26, steps per second: 1964, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: 0.129 [-0.412, 1.562], mean_best_reward: --\n",
      "  6106/100000: episode: 338, duration: 0.011s, episode steps: 19, steps per second: 1753, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: 0.111 [-0.414, 1.111], mean_best_reward: --\n",
      "  6116/100000: episode: 339, duration: 0.006s, episode steps: 10, steps per second: 1605, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.200 [0.000, 1.000], mean observation: 0.128 [-1.175, 1.930], mean_best_reward: --\n",
      "  6128/100000: episode: 340, duration: 0.007s, episode steps: 12, steps per second: 1655, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.134 [-0.756, 1.542], mean_best_reward: --\n",
      "  6139/100000: episode: 341, duration: 0.007s, episode steps: 11, steps per second: 1610, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.091 [0.000, 1.000], mean observation: 0.129 [-1.754, 2.897], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6160/100000: episode: 342, duration: 0.011s, episode steps: 21, steps per second: 1991, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.524 [0.000, 1.000], mean observation: -0.078 [-1.112, 0.764], mean_best_reward: --\n",
      "  6176/100000: episode: 343, duration: 0.011s, episode steps: 16, steps per second: 1393, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.312 [0.000, 1.000], mean observation: 0.095 [-1.209, 2.041], mean_best_reward: --\n",
      "  6199/100000: episode: 344, duration: 0.019s, episode steps: 23, steps per second: 1196, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: 0.108 [-1.014, 1.495], mean_best_reward: --\n",
      "  6233/100000: episode: 345, duration: 0.021s, episode steps: 34, steps per second: 1622, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.441 [0.000, 1.000], mean observation: 0.031 [-1.156, 1.712], mean_best_reward: --\n",
      "  6245/100000: episode: 346, duration: 0.007s, episode steps: 12, steps per second: 1734, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.109 [-2.082, 1.223], mean_best_reward: --\n",
      "  6255/100000: episode: 347, duration: 0.006s, episode steps: 10, steps per second: 1568, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.100 [0.000, 1.000], mean observation: 0.138 [-1.550, 2.549], mean_best_reward: --\n",
      "  6279/100000: episode: 348, duration: 0.012s, episode steps: 24, steps per second: 2001, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.106 [-0.929, 1.483], mean_best_reward: --\n",
      "  6304/100000: episode: 349, duration: 0.012s, episode steps: 25, steps per second: 2033, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.240 [0.000, 1.000], mean observation: 0.013 [-2.479, 3.377], mean_best_reward: --\n",
      "  6320/100000: episode: 350, duration: 0.009s, episode steps: 16, steps per second: 1832, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.119 [-1.218, 0.562], mean_best_reward: --\n",
      "  6334/100000: episode: 351, duration: 0.008s, episode steps: 14, steps per second: 1687, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: 0.103 [-0.801, 1.437], mean_best_reward: 81.000000\n",
      "  6346/100000: episode: 352, duration: 0.007s, episode steps: 12, steps per second: 1828, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.117 [-1.560, 0.794], mean_best_reward: --\n",
      "  6369/100000: episode: 353, duration: 0.011s, episode steps: 23, steps per second: 2146, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.609 [0.000, 1.000], mean observation: -0.040 [-1.664, 0.960], mean_best_reward: --\n",
      "  6383/100000: episode: 354, duration: 0.007s, episode steps: 14, steps per second: 1924, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.786 [0.000, 1.000], mean observation: -0.085 [-2.660, 1.801], mean_best_reward: --\n",
      "  6393/100000: episode: 355, duration: 0.006s, episode steps: 10, steps per second: 1792, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.800 [0.000, 1.000], mean observation: -0.131 [-2.067, 1.159], mean_best_reward: --\n",
      "  6408/100000: episode: 356, duration: 0.007s, episode steps: 15, steps per second: 2004, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.533 [0.000, 1.000], mean observation: -0.112 [-1.315, 0.803], mean_best_reward: --\n",
      "  6433/100000: episode: 357, duration: 0.013s, episode steps: 25, steps per second: 1961, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: -0.056 [-1.058, 0.636], mean_best_reward: --\n",
      "  6444/100000: episode: 358, duration: 0.007s, episode steps: 11, steps per second: 1496, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.129 [-2.212, 1.332], mean_best_reward: --\n",
      "  6456/100000: episode: 359, duration: 0.008s, episode steps: 12, steps per second: 1534, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.833 [0.000, 1.000], mean observation: -0.100 [-2.564, 1.595], mean_best_reward: --\n",
      "  6477/100000: episode: 360, duration: 0.011s, episode steps: 21, steps per second: 1907, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: 0.047 [-0.930, 1.435], mean_best_reward: --\n",
      "  6491/100000: episode: 361, duration: 0.009s, episode steps: 14, steps per second: 1595, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.214 [0.000, 1.000], mean observation: 0.075 [-1.590, 2.425], mean_best_reward: --\n",
      "  6510/100000: episode: 362, duration: 0.013s, episode steps: 19, steps per second: 1421, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.684 [0.000, 1.000], mean observation: -0.096 [-2.335, 1.339], mean_best_reward: --\n",
      "  6529/100000: episode: 363, duration: 0.015s, episode steps: 19, steps per second: 1227, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.526 [0.000, 1.000], mean observation: 0.109 [-0.431, 0.970], mean_best_reward: --\n",
      "  6547/100000: episode: 364, duration: 0.013s, episode steps: 18, steps per second: 1387, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.611 [0.000, 1.000], mean observation: -0.082 [-1.553, 0.835], mean_best_reward: --\n",
      "  6562/100000: episode: 365, duration: 0.008s, episode steps: 15, steps per second: 1897, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.533 [0.000, 1.000], mean observation: -0.086 [-1.281, 0.830], mean_best_reward: --\n",
      "  6578/100000: episode: 366, duration: 0.009s, episode steps: 16, steps per second: 1819, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.095 [-2.571, 1.580], mean_best_reward: --\n",
      "  6599/100000: episode: 367, duration: 0.010s, episode steps: 21, steps per second: 2013, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.524 [0.000, 1.000], mean observation: -0.067 [-1.121, 0.823], mean_best_reward: --\n",
      "  6612/100000: episode: 368, duration: 0.007s, episode steps: 13, steps per second: 1776, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.692 [0.000, 1.000], mean observation: -0.106 [-1.766, 0.987], mean_best_reward: --\n",
      "  6623/100000: episode: 369, duration: 0.006s, episode steps: 11, steps per second: 1808, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.909 [0.000, 1.000], mean observation: -0.121 [-2.824, 1.798], mean_best_reward: --\n",
      "  6723/100000: episode: 370, duration: 0.041s, episode steps: 100, steps per second: 2457, episode reward: 100.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.085 [-1.076, 0.742], mean_best_reward: --\n",
      "  6733/100000: episode: 371, duration: 0.006s, episode steps: 10, steps per second: 1748, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.900 [0.000, 1.000], mean observation: -0.154 [-2.564, 1.579], mean_best_reward: --\n",
      "  6753/100000: episode: 372, duration: 0.011s, episode steps: 20, steps per second: 1874, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.120 [-1.466, 0.964], mean_best_reward: --\n",
      "  6763/100000: episode: 373, duration: 0.006s, episode steps: 10, steps per second: 1657, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.800 [0.000, 1.000], mean observation: -0.127 [-2.363, 1.583], mean_best_reward: --\n",
      "  6797/100000: episode: 374, duration: 0.015s, episode steps: 34, steps per second: 2208, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.062 [-1.088, 0.609], mean_best_reward: --\n",
      "  6808/100000: episode: 375, duration: 0.006s, episode steps: 11, steps per second: 1813, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.364 [0.000, 1.000], mean observation: 0.118 [-0.952, 1.665], mean_best_reward: --\n",
      "  6825/100000: episode: 376, duration: 0.009s, episode steps: 17, steps per second: 1998, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.765 [0.000, 1.000], mean observation: -0.085 [-2.744, 1.712], mean_best_reward: --\n",
      "  6835/100000: episode: 377, duration: 0.006s, episode steps: 10, steps per second: 1733, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 1.000 [1.000, 1.000], mean observation: -0.126 [-2.951, 1.911], mean_best_reward: --\n",
      "  6852/100000: episode: 378, duration: 0.008s, episode steps: 17, steps per second: 2010, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.412 [0.000, 1.000], mean observation: 0.110 [-0.615, 1.376], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6899/100000: episode: 379, duration: 0.021s, episode steps: 47, steps per second: 2283, episode reward: 47.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.426 [0.000, 1.000], mean observation: -0.168 [-1.276, 0.397], mean_best_reward: --\n",
      "  6910/100000: episode: 380, duration: 0.008s, episode steps: 11, steps per second: 1386, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.909 [0.000, 1.000], mean observation: -0.122 [-2.781, 1.754], mean_best_reward: --\n",
      "  6938/100000: episode: 381, duration: 0.020s, episode steps: 28, steps per second: 1376, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.073 [-0.658, 1.474], mean_best_reward: --\n",
      "  6951/100000: episode: 382, duration: 0.007s, episode steps: 13, steps per second: 1776, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.692 [0.000, 1.000], mean observation: -0.133 [-2.081, 1.166], mean_best_reward: --\n",
      "  6960/100000: episode: 383, duration: 0.006s, episode steps: 9, steps per second: 1463, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.148 [-1.602, 0.972], mean_best_reward: --\n",
      "  7022/100000: episode: 384, duration: 0.029s, episode steps: 62, steps per second: 2172, episode reward: 62.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.548 [0.000, 1.000], mean observation: 0.108 [-1.835, 2.035], mean_best_reward: --\n",
      "  7031/100000: episode: 385, duration: 0.006s, episode steps: 9, steps per second: 1557, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 1.000 [1.000, 1.000], mean observation: -0.161 [-2.838, 1.762], mean_best_reward: --\n",
      "  7046/100000: episode: 386, duration: 0.008s, episode steps: 15, steps per second: 1900, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.733 [0.000, 1.000], mean observation: -0.089 [-2.228, 1.412], mean_best_reward: --\n",
      "  7069/100000: episode: 387, duration: 0.011s, episode steps: 23, steps per second: 2063, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.522 [0.000, 1.000], mean observation: -0.088 [-0.904, 0.582], mean_best_reward: --\n",
      "  7107/100000: episode: 388, duration: 0.017s, episode steps: 38, steps per second: 2234, episode reward: 38.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.526 [0.000, 1.000], mean observation: -0.007 [-0.954, 0.722], mean_best_reward: --\n",
      "  7116/100000: episode: 389, duration: 0.006s, episode steps: 9, steps per second: 1491, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.889 [0.000, 1.000], mean observation: -0.149 [-2.270, 1.349], mean_best_reward: --\n",
      "  7140/100000: episode: 390, duration: 0.013s, episode steps: 24, steps per second: 1869, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.375 [0.000, 1.000], mean observation: 0.020 [-1.213, 1.906], mean_best_reward: --\n",
      "  7155/100000: episode: 391, duration: 0.011s, episode steps: 15, steps per second: 1306, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.800 [0.000, 1.000], mean observation: -0.090 [-2.845, 1.790], mean_best_reward: --\n",
      "  7181/100000: episode: 392, duration: 0.018s, episode steps: 26, steps per second: 1471, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.423 [0.000, 1.000], mean observation: 0.071 [-1.150, 2.040], mean_best_reward: --\n",
      "  7218/100000: episode: 393, duration: 0.019s, episode steps: 37, steps per second: 1969, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.541 [0.000, 1.000], mean observation: 0.145 [-0.562, 0.890], mean_best_reward: --\n",
      "  7239/100000: episode: 394, duration: 0.012s, episode steps: 21, steps per second: 1774, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: -0.081 [-0.961, 0.553], mean_best_reward: --\n",
      "  7250/100000: episode: 395, duration: 0.007s, episode steps: 11, steps per second: 1550, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.636 [0.000, 1.000], mean observation: -0.115 [-1.390, 0.776], mean_best_reward: --\n",
      "  7263/100000: episode: 396, duration: 0.009s, episode steps: 13, steps per second: 1391, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.769 [0.000, 1.000], mean observation: -0.089 [-2.193, 1.355], mean_best_reward: --\n",
      "  7275/100000: episode: 397, duration: 0.012s, episode steps: 12, steps per second: 1037, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.087 [-1.482, 0.830], mean_best_reward: --\n",
      "  7285/100000: episode: 398, duration: 0.007s, episode steps: 10, steps per second: 1422, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.100 [0.000, 1.000], mean observation: 0.146 [-1.552, 2.501], mean_best_reward: --\n",
      "  7320/100000: episode: 399, duration: 0.017s, episode steps: 35, steps per second: 2064, episode reward: 35.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: 0.109 [-0.354, 0.945], mean_best_reward: --\n",
      "  7345/100000: episode: 400, duration: 0.013s, episode steps: 25, steps per second: 1969, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.066 [-1.286, 0.803], mean_best_reward: --\n",
      "  7358/100000: episode: 401, duration: 0.008s, episode steps: 13, steps per second: 1586, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.769 [0.000, 1.000], mean observation: -0.109 [-2.365, 1.516], mean_best_reward: 69.000000\n",
      "  7380/100000: episode: 402, duration: 0.012s, episode steps: 22, steps per second: 1879, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: -0.093 [-1.282, 0.753], mean_best_reward: --\n",
      "  7404/100000: episode: 403, duration: 0.011s, episode steps: 24, steps per second: 2114, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.076 [-1.015, 0.598], mean_best_reward: --\n",
      "  7416/100000: episode: 404, duration: 0.007s, episode steps: 12, steps per second: 1817, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.112 [-1.662, 0.958], mean_best_reward: --\n",
      "  7428/100000: episode: 405, duration: 0.008s, episode steps: 12, steps per second: 1413, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.833 [0.000, 1.000], mean observation: -0.108 [-2.583, 1.582], mean_best_reward: --\n",
      "  7443/100000: episode: 406, duration: 0.008s, episode steps: 15, steps per second: 1927, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.102 [-1.515, 0.795], mean_best_reward: --\n",
      "  7467/100000: episode: 407, duration: 0.012s, episode steps: 24, steps per second: 1974, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.542 [0.000, 1.000], mean observation: -0.100 [-1.294, 0.570], mean_best_reward: --\n",
      "  7477/100000: episode: 408, duration: 0.006s, episode steps: 10, steps per second: 1592, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.800 [0.000, 1.000], mean observation: -0.134 [-2.045, 1.170], mean_best_reward: --\n",
      "  7486/100000: episode: 409, duration: 0.006s, episode steps: 9, steps per second: 1544, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.142 [-1.788, 2.820], mean_best_reward: --\n",
      "  7502/100000: episode: 410, duration: 0.009s, episode steps: 16, steps per second: 1843, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.117 [-1.305, 0.758], mean_best_reward: --\n",
      "  7525/100000: episode: 411, duration: 0.011s, episode steps: 23, steps per second: 2000, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.652 [0.000, 1.000], mean observation: -0.020 [-2.638, 1.980], mean_best_reward: --\n",
      "  7539/100000: episode: 412, duration: 0.007s, episode steps: 14, steps per second: 1942, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.357 [0.000, 1.000], mean observation: 0.103 [-1.151, 1.927], mean_best_reward: --\n",
      "  7555/100000: episode: 413, duration: 0.008s, episode steps: 16, steps per second: 1997, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.688 [0.000, 1.000], mean observation: -0.070 [-2.003, 1.206], mean_best_reward: --\n",
      "  7566/100000: episode: 414, duration: 0.006s, episode steps: 11, steps per second: 1826, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.097 [-2.215, 1.415], mean_best_reward: --\n",
      "  7586/100000: episode: 415, duration: 0.011s, episode steps: 20, steps per second: 1837, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.700 [0.000, 1.000], mean observation: -0.070 [-2.572, 1.555], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7610/100000: episode: 416, duration: 0.014s, episode steps: 24, steps per second: 1762, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.542 [0.000, 1.000], mean observation: -0.093 [-1.321, 0.612], mean_best_reward: --\n",
      "  7621/100000: episode: 417, duration: 0.007s, episode steps: 11, steps per second: 1509, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.727 [0.000, 1.000], mean observation: -0.093 [-1.866, 1.194], mean_best_reward: --\n",
      "  7640/100000: episode: 418, duration: 0.012s, episode steps: 19, steps per second: 1631, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.737 [0.000, 1.000], mean observation: -0.034 [-2.787, 1.966], mean_best_reward: --\n",
      "  7658/100000: episode: 419, duration: 0.013s, episode steps: 18, steps per second: 1400, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.120 [-0.556, 1.289], mean_best_reward: --\n",
      "  7670/100000: episode: 420, duration: 0.007s, episode steps: 12, steps per second: 1726, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.417 [0.000, 1.000], mean observation: 0.091 [-1.014, 1.623], mean_best_reward: --\n",
      "  7730/100000: episode: 421, duration: 0.027s, episode steps: 60, steps per second: 2186, episode reward: 60.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.078 [-0.839, 0.669], mean_best_reward: --\n",
      "  7770/100000: episode: 422, duration: 0.018s, episode steps: 40, steps per second: 2202, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.550 [0.000, 1.000], mean observation: 0.121 [-1.701, 1.757], mean_best_reward: --\n",
      "  7821/100000: episode: 423, duration: 0.023s, episode steps: 51, steps per second: 2266, episode reward: 51.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.608 [0.000, 1.000], mean observation: 0.090 [-2.325, 2.281], mean_best_reward: --\n",
      "  7845/100000: episode: 424, duration: 0.011s, episode steps: 24, steps per second: 2146, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.542 [0.000, 1.000], mean observation: 0.104 [-0.597, 1.035], mean_best_reward: --\n",
      "  7865/100000: episode: 425, duration: 0.011s, episode steps: 20, steps per second: 1851, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.450 [0.000, 1.000], mean observation: -0.107 [-0.833, 0.394], mean_best_reward: --\n",
      "  7875/100000: episode: 426, duration: 0.006s, episode steps: 10, steps per second: 1724, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.800 [0.000, 1.000], mean observation: -0.127 [-2.215, 1.356], mean_best_reward: --\n",
      "  7889/100000: episode: 427, duration: 0.013s, episode steps: 14, steps per second: 1100, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.286 [0.000, 1.000], mean observation: 0.100 [-1.154, 1.994], mean_best_reward: --\n",
      "  7954/100000: episode: 428, duration: 0.060s, episode steps: 65, steps per second: 1078, episode reward: 65.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.523 [0.000, 1.000], mean observation: -0.008 [-1.777, 0.630], mean_best_reward: --\n",
      "  7967/100000: episode: 429, duration: 0.017s, episode steps: 13, steps per second: 769, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: 0.128 [-0.576, 1.065], mean_best_reward: --\n",
      "  7978/100000: episode: 430, duration: 0.017s, episode steps: 11, steps per second: 655, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.182 [0.000, 1.000], mean observation: 0.104 [-1.375, 2.189], mean_best_reward: --\n",
      "  7988/100000: episode: 431, duration: 0.013s, episode steps: 10, steps per second: 752, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.900 [0.000, 1.000], mean observation: -0.142 [-2.692, 1.748], mean_best_reward: --\n",
      "  8004/100000: episode: 432, duration: 0.018s, episode steps: 16, steps per second: 874, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.688 [0.000, 1.000], mean observation: -0.063 [-2.115, 1.408], mean_best_reward: --\n",
      "  8033/100000: episode: 433, duration: 0.030s, episode steps: 29, steps per second: 958, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.517 [0.000, 1.000], mean observation: -0.055 [-1.358, 0.938], mean_best_reward: --\n",
      "  8054/100000: episode: 434, duration: 0.024s, episode steps: 21, steps per second: 866, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.068 [-2.221, 1.338], mean_best_reward: --\n",
      "  8067/100000: episode: 435, duration: 0.018s, episode steps: 13, steps per second: 718, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.692 [0.000, 1.000], mean observation: -0.078 [-1.783, 1.210], mean_best_reward: --\n",
      "  8106/100000: episode: 436, duration: 0.031s, episode steps: 39, steps per second: 1276, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.135 [-0.920, 0.495], mean_best_reward: --\n",
      "  8149/100000: episode: 437, duration: 0.031s, episode steps: 43, steps per second: 1387, episode reward: 43.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.465 [0.000, 1.000], mean observation: -0.136 [-0.923, 0.403], mean_best_reward: --\n",
      "  8159/100000: episode: 438, duration: 0.009s, episode steps: 10, steps per second: 1137, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 1.000 [1.000, 1.000], mean observation: -0.147 [-3.074, 1.987], mean_best_reward: --\n",
      "  8185/100000: episode: 439, duration: 0.020s, episode steps: 26, steps per second: 1301, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.085 [-1.075, 0.445], mean_best_reward: --\n",
      "  8195/100000: episode: 440, duration: 0.006s, episode steps: 10, steps per second: 1746, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.800 [0.000, 1.000], mean observation: -0.148 [-2.191, 1.349], mean_best_reward: --\n",
      "  8207/100000: episode: 441, duration: 0.007s, episode steps: 12, steps per second: 1774, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.833 [0.000, 1.000], mean observation: -0.114 [-2.530, 1.603], mean_best_reward: --\n",
      "  8220/100000: episode: 442, duration: 0.007s, episode steps: 13, steps per second: 1853, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.846 [0.000, 1.000], mean observation: -0.121 [-2.747, 1.723], mean_best_reward: --\n",
      "  8233/100000: episode: 443, duration: 0.007s, episode steps: 13, steps per second: 1842, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.769 [0.000, 1.000], mean observation: -0.121 [-2.352, 1.371], mean_best_reward: --\n",
      "  8252/100000: episode: 444, duration: 0.010s, episode steps: 19, steps per second: 1956, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: 0.084 [-0.750, 1.186], mean_best_reward: --\n",
      "  8267/100000: episode: 445, duration: 0.008s, episode steps: 15, steps per second: 1961, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.867 [0.000, 1.000], mean observation: -0.087 [-3.238, 2.120], mean_best_reward: --\n",
      "  8292/100000: episode: 446, duration: 0.012s, episode steps: 25, steps per second: 2133, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.400 [0.000, 1.000], mean observation: 0.070 [-1.153, 2.137], mean_best_reward: --\n",
      "  8309/100000: episode: 447, duration: 0.009s, episode steps: 17, steps per second: 1939, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.529 [0.000, 1.000], mean observation: -0.090 [-1.425, 0.812], mean_best_reward: --\n",
      "  8320/100000: episode: 448, duration: 0.006s, episode steps: 11, steps per second: 1808, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.273 [0.000, 1.000], mean observation: 0.102 [-1.203, 2.005], mean_best_reward: --\n",
      "  8334/100000: episode: 449, duration: 0.007s, episode steps: 14, steps per second: 1892, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.286 [0.000, 1.000], mean observation: 0.125 [-1.138, 2.076], mean_best_reward: --\n",
      "  8427/100000: episode: 450, duration: 0.038s, episode steps: 93, steps per second: 2429, episode reward: 93.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.516 [0.000, 1.000], mean observation: 0.143 [-1.146, 1.246], mean_best_reward: --\n",
      "  8456/100000: episode: 451, duration: 0.014s, episode steps: 29, steps per second: 2125, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.517 [0.000, 1.000], mean observation: 0.068 [-0.565, 0.945], mean_best_reward: 62.000000\n",
      "  8471/100000: episode: 452, duration: 0.008s, episode steps: 15, steps per second: 1953, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.733 [0.000, 1.000], mean observation: -0.099 [-2.233, 1.348], mean_best_reward: --\n",
      "  8493/100000: episode: 453, duration: 0.010s, episode steps: 22, steps per second: 2096, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.409 [0.000, 1.000], mean observation: 0.091 [-0.772, 1.720], mean_best_reward: --\n",
      "  8501/100000: episode: 454, duration: 0.005s, episode steps: 8, steps per second: 1612, episode reward: 8.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.125 [0.000, 1.000], mean observation: 0.129 [-1.419, 2.244], mean_best_reward: --\n",
      "  8519/100000: episode: 455, duration: 0.009s, episode steps: 18, steps per second: 2061, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.778 [0.000, 1.000], mean observation: -0.057 [-3.009, 1.952], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8535/100000: episode: 456, duration: 0.010s, episode steps: 16, steps per second: 1627, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.688 [0.000, 1.000], mean observation: -0.073 [-1.972, 1.166], mean_best_reward: --\n",
      "  8549/100000: episode: 457, duration: 0.009s, episode steps: 14, steps per second: 1548, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.357 [0.000, 1.000], mean observation: 0.086 [-1.019, 1.751], mean_best_reward: --\n",
      "  8560/100000: episode: 458, duration: 0.009s, episode steps: 11, steps per second: 1210, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.110 [-2.409, 1.527], mean_best_reward: --\n",
      "  8578/100000: episode: 459, duration: 0.011s, episode steps: 18, steps per second: 1640, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.047 [-1.585, 2.280], mean_best_reward: --\n",
      "  8588/100000: episode: 460, duration: 0.007s, episode steps: 10, steps per second: 1389, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.120 [-1.986, 3.014], mean_best_reward: --\n",
      "  8602/100000: episode: 461, duration: 0.008s, episode steps: 14, steps per second: 1800, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.643 [0.000, 1.000], mean observation: -0.129 [-1.827, 0.968], mean_best_reward: --\n",
      "  8632/100000: episode: 462, duration: 0.015s, episode steps: 30, steps per second: 1976, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.633 [0.000, 1.000], mean observation: -0.001 [-2.345, 1.578], mean_best_reward: --\n",
      "  8682/100000: episode: 463, duration: 0.022s, episode steps: 50, steps per second: 2238, episode reward: 50.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.069 [-1.156, 0.757], mean_best_reward: --\n",
      "  8693/100000: episode: 464, duration: 0.006s, episode steps: 11, steps per second: 1834, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.120 [-2.216, 1.417], mean_best_reward: --\n",
      "  8702/100000: episode: 465, duration: 0.005s, episode steps: 9, steps per second: 1697, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.111 [0.000, 1.000], mean observation: 0.133 [-1.347, 2.211], mean_best_reward: --\n",
      "  8715/100000: episode: 466, duration: 0.007s, episode steps: 13, steps per second: 1854, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.615 [0.000, 1.000], mean observation: -0.086 [-1.369, 0.817], mean_best_reward: --\n",
      "  8724/100000: episode: 467, duration: 0.005s, episode steps: 9, steps per second: 1699, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.163 [-1.729, 2.891], mean_best_reward: --\n",
      "  8735/100000: episode: 468, duration: 0.006s, episode steps: 11, steps per second: 1798, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.909 [0.000, 1.000], mean observation: -0.138 [-2.890, 1.778], mean_best_reward: --\n",
      "  8756/100000: episode: 469, duration: 0.010s, episode steps: 21, steps per second: 2106, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.619 [0.000, 1.000], mean observation: -0.037 [-1.868, 1.197], mean_best_reward: --\n",
      "  8766/100000: episode: 470, duration: 0.006s, episode steps: 10, steps per second: 1740, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.700 [0.000, 1.000], mean observation: -0.137 [-1.818, 1.137], mean_best_reward: --\n",
      "  8775/100000: episode: 471, duration: 0.005s, episode steps: 9, steps per second: 1699, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.222 [0.000, 1.000], mean observation: 0.145 [-1.178, 1.971], mean_best_reward: --\n",
      "  8786/100000: episode: 472, duration: 0.006s, episode steps: 11, steps per second: 1814, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.636 [0.000, 1.000], mean observation: -0.084 [-1.574, 1.023], mean_best_reward: --\n",
      "  8808/100000: episode: 473, duration: 0.011s, episode steps: 22, steps per second: 1954, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.636 [0.000, 1.000], mean observation: -0.069 [-2.232, 1.373], mean_best_reward: --\n",
      "  8819/100000: episode: 474, duration: 0.006s, episode steps: 11, steps per second: 1714, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.124 [-2.258, 1.389], mean_best_reward: --\n",
      "  8863/100000: episode: 475, duration: 0.019s, episode steps: 44, steps per second: 2305, episode reward: 44.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.591 [0.000, 1.000], mean observation: 0.055 [-2.057, 1.881], mean_best_reward: --\n",
      "  8884/100000: episode: 476, duration: 0.011s, episode steps: 21, steps per second: 1845, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.056 [-2.458, 1.551], mean_best_reward: --\n",
      "  8902/100000: episode: 477, duration: 0.011s, episode steps: 18, steps per second: 1670, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.046 [-2.220, 1.572], mean_best_reward: --\n",
      "  8921/100000: episode: 478, duration: 0.023s, episode steps: 19, steps per second: 839, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.632 [0.000, 1.000], mean observation: -0.093 [-1.843, 0.985], mean_best_reward: --\n",
      "  8930/100000: episode: 479, duration: 0.007s, episode steps: 9, steps per second: 1332, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.165 [-1.734, 2.848], mean_best_reward: --\n",
      "  8948/100000: episode: 480, duration: 0.015s, episode steps: 18, steps per second: 1210, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.722 [0.000, 1.000], mean observation: -0.035 [-2.413, 1.610], mean_best_reward: --\n",
      "  8957/100000: episode: 481, duration: 0.007s, episode steps: 9, steps per second: 1383, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.111 [0.000, 1.000], mean observation: 0.129 [-1.382, 2.236], mean_best_reward: --\n",
      "  8981/100000: episode: 482, duration: 0.014s, episode steps: 24, steps per second: 1722, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.050 [-2.501, 1.537], mean_best_reward: --\n",
      "  8991/100000: episode: 483, duration: 0.006s, episode steps: 10, steps per second: 1724, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.123 [-1.996, 2.995], mean_best_reward: --\n",
      "  9002/100000: episode: 484, duration: 0.007s, episode steps: 11, steps per second: 1480, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.091 [0.000, 1.000], mean observation: 0.136 [-1.715, 2.839], mean_best_reward: --\n",
      "  9024/100000: episode: 485, duration: 0.012s, episode steps: 22, steps per second: 1852, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: -0.050 [-1.586, 0.971], mean_best_reward: --\n",
      "  9058/100000: episode: 486, duration: 0.018s, episode steps: 34, steps per second: 1927, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.676 [0.000, 1.000], mean observation: -0.011 [-3.159, 2.317], mean_best_reward: --\n",
      "  9073/100000: episode: 487, duration: 0.009s, episode steps: 15, steps per second: 1702, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.110 [-0.991, 1.925], mean_best_reward: --\n",
      "  9087/100000: episode: 488, duration: 0.009s, episode steps: 14, steps per second: 1624, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.786 [0.000, 1.000], mean observation: -0.092 [-2.484, 1.581], mean_best_reward: --\n",
      "  9096/100000: episode: 489, duration: 0.006s, episode steps: 9, steps per second: 1510, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 1.000 [1.000, 1.000], mean observation: -0.132 [-2.842, 1.811], mean_best_reward: --\n",
      "  9108/100000: episode: 490, duration: 0.007s, episode steps: 12, steps per second: 1660, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.092 [-1.388, 2.130], mean_best_reward: --\n",
      "  9156/100000: episode: 491, duration: 0.023s, episode steps: 48, steps per second: 2127, episode reward: 48.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.091 [-1.130, 0.359], mean_best_reward: --\n",
      "  9173/100000: episode: 492, duration: 0.009s, episode steps: 17, steps per second: 1883, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.647 [0.000, 1.000], mean observation: -0.084 [-2.163, 1.360], mean_best_reward: --\n",
      "  9188/100000: episode: 493, duration: 0.009s, episode steps: 15, steps per second: 1726, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.733 [0.000, 1.000], mean observation: -0.066 [-2.438, 1.614], mean_best_reward: --\n",
      "  9217/100000: episode: 494, duration: 0.014s, episode steps: 29, steps per second: 2065, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.517 [0.000, 1.000], mean observation: 0.076 [-0.557, 1.064], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9229/100000: episode: 495, duration: 0.007s, episode steps: 12, steps per second: 1619, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.833 [0.000, 1.000], mean observation: -0.109 [-2.449, 1.519], mean_best_reward: --\n",
      "  9254/100000: episode: 496, duration: 0.014s, episode steps: 25, steps per second: 1838, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.640 [0.000, 1.000], mean observation: -0.010 [-2.147, 1.415], mean_best_reward: --\n",
      "  9268/100000: episode: 497, duration: 0.008s, episode steps: 14, steps per second: 1731, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.786 [0.000, 1.000], mean observation: -0.112 [-2.452, 1.527], mean_best_reward: --\n",
      "  9281/100000: episode: 498, duration: 0.011s, episode steps: 13, steps per second: 1175, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.769 [0.000, 1.000], mean observation: -0.100 [-2.293, 1.341], mean_best_reward: --\n",
      "  9292/100000: episode: 499, duration: 0.006s, episode steps: 11, steps per second: 1704, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.114 [-2.269, 1.370], mean_best_reward: --\n",
      "  9303/100000: episode: 500, duration: 0.007s, episode steps: 11, steps per second: 1576, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.273 [0.000, 1.000], mean observation: 0.117 [-0.994, 1.765], mean_best_reward: --\n",
      "  9318/100000: episode: 501, duration: 0.011s, episode steps: 15, steps per second: 1342, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.200 [0.000, 1.000], mean observation: 0.105 [-1.733, 2.819], mean_best_reward: 71.000000\n",
      "  9353/100000: episode: 502, duration: 0.018s, episode steps: 35, steps per second: 1999, episode reward: 35.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: -0.043 [-1.196, 0.452], mean_best_reward: --\n",
      "  9383/100000: episode: 503, duration: 0.016s, episode steps: 30, steps per second: 1916, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.077 [-0.817, 0.424], mean_best_reward: --\n",
      "  9396/100000: episode: 504, duration: 0.009s, episode steps: 13, steps per second: 1421, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.692 [0.000, 1.000], mean observation: -0.112 [-1.931, 1.140], mean_best_reward: --\n",
      "  9442/100000: episode: 505, duration: 0.022s, episode steps: 46, steps per second: 2068, episode reward: 46.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.014 [-0.912, 0.609], mean_best_reward: --\n",
      "  9458/100000: episode: 506, duration: 0.010s, episode steps: 16, steps per second: 1673, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.090 [-1.206, 0.811], mean_best_reward: --\n",
      "  9492/100000: episode: 507, duration: 0.016s, episode steps: 34, steps per second: 2063, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.035 [-0.882, 0.590], mean_best_reward: --\n",
      "  9516/100000: episode: 508, duration: 0.012s, episode steps: 24, steps per second: 2007, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.542 [0.000, 1.000], mean observation: -0.055 [-1.196, 0.732], mean_best_reward: --\n",
      "  9638/100000: episode: 509, duration: 0.058s, episode steps: 122, steps per second: 2093, episode reward: 122.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.062 [-0.915, 1.154], mean_best_reward: --\n",
      "  9663/100000: episode: 510, duration: 0.017s, episode steps: 25, steps per second: 1450, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.144 [-0.951, 0.555], mean_best_reward: --\n",
      "  9721/100000: episode: 511, duration: 0.030s, episode steps: 58, steps per second: 1945, episode reward: 58.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.448 [0.000, 1.000], mean observation: -0.131 [-1.533, 1.308], mean_best_reward: --\n",
      "  9760/100000: episode: 512, duration: 0.019s, episode steps: 39, steps per second: 2020, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: 0.024 [-1.167, 1.503], mean_best_reward: --\n",
      "  9774/100000: episode: 513, duration: 0.008s, episode steps: 14, steps per second: 1709, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.714 [0.000, 1.000], mean observation: -0.088 [-2.113, 1.395], mean_best_reward: --\n",
      "  9791/100000: episode: 514, duration: 0.009s, episode steps: 17, steps per second: 1883, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.647 [0.000, 1.000], mean observation: -0.062 [-1.826, 1.128], mean_best_reward: --\n",
      "  9824/100000: episode: 515, duration: 0.016s, episode steps: 33, steps per second: 2105, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: -0.087 [-0.880, 0.415], mean_best_reward: --\n",
      "  9870/100000: episode: 516, duration: 0.020s, episode steps: 46, steps per second: 2247, episode reward: 46.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: -0.050 [-0.972, 0.855], mean_best_reward: --\n",
      "  9922/100000: episode: 517, duration: 0.022s, episode steps: 52, steps per second: 2321, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.519 [0.000, 1.000], mean observation: 0.016 [-0.443, 0.786], mean_best_reward: --\n",
      "  9967/100000: episode: 518, duration: 0.019s, episode steps: 45, steps per second: 2313, episode reward: 45.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.511 [0.000, 1.000], mean observation: 0.002 [-0.795, 0.977], mean_best_reward: --\n",
      "  9980/100000: episode: 519, duration: 0.007s, episode steps: 13, steps per second: 1862, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.615 [0.000, 1.000], mean observation: -0.123 [-1.321, 0.745], mean_best_reward: --\n",
      "  9996/100000: episode: 520, duration: 0.008s, episode steps: 16, steps per second: 2023, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.128 [-1.063, 0.547], mean_best_reward: --\n",
      " 10016/100000: episode: 521, duration: 0.012s, episode steps: 20, steps per second: 1651, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.107 [-1.014, 0.587], mean_best_reward: --\n",
      " 10094/100000: episode: 522, duration: 0.044s, episode steps: 78, steps per second: 1771, episode reward: 78.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: -0.210 [-1.138, 0.893], mean_best_reward: --\n",
      " 10109/100000: episode: 523, duration: 0.012s, episode steps: 15, steps per second: 1255, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.267 [0.000, 1.000], mean observation: 0.088 [-1.340, 2.239], mean_best_reward: --\n",
      " 10120/100000: episode: 524, duration: 0.006s, episode steps: 11, steps per second: 1710, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.120 [-2.404, 1.596], mean_best_reward: --\n",
      " 10163/100000: episode: 525, duration: 0.026s, episode steps: 43, steps per second: 1680, episode reward: 43.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.465 [0.000, 1.000], mean observation: -0.117 [-1.246, 0.792], mean_best_reward: --\n",
      " 10175/100000: episode: 526, duration: 0.014s, episode steps: 12, steps per second: 873, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.094 [-1.985, 1.215], mean_best_reward: --\n",
      " 10220/100000: episode: 527, duration: 0.052s, episode steps: 45, steps per second: 870, episode reward: 45.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.511 [0.000, 1.000], mean observation: -0.015 [-1.624, 1.312], mean_best_reward: --\n",
      " 10237/100000: episode: 528, duration: 0.021s, episode steps: 17, steps per second: 792, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.529 [0.000, 1.000], mean observation: -0.094 [-1.467, 0.935], mean_best_reward: --\n",
      " 10256/100000: episode: 529, duration: 0.027s, episode steps: 19, steps per second: 700, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: 0.072 [-0.759, 1.173], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10286/100000: episode: 530, duration: 0.040s, episode steps: 30, steps per second: 744, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.533 [0.000, 1.000], mean observation: 0.088 [-0.403, 0.804], mean_best_reward: --\n",
      " 10309/100000: episode: 531, duration: 0.022s, episode steps: 23, steps per second: 1029, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.522 [0.000, 1.000], mean observation: -0.099 [-1.492, 0.806], mean_best_reward: --\n",
      " 10357/100000: episode: 532, duration: 0.034s, episode steps: 48, steps per second: 1405, episode reward: 48.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.011 [-0.830, 1.219], mean_best_reward: --\n",
      " 10380/100000: episode: 533, duration: 0.023s, episode steps: 23, steps per second: 1010, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: 0.073 [-0.628, 1.090], mean_best_reward: --\n",
      " 10398/100000: episode: 534, duration: 0.019s, episode steps: 18, steps per second: 943, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.556 [0.000, 1.000], mean observation: -0.102 [-1.181, 0.555], mean_best_reward: --\n",
      " 10504/100000: episode: 535, duration: 0.111s, episode steps: 106, steps per second: 956, episode reward: 106.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.575 [0.000, 1.000], mean observation: 0.035 [-3.319, 3.085], mean_best_reward: --\n",
      " 10534/100000: episode: 536, duration: 0.044s, episode steps: 30, steps per second: 680, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.155 [-0.923, 0.540], mean_best_reward: --\n",
      " 10546/100000: episode: 537, duration: 0.021s, episode steps: 12, steps per second: 585, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.119 [-1.681, 0.976], mean_best_reward: --\n",
      " 10606/100000: episode: 538, duration: 0.060s, episode steps: 60, steps per second: 993, episode reward: 60.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.517 [0.000, 1.000], mean observation: -0.047 [-1.361, 0.609], mean_best_reward: --\n",
      " 10645/100000: episode: 539, duration: 0.021s, episode steps: 39, steps per second: 1820, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.513 [0.000, 1.000], mean observation: -0.046 [-1.166, 0.397], mean_best_reward: --\n",
      " 10705/100000: episode: 540, duration: 0.026s, episode steps: 60, steps per second: 2348, episode reward: 60.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.042 [-1.446, 1.016], mean_best_reward: --\n",
      " 10726/100000: episode: 541, duration: 0.010s, episode steps: 21, steps per second: 2068, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.571 [0.000, 1.000], mean observation: -0.084 [-1.644, 0.829], mean_best_reward: --\n",
      " 10785/100000: episode: 542, duration: 0.027s, episode steps: 59, steps per second: 2218, episode reward: 59.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.441 [0.000, 1.000], mean observation: -0.219 [-1.696, 1.064], mean_best_reward: --\n",
      " 10830/100000: episode: 543, duration: 0.025s, episode steps: 45, steps per second: 1797, episode reward: 45.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.163 [-1.008, 0.857], mean_best_reward: --\n",
      " 10908/100000: episode: 544, duration: 0.035s, episode steps: 78, steps per second: 2256, episode reward: 78.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.487 [0.000, 1.000], mean observation: -0.185 [-1.487, 1.199], mean_best_reward: --\n",
      " 10937/100000: episode: 545, duration: 0.013s, episode steps: 29, steps per second: 2213, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.517 [0.000, 1.000], mean observation: -0.104 [-1.184, 0.564], mean_best_reward: --\n",
      " 10974/100000: episode: 546, duration: 0.016s, episode steps: 37, steps per second: 2324, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.568 [0.000, 1.000], mean observation: 0.005 [-1.699, 1.160], mean_best_reward: --\n",
      " 10985/100000: episode: 547, duration: 0.006s, episode steps: 11, steps per second: 1886, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.098 [-2.286, 1.424], mean_best_reward: --\n",
      " 11055/100000: episode: 548, duration: 0.029s, episode steps: 70, steps per second: 2389, episode reward: 70.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.457 [0.000, 1.000], mean observation: -0.084 [-1.328, 1.399], mean_best_reward: --\n",
      " 11134/100000: episode: 549, duration: 0.036s, episode steps: 79, steps per second: 2174, episode reward: 79.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.519 [0.000, 1.000], mean observation: 0.076 [-0.575, 1.316], mean_best_reward: --\n",
      " 11295/100000: episode: 550, duration: 0.163s, episode steps: 161, steps per second: 988, episode reward: 161.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.497 [0.000, 1.000], mean observation: -0.049 [-1.001, 1.311], mean_best_reward: --\n",
      " 11306/100000: episode: 551, duration: 0.010s, episode steps: 11, steps per second: 1100, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.727 [0.000, 1.000], mean observation: -0.095 [-1.949, 1.197], mean_best_reward: 51.500000\n",
      " 11317/100000: episode: 552, duration: 0.014s, episode steps: 11, steps per second: 788, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.273 [0.000, 1.000], mean observation: 0.110 [-1.019, 1.746], mean_best_reward: --\n",
      " 11336/100000: episode: 553, duration: 0.026s, episode steps: 19, steps per second: 729, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.632 [0.000, 1.000], mean observation: -0.082 [-1.691, 0.947], mean_best_reward: --\n",
      " 11347/100000: episode: 554, duration: 0.012s, episode steps: 11, steps per second: 889, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.636 [0.000, 1.000], mean observation: -0.098 [-1.542, 1.019], mean_best_reward: --\n",
      " 11366/100000: episode: 555, duration: 0.010s, episode steps: 19, steps per second: 1997, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.211 [0.000, 1.000], mean observation: 0.049 [-2.131, 3.131], mean_best_reward: --\n",
      " 11375/100000: episode: 556, duration: 0.009s, episode steps: 9, steps per second: 1050, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.889 [0.000, 1.000], mean observation: -0.136 [-2.252, 1.330], mean_best_reward: --\n",
      " 11384/100000: episode: 557, duration: 0.006s, episode steps: 9, steps per second: 1598, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.111 [0.000, 1.000], mean observation: 0.149 [-1.556, 2.493], mean_best_reward: --\n",
      " 11399/100000: episode: 558, duration: 0.008s, episode steps: 15, steps per second: 1894, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.800 [0.000, 1.000], mean observation: -0.101 [-2.756, 1.727], mean_best_reward: --\n",
      " 11408/100000: episode: 559, duration: 0.005s, episode steps: 9, steps per second: 1677, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.889 [0.000, 1.000], mean observation: -0.138 [-2.509, 1.574], mean_best_reward: --\n",
      " 11483/100000: episode: 560, duration: 0.031s, episode steps: 75, steps per second: 2400, episode reward: 75.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.123 [-1.266, 0.622], mean_best_reward: --\n",
      " 11498/100000: episode: 561, duration: 0.008s, episode steps: 15, steps per second: 1959, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.200 [0.000, 1.000], mean observation: 0.095 [-1.745, 2.822], mean_best_reward: --\n",
      " 11510/100000: episode: 562, duration: 0.007s, episode steps: 12, steps per second: 1825, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.083 [0.000, 1.000], mean observation: 0.102 [-1.931, 3.018], mean_best_reward: --\n",
      " 11521/100000: episode: 563, duration: 0.006s, episode steps: 11, steps per second: 1821, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.115 [-2.300, 1.421], mean_best_reward: --\n",
      " 11532/100000: episode: 564, duration: 0.006s, episode steps: 11, steps per second: 1842, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.151 [-2.308, 1.329], mean_best_reward: --\n",
      " 11541/100000: episode: 565, duration: 0.005s, episode steps: 9, steps per second: 1745, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.889 [0.000, 1.000], mean observation: -0.137 [-2.291, 1.417], mean_best_reward: --\n",
      " 11564/100000: episode: 566, duration: 0.011s, episode steps: 23, steps per second: 2167, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.522 [0.000, 1.000], mean observation: 0.085 [-0.829, 1.362], mean_best_reward: --\n",
      " 11575/100000: episode: 567, duration: 0.006s, episode steps: 11, steps per second: 1728, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.909 [0.000, 1.000], mean observation: -0.116 [-2.686, 1.756], mean_best_reward: --\n",
      " 11587/100000: episode: 568, duration: 0.009s, episode steps: 12, steps per second: 1377, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.084 [-1.645, 1.028], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11622/100000: episode: 569, duration: 0.018s, episode steps: 35, steps per second: 1964, episode reward: 35.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.400 [0.000, 1.000], mean observation: -0.059 [-1.694, 1.789], mean_best_reward: --\n",
      " 11643/100000: episode: 570, duration: 0.013s, episode steps: 21, steps per second: 1671, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.762 [0.000, 1.000], mean observation: -0.015 [-2.970, 2.097], mean_best_reward: --\n",
      " 11655/100000: episode: 571, duration: 0.008s, episode steps: 12, steps per second: 1587, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.121 [-0.991, 1.682], mean_best_reward: --\n",
      " 11674/100000: episode: 572, duration: 0.012s, episode steps: 19, steps per second: 1586, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.421 [0.000, 1.000], mean observation: 0.062 [-0.810, 1.338], mean_best_reward: --\n",
      " 11689/100000: episode: 573, duration: 0.009s, episode steps: 15, steps per second: 1659, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.267 [0.000, 1.000], mean observation: 0.100 [-1.363, 2.342], mean_best_reward: --\n",
      " 11699/100000: episode: 574, duration: 0.006s, episode steps: 10, steps per second: 1690, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.100 [0.000, 1.000], mean observation: 0.158 [-1.519, 2.580], mean_best_reward: --\n",
      " 11713/100000: episode: 575, duration: 0.007s, episode steps: 14, steps per second: 1904, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.286 [0.000, 1.000], mean observation: 0.102 [-1.144, 2.029], mean_best_reward: --\n",
      " 11723/100000: episode: 576, duration: 0.006s, episode steps: 10, steps per second: 1652, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.900 [0.000, 1.000], mean observation: -0.120 [-2.574, 1.601], mean_best_reward: --\n",
      " 11744/100000: episode: 577, duration: 0.010s, episode steps: 21, steps per second: 2040, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.619 [0.000, 1.000], mean observation: -0.102 [-1.869, 0.956], mean_best_reward: --\n",
      " 11758/100000: episode: 578, duration: 0.008s, episode steps: 14, steps per second: 1799, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.286 [0.000, 1.000], mean observation: 0.072 [-1.232, 2.047], mean_best_reward: --\n",
      " 11774/100000: episode: 579, duration: 0.016s, episode steps: 16, steps per second: 990, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.312 [0.000, 1.000], mean observation: 0.091 [-1.170, 2.098], mean_best_reward: --\n",
      " 11786/100000: episode: 580, duration: 0.008s, episode steps: 12, steps per second: 1489, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.108 [-2.141, 1.379], mean_best_reward: --\n",
      " 11897/100000: episode: 581, duration: 0.060s, episode steps: 111, steps per second: 1840, episode reward: 111.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.550 [0.000, 1.000], mean observation: -0.085 [-2.479, 2.120], mean_best_reward: --\n",
      " 11910/100000: episode: 582, duration: 0.008s, episode steps: 13, steps per second: 1704, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.231 [0.000, 1.000], mean observation: 0.122 [-1.340, 2.297], mean_best_reward: --\n",
      " 11924/100000: episode: 583, duration: 0.008s, episode steps: 14, steps per second: 1779, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.714 [0.000, 1.000], mean observation: -0.122 [-2.055, 1.139], mean_best_reward: --\n",
      " 11947/100000: episode: 584, duration: 0.012s, episode steps: 23, steps per second: 1966, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.739 [0.000, 1.000], mean observation: -0.011 [-2.944, 2.152], mean_best_reward: --\n",
      " 11964/100000: episode: 585, duration: 0.013s, episode steps: 17, steps per second: 1325, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.412 [0.000, 1.000], mean observation: 0.098 [-0.741, 1.321], mean_best_reward: --\n",
      " 11975/100000: episode: 586, duration: 0.013s, episode steps: 11, steps per second: 847, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.727 [0.000, 1.000], mean observation: -0.095 [-1.962, 1.207], mean_best_reward: --\n",
      " 11989/100000: episode: 587, duration: 0.011s, episode steps: 14, steps per second: 1288, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.786 [0.000, 1.000], mean observation: -0.113 [-2.609, 1.543], mean_best_reward: --\n",
      " 12003/100000: episode: 588, duration: 0.008s, episode steps: 14, steps per second: 1810, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.357 [0.000, 1.000], mean observation: 0.100 [-1.005, 1.520], mean_best_reward: --\n",
      " 12016/100000: episode: 589, duration: 0.008s, episode steps: 13, steps per second: 1643, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.231 [0.000, 1.000], mean observation: 0.107 [-1.615, 2.496], mean_best_reward: --\n",
      " 12031/100000: episode: 590, duration: 0.008s, episode steps: 15, steps per second: 1939, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.094 [-1.141, 1.987], mean_best_reward: --\n",
      " 12042/100000: episode: 591, duration: 0.006s, episode steps: 11, steps per second: 1796, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.909 [0.000, 1.000], mean observation: -0.136 [-2.776, 1.729], mean_best_reward: --\n",
      " 12059/100000: episode: 592, duration: 0.009s, episode steps: 17, steps per second: 1986, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.353 [0.000, 1.000], mean observation: 0.084 [-1.172, 1.728], mean_best_reward: --\n",
      " 12071/100000: episode: 593, duration: 0.006s, episode steps: 12, steps per second: 1846, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.833 [0.000, 1.000], mean observation: -0.112 [-2.526, 1.606], mean_best_reward: --\n",
      " 12080/100000: episode: 594, duration: 0.005s, episode steps: 9, steps per second: 1647, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.111 [0.000, 1.000], mean observation: 0.128 [-1.416, 2.289], mean_best_reward: --\n",
      " 12101/100000: episode: 595, duration: 0.011s, episode steps: 21, steps per second: 1923, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.286 [0.000, 1.000], mean observation: 0.015 [-1.795, 2.554], mean_best_reward: --\n",
      " 12121/100000: episode: 596, duration: 0.010s, episode steps: 20, steps per second: 1937, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.350 [0.000, 1.000], mean observation: 0.072 [-1.317, 2.084], mean_best_reward: --\n",
      " 12137/100000: episode: 597, duration: 0.009s, episode steps: 16, steps per second: 1854, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.375 [0.000, 1.000], mean observation: 0.065 [-1.029, 1.652], mean_best_reward: --\n",
      " 12147/100000: episode: 598, duration: 0.006s, episode steps: 10, steps per second: 1539, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.800 [0.000, 1.000], mean observation: -0.126 [-1.995, 1.218], mean_best_reward: --\n",
      " 12159/100000: episode: 599, duration: 0.007s, episode steps: 12, steps per second: 1668, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.122 [-2.091, 1.150], mean_best_reward: --\n",
      " 12177/100000: episode: 600, duration: 0.009s, episode steps: 18, steps per second: 1972, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.778 [0.000, 1.000], mean observation: -0.053 [-2.918, 1.958], mean_best_reward: --\n",
      " 12199/100000: episode: 601, duration: 0.011s, episode steps: 22, steps per second: 2040, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.636 [0.000, 1.000], mean observation: -0.088 [-2.044, 1.149], mean_best_reward: 61.000000\n",
      " 12218/100000: episode: 602, duration: 0.009s, episode steps: 19, steps per second: 2061, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.684 [0.000, 1.000], mean observation: -0.078 [-2.490, 1.567], mean_best_reward: --\n",
      " 12228/100000: episode: 603, duration: 0.006s, episode steps: 10, steps per second: 1580, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.900 [0.000, 1.000], mean observation: -0.126 [-2.515, 1.585], mean_best_reward: --\n",
      " 12253/100000: episode: 604, duration: 0.013s, episode steps: 25, steps per second: 1951, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: -0.100 [-1.101, 0.364], mean_best_reward: --\n",
      " 12264/100000: episode: 605, duration: 0.006s, episode steps: 11, steps per second: 1762, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.118 [-2.328, 1.409], mean_best_reward: --\n",
      " 12288/100000: episode: 606, duration: 0.011s, episode steps: 24, steps per second: 2188, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.542 [0.000, 1.000], mean observation: -0.107 [-1.279, 0.407], mean_best_reward: --\n",
      " 12298/100000: episode: 607, duration: 0.006s, episode steps: 10, steps per second: 1788, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.800 [0.000, 1.000], mean observation: -0.128 [-2.170, 1.388], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12316/100000: episode: 608, duration: 0.011s, episode steps: 18, steps per second: 1646, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.611 [0.000, 1.000], mean observation: -0.087 [-1.616, 0.783], mean_best_reward: --\n",
      " 12335/100000: episode: 609, duration: 0.011s, episode steps: 19, steps per second: 1668, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.579 [0.000, 1.000], mean observation: -0.095 [-1.344, 0.736], mean_best_reward: --\n",
      " 12348/100000: episode: 610, duration: 0.009s, episode steps: 13, steps per second: 1400, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.769 [0.000, 1.000], mean observation: -0.098 [-2.266, 1.415], mean_best_reward: --\n",
      " 12366/100000: episode: 611, duration: 0.013s, episode steps: 18, steps per second: 1345, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.778 [0.000, 1.000], mean observation: -0.074 [-2.982, 1.908], mean_best_reward: --\n",
      " 12386/100000: episode: 612, duration: 0.011s, episode steps: 20, steps per second: 1893, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.350 [0.000, 1.000], mean observation: 0.057 [-1.343, 2.201], mean_best_reward: --\n",
      " 12430/100000: episode: 613, duration: 0.021s, episode steps: 44, steps per second: 2133, episode reward: 44.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.047 [-0.748, 1.118], mean_best_reward: --\n",
      " 12442/100000: episode: 614, duration: 0.007s, episode steps: 12, steps per second: 1715, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.833 [0.000, 1.000], mean observation: -0.124 [-2.466, 1.528], mean_best_reward: --\n",
      " 12453/100000: episode: 615, duration: 0.007s, episode steps: 11, steps per second: 1674, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.109 [-2.421, 1.601], mean_best_reward: --\n",
      " 12469/100000: episode: 616, duration: 0.009s, episode steps: 16, steps per second: 1850, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.081 [-2.604, 1.599], mean_best_reward: --\n",
      " 12479/100000: episode: 617, duration: 0.006s, episode steps: 10, steps per second: 1686, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.800 [0.000, 1.000], mean observation: -0.127 [-2.023, 1.205], mean_best_reward: --\n",
      " 12493/100000: episode: 618, duration: 0.007s, episode steps: 14, steps per second: 1874, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.214 [0.000, 1.000], mean observation: 0.077 [-1.576, 2.416], mean_best_reward: --\n",
      " 12513/100000: episode: 619, duration: 0.009s, episode steps: 20, steps per second: 2108, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.650 [0.000, 1.000], mean observation: -0.066 [-1.975, 1.164], mean_best_reward: --\n",
      " 12523/100000: episode: 620, duration: 0.006s, episode steps: 10, steps per second: 1689, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 1.000 [1.000, 1.000], mean observation: -0.139 [-3.062, 1.969], mean_best_reward: --\n",
      " 12535/100000: episode: 621, duration: 0.006s, episode steps: 12, steps per second: 1898, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.071 [-1.031, 1.642], mean_best_reward: --\n",
      " 12554/100000: episode: 622, duration: 0.009s, episode steps: 19, steps per second: 2069, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.684 [0.000, 1.000], mean observation: -0.065 [-2.283, 1.394], mean_best_reward: --\n",
      " 12564/100000: episode: 623, duration: 0.006s, episode steps: 10, steps per second: 1715, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.900 [0.000, 1.000], mean observation: -0.118 [-2.567, 1.591], mean_best_reward: --\n",
      " 12575/100000: episode: 624, duration: 0.006s, episode steps: 11, steps per second: 1694, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.108 [-2.413, 1.585], mean_best_reward: --\n",
      " 12592/100000: episode: 625, duration: 0.009s, episode steps: 17, steps per second: 1797, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.765 [0.000, 1.000], mean observation: -0.099 [-2.928, 1.793], mean_best_reward: --\n",
      " 12603/100000: episode: 626, duration: 0.009s, episode steps: 11, steps per second: 1221, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.120 [-2.315, 1.351], mean_best_reward: --\n",
      " 12614/100000: episode: 627, duration: 0.006s, episode steps: 11, steps per second: 1765, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.182 [0.000, 1.000], mean observation: 0.131 [-1.365, 2.313], mean_best_reward: --\n",
      " 12624/100000: episode: 628, duration: 0.006s, episode steps: 10, steps per second: 1737, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.900 [0.000, 1.000], mean observation: -0.140 [-2.566, 1.553], mean_best_reward: --\n",
      " 12643/100000: episode: 629, duration: 0.010s, episode steps: 19, steps per second: 1953, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.632 [0.000, 1.000], mean observation: -0.089 [-2.050, 1.152], mean_best_reward: --\n",
      " 12652/100000: episode: 630, duration: 0.005s, episode steps: 9, steps per second: 1644, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.889 [0.000, 1.000], mean observation: -0.137 [-2.280, 1.353], mean_best_reward: --\n",
      " 12677/100000: episode: 631, duration: 0.014s, episode steps: 25, steps per second: 1811, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.400 [0.000, 1.000], mean observation: 0.078 [-0.963, 1.929], mean_best_reward: --\n",
      " 12697/100000: episode: 632, duration: 0.019s, episode steps: 20, steps per second: 1028, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.650 [0.000, 1.000], mean observation: -0.068 [-2.451, 1.555], mean_best_reward: --\n",
      " 12709/100000: episode: 633, duration: 0.007s, episode steps: 12, steps per second: 1710, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.122 [-2.008, 1.158], mean_best_reward: --\n",
      " 12777/100000: episode: 634, duration: 0.030s, episode steps: 68, steps per second: 2245, episode reward: 68.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.218 [-1.479, 0.454], mean_best_reward: --\n",
      " 12786/100000: episode: 635, duration: 0.006s, episode steps: 9, steps per second: 1532, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 1.000 [1.000, 1.000], mean observation: -0.146 [-2.861, 1.786], mean_best_reward: --\n",
      " 12800/100000: episode: 636, duration: 0.008s, episode steps: 14, steps per second: 1797, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.643 [0.000, 1.000], mean observation: -0.093 [-1.879, 1.159], mean_best_reward: --\n",
      " 12811/100000: episode: 637, duration: 0.007s, episode steps: 11, steps per second: 1588, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.136 [-2.510, 1.553], mean_best_reward: --\n",
      " 12830/100000: episode: 638, duration: 0.010s, episode steps: 19, steps per second: 1941, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.579 [0.000, 1.000], mean observation: -0.093 [-1.588, 0.767], mean_best_reward: --\n",
      " 12843/100000: episode: 639, duration: 0.007s, episode steps: 13, steps per second: 1805, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.769 [0.000, 1.000], mean observation: -0.105 [-2.340, 1.380], mean_best_reward: --\n",
      " 12863/100000: episode: 640, duration: 0.010s, episode steps: 20, steps per second: 2015, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.067 [-1.074, 0.623], mean_best_reward: --\n",
      " 12873/100000: episode: 641, duration: 0.006s, episode steps: 10, steps per second: 1723, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.900 [0.000, 1.000], mean observation: -0.141 [-2.664, 1.726], mean_best_reward: --\n",
      " 12913/100000: episode: 642, duration: 0.018s, episode steps: 40, steps per second: 2218, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.525 [0.000, 1.000], mean observation: 0.063 [-0.747, 1.087], mean_best_reward: --\n",
      " 12927/100000: episode: 643, duration: 0.007s, episode steps: 14, steps per second: 1914, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.643 [0.000, 1.000], mean observation: -0.114 [-1.559, 0.750], mean_best_reward: --\n",
      " 12937/100000: episode: 644, duration: 0.006s, episode steps: 10, steps per second: 1801, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.100 [0.000, 1.000], mean observation: 0.111 [-1.606, 2.583], mean_best_reward: --\n",
      " 12959/100000: episode: 645, duration: 0.010s, episode steps: 22, steps per second: 2188, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.119 [-0.369, 0.896], mean_best_reward: --\n",
      " 12972/100000: episode: 646, duration: 0.007s, episode steps: 13, steps per second: 1924, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.769 [0.000, 1.000], mean observation: -0.100 [-2.284, 1.375], mean_best_reward: --\n",
      " 12986/100000: episode: 647, duration: 0.007s, episode steps: 14, steps per second: 1898, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.714 [0.000, 1.000], mean observation: -0.101 [-1.964, 1.157], mean_best_reward: --\n",
      " 13002/100000: episode: 648, duration: 0.008s, episode steps: 16, steps per second: 2010, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.112 [-2.618, 1.534], mean_best_reward: --\n",
      " 13024/100000: episode: 649, duration: 0.010s, episode steps: 22, steps per second: 2158, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.682 [0.000, 1.000], mean observation: -0.045 [-2.410, 1.561], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13048/100000: episode: 650, duration: 0.012s, episode steps: 24, steps per second: 2080, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.040 [-2.471, 1.609], mean_best_reward: --\n",
      " 13064/100000: episode: 651, duration: 0.010s, episode steps: 16, steps per second: 1600, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.562 [0.000, 1.000], mean observation: -0.106 [-1.255, 0.557], mean_best_reward: 73.500000\n",
      " 13076/100000: episode: 652, duration: 0.011s, episode steps: 12, steps per second: 1096, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.113 [-2.184, 1.365], mean_best_reward: --\n",
      " 13136/100000: episode: 653, duration: 0.032s, episode steps: 60, steps per second: 1896, episode reward: 60.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.617 [0.000, 1.000], mean observation: 0.038 [-3.250, 2.707], mean_best_reward: --\n",
      " 13179/100000: episode: 654, duration: 0.020s, episode steps: 43, steps per second: 2101, episode reward: 43.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.465 [0.000, 1.000], mean observation: -0.061 [-0.916, 0.606], mean_best_reward: --\n",
      " 13211/100000: episode: 655, duration: 0.015s, episode steps: 32, steps per second: 2200, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.562 [0.000, 1.000], mean observation: -0.038 [-1.506, 0.812], mean_best_reward: --\n",
      " 13263/100000: episode: 656, duration: 0.024s, episode steps: 52, steps per second: 2191, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.025 [-0.646, 1.033], mean_best_reward: --\n",
      " 13282/100000: episode: 657, duration: 0.010s, episode steps: 19, steps per second: 1990, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.684 [0.000, 1.000], mean observation: -0.081 [-2.333, 1.356], mean_best_reward: --\n",
      " 13304/100000: episode: 658, duration: 0.012s, episode steps: 22, steps per second: 1894, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.103 [-0.567, 1.148], mean_best_reward: --\n",
      " 13338/100000: episode: 659, duration: 0.016s, episode steps: 34, steps per second: 2076, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.086 [-0.884, 0.582], mean_best_reward: --\n",
      " 13364/100000: episode: 660, duration: 0.012s, episode steps: 26, steps per second: 2187, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.121 [-0.954, 0.571], mean_best_reward: --\n",
      " 13376/100000: episode: 661, duration: 0.006s, episode steps: 12, steps per second: 1896, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.116 [-1.154, 1.844], mean_best_reward: --\n",
      " 13425/100000: episode: 662, duration: 0.022s, episode steps: 49, steps per second: 2261, episode reward: 49.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.078 [-0.610, 1.544], mean_best_reward: --\n",
      " 13465/100000: episode: 663, duration: 0.022s, episode steps: 40, steps per second: 1831, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.096 [-1.010, 0.530], mean_best_reward: --\n",
      " 13532/100000: episode: 664, duration: 0.035s, episode steps: 67, steps per second: 1896, episode reward: 67.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.507 [0.000, 1.000], mean observation: -0.021 [-0.983, 0.607], mean_best_reward: --\n",
      " 13682/100000: episode: 665, duration: 0.065s, episode steps: 150, steps per second: 2301, episode reward: 150.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.473 [0.000, 1.000], mean observation: -0.313 [-2.239, 1.166], mean_best_reward: --\n",
      " 13708/100000: episode: 666, duration: 0.012s, episode steps: 26, steps per second: 2177, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.731 [0.000, 1.000], mean observation: 0.007 [-3.190, 2.354], mean_best_reward: --\n",
      " 13745/100000: episode: 667, duration: 0.017s, episode steps: 37, steps per second: 2216, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: 0.074 [-0.575, 0.797], mean_best_reward: --\n",
      " 13829/100000: episode: 668, duration: 0.037s, episode steps: 84, steps per second: 2267, episode reward: 84.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.512 [0.000, 1.000], mean observation: -0.142 [-1.168, 0.909], mean_best_reward: --\n",
      " 13846/100000: episode: 669, duration: 0.010s, episode steps: 17, steps per second: 1630, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.647 [0.000, 1.000], mean observation: -0.077 [-1.969, 1.192], mean_best_reward: --\n",
      " 13857/100000: episode: 670, duration: 0.007s, episode steps: 11, steps per second: 1680, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.122 [-2.331, 1.376], mean_best_reward: --\n",
      " 13891/100000: episode: 671, duration: 0.018s, episode steps: 34, steps per second: 1849, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.069 [-0.912, 0.425], mean_best_reward: --\n",
      " 13917/100000: episode: 672, duration: 0.016s, episode steps: 26, steps per second: 1642, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: 0.065 [-0.547, 1.103], mean_best_reward: --\n",
      " 13996/100000: episode: 673, duration: 0.040s, episode steps: 79, steps per second: 1994, episode reward: 79.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.544 [0.000, 1.000], mean observation: 0.281 [-0.912, 1.839], mean_best_reward: --\n",
      " 14152/100000: episode: 674, duration: 0.066s, episode steps: 156, steps per second: 2379, episode reward: 156.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: -0.122 [-1.889, 1.811], mean_best_reward: --\n",
      " 14178/100000: episode: 675, duration: 0.012s, episode steps: 26, steps per second: 2152, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.100 [-0.886, 0.396], mean_best_reward: --\n",
      " 14265/100000: episode: 676, duration: 0.037s, episode steps: 87, steps per second: 2381, episode reward: 87.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.425 [0.000, 1.000], mean observation: -0.304 [-2.459, 1.774], mean_best_reward: --\n",
      " 14285/100000: episode: 677, duration: 0.010s, episode steps: 20, steps per second: 2060, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.071 [-1.922, 1.143], mean_best_reward: --\n",
      " 14328/100000: episode: 678, duration: 0.019s, episode steps: 43, steps per second: 2268, episode reward: 43.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.535 [0.000, 1.000], mean observation: 0.128 [-0.599, 1.012], mean_best_reward: --\n",
      " 14364/100000: episode: 679, duration: 0.025s, episode steps: 36, steps per second: 1461, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.105 [-0.563, 1.024], mean_best_reward: --\n",
      " 14394/100000: episode: 680, duration: 0.016s, episode steps: 30, steps per second: 1927, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.109 [-1.081, 0.415], mean_best_reward: --\n",
      " 14440/100000: episode: 681, duration: 0.021s, episode steps: 46, steps per second: 2182, episode reward: 46.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.522 [0.000, 1.000], mean observation: 0.134 [-0.551, 1.122], mean_best_reward: --\n",
      " 14453/100000: episode: 682, duration: 0.007s, episode steps: 13, steps per second: 1767, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: 0.110 [-0.567, 1.203], mean_best_reward: --\n",
      " 14470/100000: episode: 683, duration: 0.009s, episode steps: 17, steps per second: 1829, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.080 [-1.383, 0.823], mean_best_reward: --\n",
      " 14494/100000: episode: 684, duration: 0.012s, episode steps: 24, steps per second: 1987, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.094 [-0.948, 1.468], mean_best_reward: --\n",
      " 14537/100000: episode: 685, duration: 0.020s, episode steps: 43, steps per second: 2153, episode reward: 43.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.465 [0.000, 1.000], mean observation: -0.109 [-0.899, 0.565], mean_best_reward: --\n",
      " 14591/100000: episode: 686, duration: 0.024s, episode steps: 54, steps per second: 2216, episode reward: 54.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.556 [0.000, 1.000], mean observation: 0.153 [-0.821, 1.143], mean_best_reward: --\n",
      " 14682/100000: episode: 687, duration: 0.039s, episode steps: 91, steps per second: 2364, episode reward: 91.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.516 [0.000, 1.000], mean observation: 0.081 [-0.778, 0.755], mean_best_reward: --\n",
      " 14760/100000: episode: 688, duration: 0.033s, episode steps: 78, steps per second: 2390, episode reward: 78.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.487 [0.000, 1.000], mean observation: -0.098 [-1.088, 1.083], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14794/100000: episode: 689, duration: 0.017s, episode steps: 34, steps per second: 2044, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.676 [0.000, 1.000], mean observation: 0.008 [-2.983, 2.324], mean_best_reward: --\n",
      " 14850/100000: episode: 690, duration: 0.034s, episode steps: 56, steps per second: 1671, episode reward: 56.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.039 [-0.932, 1.350], mean_best_reward: --\n",
      " 14882/100000: episode: 691, duration: 0.016s, episode steps: 32, steps per second: 2056, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: 0.077 [-0.429, 1.288], mean_best_reward: --\n",
      " 14926/100000: episode: 692, duration: 0.021s, episode steps: 44, steps per second: 2128, episode reward: 44.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.052 [-0.975, 1.783], mean_best_reward: --\n",
      " 14951/100000: episode: 693, duration: 0.012s, episode steps: 25, steps per second: 2136, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: -0.031 [-1.634, 1.160], mean_best_reward: --\n",
      " 15005/100000: episode: 694, duration: 0.024s, episode steps: 54, steps per second: 2215, episode reward: 54.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.537 [0.000, 1.000], mean observation: -0.167 [-2.378, 1.349], mean_best_reward: --\n",
      " 15041/100000: episode: 695, duration: 0.016s, episode steps: 36, steps per second: 2234, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.639 [0.000, 1.000], mean observation: 0.057 [-2.645, 1.983], mean_best_reward: --\n",
      " 15093/100000: episode: 696, duration: 0.023s, episode steps: 52, steps per second: 2292, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.481 [0.000, 1.000], mean observation: -0.184 [-1.270, 0.244], mean_best_reward: --\n",
      " 15123/100000: episode: 697, duration: 0.014s, episode steps: 30, steps per second: 2176, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: 0.084 [-0.450, 1.406], mean_best_reward: --\n",
      " 15172/100000: episode: 698, duration: 0.022s, episode steps: 49, steps per second: 2270, episode reward: 49.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.449 [0.000, 1.000], mean observation: -0.110 [-0.893, 0.603], mean_best_reward: --\n",
      " 15249/100000: episode: 699, duration: 0.040s, episode steps: 77, steps per second: 1918, episode reward: 77.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.506 [0.000, 1.000], mean observation: -0.054 [-0.925, 0.930], mean_best_reward: --\n",
      " 15265/100000: episode: 700, duration: 0.012s, episode steps: 16, steps per second: 1341, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.688 [0.000, 1.000], mean observation: -0.071 [-1.985, 1.197], mean_best_reward: --\n",
      " 15300/100000: episode: 701, duration: 0.018s, episode steps: 35, steps per second: 1991, episode reward: 35.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.457 [0.000, 1.000], mean observation: -0.078 [-1.036, 0.409], mean_best_reward: 83.500000\n",
      " 15337/100000: episode: 702, duration: 0.017s, episode steps: 37, steps per second: 2208, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.486 [0.000, 1.000], mean observation: -0.061 [-0.988, 0.412], mean_best_reward: --\n",
      " 15450/100000: episode: 703, duration: 0.048s, episode steps: 113, steps per second: 2351, episode reward: 113.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.451 [0.000, 1.000], mean observation: -0.446 [-2.416, 0.878], mean_best_reward: --\n",
      " 15506/100000: episode: 704, duration: 0.026s, episode steps: 56, steps per second: 2181, episode reward: 56.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.446 [0.000, 1.000], mean observation: -0.156 [-1.595, 0.989], mean_best_reward: --\n",
      " 15563/100000: episode: 705, duration: 0.024s, episode steps: 57, steps per second: 2367, episode reward: 57.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.544 [0.000, 1.000], mean observation: 0.181 [-0.696, 1.513], mean_best_reward: --\n",
      " 15638/100000: episode: 706, duration: 0.032s, episode steps: 75, steps per second: 2344, episode reward: 75.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.387 [0.000, 1.000], mean observation: -0.292 [-3.380, 2.597], mean_best_reward: --\n",
      " 15695/100000: episode: 707, duration: 0.027s, episode steps: 57, steps per second: 2117, episode reward: 57.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.526 [0.000, 1.000], mean observation: 0.114 [-0.897, 1.117], mean_best_reward: --\n",
      " 15708/100000: episode: 708, duration: 0.008s, episode steps: 13, steps per second: 1572, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.385 [0.000, 1.000], mean observation: 0.107 [-0.826, 1.434], mean_best_reward: --\n",
      " 15812/100000: episode: 709, duration: 0.050s, episode steps: 104, steps per second: 2079, episode reward: 104.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: 0.071 [-0.857, 0.762], mean_best_reward: --\n",
      " 15846/100000: episode: 710, duration: 0.015s, episode steps: 34, steps per second: 2205, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.529 [0.000, 1.000], mean observation: -0.090 [-1.354, 0.534], mean_best_reward: --\n",
      " 15894/100000: episode: 711, duration: 0.021s, episode steps: 48, steps per second: 2239, episode reward: 48.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.069 [-0.566, 1.063], mean_best_reward: --\n",
      " 15938/100000: episode: 712, duration: 0.022s, episode steps: 44, steps per second: 1999, episode reward: 44.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.477 [0.000, 1.000], mean observation: -0.068 [-1.194, 0.577], mean_best_reward: --\n",
      " 15953/100000: episode: 713, duration: 0.008s, episode steps: 15, steps per second: 1845, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: 0.101 [-0.961, 1.614], mean_best_reward: --\n",
      " 15973/100000: episode: 714, duration: 0.010s, episode steps: 20, steps per second: 2073, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.550 [0.000, 1.000], mean observation: -0.063 [-1.110, 0.627], mean_best_reward: --\n",
      " 16011/100000: episode: 715, duration: 0.017s, episode steps: 38, steps per second: 2206, episode reward: 38.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.526 [0.000, 1.000], mean observation: 0.096 [-0.465, 0.866], mean_best_reward: --\n",
      " 16055/100000: episode: 716, duration: 0.020s, episode steps: 44, steps per second: 2203, episode reward: 44.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.523 [0.000, 1.000], mean observation: -0.005 [-1.212, 0.814], mean_best_reward: --\n",
      " 16080/100000: episode: 717, duration: 0.012s, episode steps: 25, steps per second: 2106, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: -0.061 [-1.404, 0.986], mean_best_reward: --\n",
      " 16095/100000: episode: 718, duration: 0.007s, episode steps: 15, steps per second: 2023, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.098 [-1.785, 0.968], mean_best_reward: --\n",
      " 16114/100000: episode: 719, duration: 0.011s, episode steps: 19, steps per second: 1772, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.421 [0.000, 1.000], mean observation: 0.058 [-0.970, 1.358], mean_best_reward: --\n",
      " 16139/100000: episode: 720, duration: 0.016s, episode steps: 25, steps per second: 1581, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: 0.112 [-0.568, 0.969], mean_best_reward: --\n",
      " 16162/100000: episode: 721, duration: 0.016s, episode steps: 23, steps per second: 1462, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.696 [0.000, 1.000], mean observation: -0.003 [-2.659, 1.964], mean_best_reward: --\n",
      " 16199/100000: episode: 722, duration: 0.017s, episode steps: 37, steps per second: 2133, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.486 [0.000, 1.000], mean observation: -0.128 [-1.208, 0.381], mean_best_reward: --\n",
      " 16227/100000: episode: 723, duration: 0.014s, episode steps: 28, steps per second: 2049, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.464 [0.000, 1.000], mean observation: 0.043 [-0.604, 1.190], mean_best_reward: --\n",
      " 16244/100000: episode: 724, duration: 0.008s, episode steps: 17, steps per second: 2022, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.529 [0.000, 1.000], mean observation: -0.112 [-1.289, 0.564], mean_best_reward: --\n",
      " 16265/100000: episode: 725, duration: 0.010s, episode steps: 21, steps per second: 2064, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.524 [0.000, 1.000], mean observation: -0.064 [-1.390, 0.810], mean_best_reward: --\n",
      " 16341/100000: episode: 726, duration: 0.032s, episode steps: 76, steps per second: 2390, episode reward: 76.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.447 [0.000, 1.000], mean observation: -0.132 [-1.845, 1.561], mean_best_reward: --\n",
      " 16367/100000: episode: 727, duration: 0.013s, episode steps: 26, steps per second: 2047, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.091 [-1.000, 0.580], mean_best_reward: --\n",
      " 16403/100000: episode: 728, duration: 0.017s, episode steps: 36, steps per second: 2083, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.556 [0.000, 1.000], mean observation: 0.148 [-0.377, 0.748], mean_best_reward: --\n",
      " 16416/100000: episode: 729, duration: 0.007s, episode steps: 13, steps per second: 1770, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.231 [0.000, 1.000], mean observation: 0.119 [-1.350, 2.380], mean_best_reward: --\n",
      " 16471/100000: episode: 730, duration: 0.026s, episode steps: 55, steps per second: 2115, episode reward: 55.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.473 [0.000, 1.000], mean observation: -0.133 [-1.095, 0.774], mean_best_reward: --\n",
      " 16480/100000: episode: 731, duration: 0.006s, episode steps: 9, steps per second: 1505, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 1.000 [1.000, 1.000], mean observation: -0.150 [-2.870, 1.794], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16507/100000: episode: 732, duration: 0.015s, episode steps: 27, steps per second: 1832, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.481 [0.000, 1.000], mean observation: -0.073 [-1.229, 0.790], mean_best_reward: --\n",
      " 16532/100000: episode: 733, duration: 0.014s, episode steps: 25, steps per second: 1759, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: 0.062 [-0.818, 1.235], mean_best_reward: --\n",
      " 16550/100000: episode: 734, duration: 0.013s, episode steps: 18, steps per second: 1343, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.084 [-1.222, 2.202], mean_best_reward: --\n",
      " 16571/100000: episode: 735, duration: 0.015s, episode steps: 21, steps per second: 1448, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: 0.066 [-0.794, 1.269], mean_best_reward: --\n",
      " 16686/100000: episode: 736, duration: 0.053s, episode steps: 115, steps per second: 2151, episode reward: 115.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.539 [0.000, 1.000], mean observation: 0.317 [-0.997, 2.054], mean_best_reward: --\n",
      " 16751/100000: episode: 737, duration: 0.030s, episode steps: 65, steps per second: 2133, episode reward: 65.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.508 [0.000, 1.000], mean observation: -0.053 [-1.102, 0.854], mean_best_reward: --\n",
      " 16824/100000: episode: 738, duration: 0.032s, episode steps: 73, steps per second: 2260, episode reward: 73.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.534 [0.000, 1.000], mean observation: 0.064 [-0.467, 0.881], mean_best_reward: --\n",
      " 16884/100000: episode: 739, duration: 0.028s, episode steps: 60, steps per second: 2116, episode reward: 60.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.483 [0.000, 1.000], mean observation: -0.061 [-0.833, 0.606], mean_best_reward: --\n",
      " 16915/100000: episode: 740, duration: 0.019s, episode steps: 31, steps per second: 1621, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.548 [0.000, 1.000], mean observation: 0.054 [-0.632, 1.082], mean_best_reward: --\n",
      " 16987/100000: episode: 741, duration: 0.046s, episode steps: 72, steps per second: 1552, episode reward: 72.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.213 [-2.111, 0.772], mean_best_reward: --\n",
      " 17019/100000: episode: 742, duration: 0.019s, episode steps: 32, steps per second: 1676, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.143 [-0.547, 1.274], mean_best_reward: --\n",
      " 17031/100000: episode: 743, duration: 0.006s, episode steps: 12, steps per second: 1862, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.417 [0.000, 1.000], mean observation: 0.121 [-0.748, 1.324], mean_best_reward: --\n",
      " 17044/100000: episode: 744, duration: 0.007s, episode steps: 13, steps per second: 1739, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.769 [0.000, 1.000], mean observation: -0.088 [-2.379, 1.578], mean_best_reward: --\n",
      " 17075/100000: episode: 745, duration: 0.015s, episode steps: 31, steps per second: 2065, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.548 [0.000, 1.000], mean observation: -0.059 [-1.545, 0.651], mean_best_reward: --\n",
      " 17124/100000: episode: 746, duration: 0.021s, episode steps: 49, steps per second: 2365, episode reward: 49.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.531 [0.000, 1.000], mean observation: 0.105 [-0.759, 1.370], mean_best_reward: --\n",
      " 17213/100000: episode: 747, duration: 0.037s, episode steps: 89, steps per second: 2400, episode reward: 89.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.528 [0.000, 1.000], mean observation: 0.257 [-0.754, 1.512], mean_best_reward: --\n",
      " 17229/100000: episode: 748, duration: 0.008s, episode steps: 16, steps per second: 1946, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.625 [0.000, 1.000], mean observation: -0.069 [-1.611, 1.008], mean_best_reward: --\n",
      " 17301/100000: episode: 749, duration: 0.030s, episode steps: 72, steps per second: 2383, episode reward: 72.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: -0.051 [-1.626, 0.534], mean_best_reward: --\n",
      " 17335/100000: episode: 750, duration: 0.020s, episode steps: 34, steps per second: 1720, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.559 [0.000, 1.000], mean observation: -0.038 [-1.608, 0.933], mean_best_reward: --\n",
      " 17395/100000: episode: 751, duration: 0.033s, episode steps: 60, steps per second: 1807, episode reward: 60.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.517 [0.000, 1.000], mean observation: 0.054 [-0.553, 0.752], mean_best_reward: 96.500000\n",
      " 17525/100000: episode: 752, duration: 0.056s, episode steps: 130, steps per second: 2307, episode reward: 130.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.531 [0.000, 1.000], mean observation: 0.222 [-1.008, 1.840], mean_best_reward: --\n",
      " 17540/100000: episode: 753, duration: 0.008s, episode steps: 15, steps per second: 1815, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.533 [0.000, 1.000], mean observation: -0.093 [-1.238, 0.642], mean_best_reward: --\n",
      " 17618/100000: episode: 754, duration: 0.032s, episode steps: 78, steps per second: 2407, episode reward: 78.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.436 [0.000, 1.000], mean observation: -0.214 [-2.480, 1.824], mean_best_reward: --\n",
      " 17668/100000: episode: 755, duration: 0.022s, episode steps: 50, steps per second: 2324, episode reward: 50.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.540 [0.000, 1.000], mean observation: 0.141 [-0.341, 0.789], mean_best_reward: --\n",
      " 17732/100000: episode: 756, duration: 0.026s, episode steps: 64, steps per second: 2424, episode reward: 64.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.562 [0.000, 1.000], mean observation: 0.345 [-0.619, 1.995], mean_best_reward: --\n",
      " 17783/100000: episode: 757, duration: 0.023s, episode steps: 51, steps per second: 2227, episode reward: 51.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.057 [-0.934, 0.812], mean_best_reward: --\n",
      " 17795/100000: episode: 758, duration: 0.008s, episode steps: 12, steps per second: 1550, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.134 [-2.195, 1.331], mean_best_reward: --\n",
      " 17829/100000: episode: 759, duration: 0.023s, episode steps: 34, steps per second: 1483, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.441 [0.000, 1.000], mean observation: -0.102 [-0.952, 0.549], mean_best_reward: --\n",
      " 17876/100000: episode: 760, duration: 0.021s, episode steps: 47, steps per second: 2202, episode reward: 47.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.468 [0.000, 1.000], mean observation: -0.148 [-0.932, 0.378], mean_best_reward: --\n",
      " 17937/100000: episode: 761, duration: 0.031s, episode steps: 61, steps per second: 1997, episode reward: 61.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.459 [0.000, 1.000], mean observation: -0.174 [-1.116, 0.614], mean_best_reward: --\n",
      " 17990/100000: episode: 762, duration: 0.023s, episode steps: 53, steps per second: 2354, episode reward: 53.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.491 [0.000, 1.000], mean observation: -0.156 [-1.476, 0.567], mean_best_reward: --\n",
      " 18003/100000: episode: 763, duration: 0.007s, episode steps: 13, steps per second: 1876, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: -0.119 [-1.808, 1.133], mean_best_reward: --\n",
      " 18098/100000: episode: 764, duration: 0.040s, episode steps: 95, steps per second: 2366, episode reward: 95.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.516 [0.000, 1.000], mean observation: 0.139 [-0.806, 1.161], mean_best_reward: --\n",
      " 18113/100000: episode: 765, duration: 0.008s, episode steps: 15, steps per second: 1931, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.533 [0.000, 1.000], mean observation: -0.085 [-1.367, 0.774], mean_best_reward: --\n",
      " 18137/100000: episode: 766, duration: 0.011s, episode steps: 24, steps per second: 2153, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.542 [0.000, 1.000], mean observation: 0.108 [-0.358, 0.909], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18202/100000: episode: 767, duration: 0.028s, episode steps: 65, steps per second: 2322, episode reward: 65.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.492 [0.000, 1.000], mean observation: 0.019 [-0.842, 1.579], mean_best_reward: --\n",
      " 18212/100000: episode: 768, duration: 0.007s, episode steps: 10, steps per second: 1533, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.700 [0.000, 1.000], mean observation: -0.110 [-1.551, 1.029], mean_best_reward: --\n",
      " 18235/100000: episode: 769, duration: 0.019s, episode steps: 23, steps per second: 1215, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: 0.102 [-0.578, 1.155], mean_best_reward: --\n",
      " 18306/100000: episode: 770, duration: 0.032s, episode steps: 71, steps per second: 2217, episode reward: 71.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.563 [0.000, 1.000], mean observation: 0.125 [-1.671, 1.687], mean_best_reward: --\n",
      " 18321/100000: episode: 771, duration: 0.008s, episode steps: 15, steps per second: 1823, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.090 [-1.485, 0.802], mean_best_reward: --\n",
      " 18361/100000: episode: 772, duration: 0.018s, episode steps: 40, steps per second: 2277, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.091 [-1.322, 0.794], mean_best_reward: --\n",
      " 18393/100000: episode: 773, duration: 0.014s, episode steps: 32, steps per second: 2221, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.089 [-1.435, 0.599], mean_best_reward: --\n",
      " 18491/100000: episode: 774, duration: 0.041s, episode steps: 98, steps per second: 2388, episode reward: 98.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.010 [-0.904, 1.050], mean_best_reward: --\n",
      " 18539/100000: episode: 775, duration: 0.025s, episode steps: 48, steps per second: 1902, episode reward: 48.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.122 [-1.400, 0.486], mean_best_reward: --\n",
      " 18571/100000: episode: 776, duration: 0.015s, episode steps: 32, steps per second: 2204, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: -0.100 [-0.778, 0.398], mean_best_reward: --\n",
      " 18582/100000: episode: 777, duration: 0.006s, episode steps: 11, steps per second: 1779, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.727 [0.000, 1.000], mean observation: -0.123 [-1.703, 0.973], mean_best_reward: --\n",
      " 18592/100000: episode: 778, duration: 0.006s, episode steps: 10, steps per second: 1728, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.700 [0.000, 1.000], mean observation: -0.147 [-1.908, 1.127], mean_best_reward: --\n",
      " 18645/100000: episode: 779, duration: 0.025s, episode steps: 53, steps per second: 2156, episode reward: 53.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.547 [0.000, 1.000], mean observation: -0.012 [-2.000, 1.026], mean_best_reward: --\n",
      " 18665/100000: episode: 780, duration: 0.014s, episode steps: 20, steps per second: 1436, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.117 [-0.930, 0.542], mean_best_reward: --\n",
      " 18718/100000: episode: 781, duration: 0.028s, episode steps: 53, steps per second: 1894, episode reward: 53.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.509 [0.000, 1.000], mean observation: 0.033 [-0.932, 1.393], mean_best_reward: --\n",
      " 18741/100000: episode: 782, duration: 0.013s, episode steps: 23, steps per second: 1721, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.696 [0.000, 1.000], mean observation: -0.027 [-2.650, 1.754], mean_best_reward: --\n",
      " 18757/100000: episode: 783, duration: 0.010s, episode steps: 16, steps per second: 1635, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.625 [0.000, 1.000], mean observation: -0.088 [-1.619, 0.939], mean_best_reward: --\n",
      " 18805/100000: episode: 784, duration: 0.023s, episode steps: 48, steps per second: 2122, episode reward: 48.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.037 [-1.357, 0.758], mean_best_reward: --\n",
      " 18881/100000: episode: 785, duration: 0.035s, episode steps: 76, steps per second: 2182, episode reward: 76.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.447 [0.000, 1.000], mean observation: -0.195 [-1.734, 1.423], mean_best_reward: --\n",
      " 18906/100000: episode: 786, duration: 0.012s, episode steps: 25, steps per second: 2000, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.109 [-0.940, 0.375], mean_best_reward: --\n",
      " 18944/100000: episode: 787, duration: 0.018s, episode steps: 38, steps per second: 2141, episode reward: 38.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.342 [0.000, 1.000], mean observation: -0.061 [-2.342, 2.940], mean_best_reward: --\n",
      " 18983/100000: episode: 788, duration: 0.019s, episode steps: 39, steps per second: 2016, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.487 [0.000, 1.000], mean observation: -0.033 [-1.459, 1.118], mean_best_reward: --\n",
      " 19007/100000: episode: 789, duration: 0.012s, episode steps: 24, steps per second: 1999, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.089 [-0.924, 0.550], mean_best_reward: --\n",
      " 19017/100000: episode: 790, duration: 0.006s, episode steps: 10, steps per second: 1731, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.700 [0.000, 1.000], mean observation: -0.123 [-1.872, 1.149], mean_best_reward: --\n",
      " 19045/100000: episode: 791, duration: 0.017s, episode steps: 28, steps per second: 1675, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.464 [0.000, 1.000], mean observation: -0.069 [-0.858, 0.588], mean_best_reward: --\n",
      " 19144/100000: episode: 792, duration: 0.052s, episode steps: 99, steps per second: 1887, episode reward: 99.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: -0.254 [-1.912, 1.503], mean_best_reward: --\n",
      " 19206/100000: episode: 793, duration: 0.027s, episode steps: 62, steps per second: 2295, episode reward: 62.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.144 [-1.598, 0.609], mean_best_reward: --\n",
      " 19257/100000: episode: 794, duration: 0.024s, episode steps: 51, steps per second: 2170, episode reward: 51.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.032 [-0.942, 0.443], mean_best_reward: --\n",
      " 19292/100000: episode: 795, duration: 0.016s, episode steps: 35, steps per second: 2202, episode reward: 35.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.486 [0.000, 1.000], mean observation: -0.075 [-1.406, 0.646], mean_best_reward: --\n",
      " 19319/100000: episode: 796, duration: 0.012s, episode steps: 27, steps per second: 2216, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.556 [0.000, 1.000], mean observation: -0.041 [-1.468, 0.969], mean_best_reward: --\n",
      " 19331/100000: episode: 797, duration: 0.007s, episode steps: 12, steps per second: 1774, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.094 [-1.805, 1.148], mean_best_reward: --\n",
      " 19357/100000: episode: 798, duration: 0.012s, episode steps: 26, steps per second: 2169, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: -0.117 [-1.440, 0.411], mean_best_reward: --\n",
      " 19475/100000: episode: 799, duration: 0.049s, episode steps: 118, steps per second: 2398, episode reward: 118.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.508 [0.000, 1.000], mean observation: 0.069 [-1.147, 1.133], mean_best_reward: --\n",
      " 19510/100000: episode: 800, duration: 0.022s, episode steps: 35, steps per second: 1612, episode reward: 35.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.486 [0.000, 1.000], mean observation: -0.069 [-1.059, 0.732], mean_best_reward: --\n",
      " 19537/100000: episode: 801, duration: 0.017s, episode steps: 27, steps per second: 1569, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.519 [0.000, 1.000], mean observation: -0.078 [-1.348, 0.603], mean_best_reward: 155.500000\n",
      " 19547/100000: episode: 802, duration: 0.006s, episode steps: 10, steps per second: 1653, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.700 [0.000, 1.000], mean observation: -0.151 [-1.985, 1.145], mean_best_reward: --\n",
      " 19578/100000: episode: 803, duration: 0.015s, episode steps: 31, steps per second: 2115, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.548 [0.000, 1.000], mean observation: 0.121 [-0.570, 1.208], mean_best_reward: --\n",
      " 19596/100000: episode: 804, duration: 0.009s, episode steps: 18, steps per second: 2010, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.090 [-2.044, 1.149], mean_best_reward: --\n",
      " 19613/100000: episode: 805, duration: 0.009s, episode steps: 17, steps per second: 1993, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.087 [-1.191, 0.749], mean_best_reward: --\n",
      " 19632/100000: episode: 806, duration: 0.009s, episode steps: 19, steps per second: 2011, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.579 [0.000, 1.000], mean observation: -0.058 [-1.229, 0.808], mean_best_reward: --\n",
      " 19642/100000: episode: 807, duration: 0.006s, episode steps: 10, steps per second: 1675, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.900 [0.000, 1.000], mean observation: -0.135 [-2.502, 1.581], mean_best_reward: --\n",
      " 19656/100000: episode: 808, duration: 0.008s, episode steps: 14, steps per second: 1673, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.786 [0.000, 1.000], mean observation: -0.106 [-2.603, 1.586], mean_best_reward: --\n",
      " 19719/100000: episode: 809, duration: 0.031s, episode steps: 63, steps per second: 2005, episode reward: 63.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: -0.023 [-0.929, 0.505], mean_best_reward: --\n",
      " 19751/100000: episode: 810, duration: 0.015s, episode steps: 32, steps per second: 2100, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.438 [0.000, 1.000], mean observation: 0.061 [-0.757, 1.518], mean_best_reward: --\n",
      " 19784/100000: episode: 811, duration: 0.016s, episode steps: 33, steps per second: 2081, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: -0.029 [-1.352, 0.928], mean_best_reward: --\n",
      " 19821/100000: episode: 812, duration: 0.016s, episode steps: 37, steps per second: 2291, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.541 [0.000, 1.000], mean observation: 0.134 [-0.432, 0.891], mean_best_reward: --\n",
      " 19840/100000: episode: 813, duration: 0.009s, episode steps: 19, steps per second: 2083, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: 0.113 [-0.759, 1.295], mean_best_reward: --\n",
      " 19851/100000: episode: 814, duration: 0.006s, episode steps: 11, steps per second: 1811, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.909 [0.000, 1.000], mean observation: -0.099 [-2.672, 1.804], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19889/100000: episode: 815, duration: 0.030s, episode steps: 38, steps per second: 1264, episode reward: 38.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.447 [0.000, 1.000], mean observation: -0.128 [-0.741, 0.379], mean_best_reward: --\n",
      " 19902/100000: episode: 816, duration: 0.011s, episode steps: 13, steps per second: 1154, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.692 [0.000, 1.000], mean observation: -0.116 [-1.815, 0.992], mean_best_reward: --\n",
      " 19943/100000: episode: 817, duration: 0.021s, episode steps: 41, steps per second: 1908, episode reward: 41.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.537 [0.000, 1.000], mean observation: 0.139 [-0.376, 0.924], mean_best_reward: --\n",
      " 20041/100000: episode: 818, duration: 0.048s, episode steps: 98, steps per second: 2024, episode reward: 98.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.112 [-1.162, 1.219], mean_best_reward: --\n",
      " 20080/100000: episode: 819, duration: 0.018s, episode steps: 39, steps per second: 2129, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.513 [0.000, 1.000], mean observation: 0.032 [-0.627, 1.161], mean_best_reward: --\n",
      " 20090/100000: episode: 820, duration: 0.006s, episode steps: 10, steps per second: 1700, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.700 [0.000, 1.000], mean observation: -0.099 [-1.584, 1.020], mean_best_reward: --\n",
      " 20102/100000: episode: 821, duration: 0.006s, episode steps: 12, steps per second: 1874, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.833 [0.000, 1.000], mean observation: -0.073 [-2.409, 1.607], mean_best_reward: --\n",
      " 20114/100000: episode: 822, duration: 0.007s, episode steps: 12, steps per second: 1804, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.833 [0.000, 1.000], mean observation: -0.114 [-2.540, 1.566], mean_best_reward: --\n",
      " 20134/100000: episode: 823, duration: 0.010s, episode steps: 20, steps per second: 1962, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.700 [0.000, 1.000], mean observation: -0.064 [-2.620, 1.590], mean_best_reward: --\n",
      " 20240/100000: episode: 824, duration: 0.045s, episode steps: 106, steps per second: 2365, episode reward: 106.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.509 [0.000, 1.000], mean observation: 0.020 [-0.897, 1.134], mean_best_reward: --\n",
      " 20292/100000: episode: 825, duration: 0.022s, episode steps: 52, steps per second: 2325, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.154 [-0.922, 0.442], mean_best_reward: --\n",
      " 20320/100000: episode: 826, duration: 0.022s, episode steps: 28, steps per second: 1298, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.571 [0.000, 1.000], mean observation: -0.056 [-1.706, 0.844], mean_best_reward: --\n",
      " 20360/100000: episode: 827, duration: 0.023s, episode steps: 40, steps per second: 1737, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.046 [-1.042, 0.751], mean_best_reward: --\n",
      " 20397/100000: episode: 828, duration: 0.018s, episode steps: 37, steps per second: 2081, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: -0.093 [-1.272, 0.416], mean_best_reward: --\n",
      " 20468/100000: episode: 829, duration: 0.030s, episode steps: 71, steps per second: 2374, episode reward: 71.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.493 [0.000, 1.000], mean observation: -0.049 [-1.118, 1.197], mean_best_reward: --\n",
      " 20579/100000: episode: 830, duration: 0.046s, episode steps: 111, steps per second: 2407, episode reward: 111.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.450 [0.000, 1.000], mean observation: -0.286 [-2.037, 0.844], mean_best_reward: --\n",
      " 20594/100000: episode: 831, duration: 0.008s, episode steps: 15, steps per second: 1859, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.733 [0.000, 1.000], mean observation: -0.103 [-2.444, 1.525], mean_best_reward: --\n",
      " 20608/100000: episode: 832, duration: 0.007s, episode steps: 14, steps per second: 1907, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.857 [0.000, 1.000], mean observation: -0.057 [-2.941, 1.978], mean_best_reward: --\n",
      " 20671/100000: episode: 833, duration: 0.027s, episode steps: 63, steps per second: 2296, episode reward: 63.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.460 [0.000, 1.000], mean observation: -0.089 [-1.933, 1.844], mean_best_reward: --\n",
      " 20705/100000: episode: 834, duration: 0.015s, episode steps: 34, steps per second: 2235, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.529 [0.000, 1.000], mean observation: -0.112 [-1.576, 0.568], mean_best_reward: --\n",
      " 20729/100000: episode: 835, duration: 0.012s, episode steps: 24, steps per second: 2058, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.458 [0.000, 1.000], mean observation: -0.094 [-0.728, 0.422], mean_best_reward: --\n",
      " 20742/100000: episode: 836, duration: 0.007s, episode steps: 13, steps per second: 1873, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.769 [0.000, 1.000], mean observation: -0.126 [-2.374, 1.370], mean_best_reward: --\n",
      " 20807/100000: episode: 837, duration: 0.043s, episode steps: 65, steps per second: 1525, episode reward: 65.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.523 [0.000, 1.000], mean observation: 0.006 [-1.499, 0.802], mean_best_reward: --\n",
      " 20829/100000: episode: 838, duration: 0.011s, episode steps: 22, steps per second: 1979, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.636 [0.000, 1.000], mean observation: -0.076 [-2.062, 1.135], mean_best_reward: --\n",
      " 20841/100000: episode: 839, duration: 0.007s, episode steps: 12, steps per second: 1752, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.833 [0.000, 1.000], mean observation: -0.102 [-2.501, 1.557], mean_best_reward: --\n",
      " 20863/100000: episode: 840, duration: 0.011s, episode steps: 22, steps per second: 1975, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: -0.088 [-1.360, 0.802], mean_best_reward: --\n",
      " 20872/100000: episode: 841, duration: 0.006s, episode steps: 9, steps per second: 1621, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.889 [0.000, 1.000], mean observation: -0.161 [-2.349, 1.385], mean_best_reward: --\n",
      " 20883/100000: episode: 842, duration: 0.006s, episode steps: 11, steps per second: 1725, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.106 [-2.452, 1.553], mean_best_reward: --\n",
      " 20961/100000: episode: 843, duration: 0.032s, episode steps: 78, steps per second: 2424, episode reward: 78.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.449 [0.000, 1.000], mean observation: -0.204 [-1.735, 1.590], mean_best_reward: --\n",
      " 20988/100000: episode: 844, duration: 0.012s, episode steps: 27, steps per second: 2214, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.016 [-2.576, 1.737], mean_best_reward: --\n",
      " 21088/100000: episode: 845, duration: 0.042s, episode steps: 100, steps per second: 2390, episode reward: 100.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: -0.012 [-1.008, 0.994], mean_best_reward: --\n",
      " 21165/100000: episode: 846, duration: 0.032s, episode steps: 77, steps per second: 2387, episode reward: 77.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.519 [0.000, 1.000], mean observation: 0.051 [-1.594, 0.943], mean_best_reward: --\n",
      " 21198/100000: episode: 847, duration: 0.015s, episode steps: 33, steps per second: 2197, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: -0.152 [-1.040, 0.598], mean_best_reward: --\n",
      " 21238/100000: episode: 848, duration: 0.018s, episode steps: 40, steps per second: 2264, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.103 [-0.910, 0.506], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21260/100000: episode: 849, duration: 0.012s, episode steps: 22, steps per second: 1839, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.083 [-1.444, 1.008], mean_best_reward: --\n",
      " 21279/100000: episode: 850, duration: 0.015s, episode steps: 19, steps per second: 1271, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.579 [0.000, 1.000], mean observation: -0.077 [-1.417, 0.638], mean_best_reward: --\n",
      " 21310/100000: episode: 851, duration: 0.016s, episode steps: 31, steps per second: 1944, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.548 [0.000, 1.000], mean observation: -0.068 [-1.450, 0.786], mean_best_reward: 83.000000\n",
      " 21375/100000: episode: 852, duration: 0.029s, episode steps: 65, steps per second: 2224, episode reward: 65.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.492 [0.000, 1.000], mean observation: -0.021 [-1.118, 1.276], mean_best_reward: --\n",
      " 21399/100000: episode: 853, duration: 0.011s, episode steps: 24, steps per second: 2130, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.057 [-0.781, 1.333], mean_best_reward: --\n",
      " 21433/100000: episode: 854, duration: 0.015s, episode steps: 34, steps per second: 2292, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.120 [-0.552, 1.192], mean_best_reward: --\n",
      " 21517/100000: episode: 855, duration: 0.035s, episode steps: 84, steps per second: 2397, episode reward: 84.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: -0.136 [-2.477, 2.281], mean_best_reward: --\n",
      " 21555/100000: episode: 856, duration: 0.017s, episode steps: 38, steps per second: 2196, episode reward: 38.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.316 [0.000, 1.000], mean observation: -0.041 [-2.730, 3.463], mean_best_reward: --\n",
      " 21625/100000: episode: 857, duration: 0.030s, episode steps: 70, steps per second: 2357, episode reward: 70.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.457 [0.000, 1.000], mean observation: -0.167 [-1.532, 1.365], mean_best_reward: --\n",
      " 21645/100000: episode: 858, duration: 0.009s, episode steps: 20, steps per second: 2121, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.550 [0.000, 1.000], mean observation: -0.059 [-1.008, 0.578], mean_best_reward: --\n",
      " 21654/100000: episode: 859, duration: 0.006s, episode steps: 9, steps per second: 1609, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.889 [0.000, 1.000], mean observation: -0.156 [-2.277, 1.344], mean_best_reward: --\n",
      " 21750/100000: episode: 860, duration: 0.051s, episode steps: 96, steps per second: 1883, episode reward: 96.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.149 [-1.474, 1.146], mean_best_reward: --\n",
      " 21800/100000: episode: 861, duration: 0.023s, episode steps: 50, steps per second: 2215, episode reward: 50.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: -0.067 [-1.509, 0.884], mean_best_reward: --\n",
      " 21849/100000: episode: 862, duration: 0.023s, episode steps: 49, steps per second: 2116, episode reward: 49.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.156 [-1.359, 0.394], mean_best_reward: --\n",
      " 21898/100000: episode: 863, duration: 0.023s, episode steps: 49, steps per second: 2150, episode reward: 49.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.449 [0.000, 1.000], mean observation: -0.153 [-1.544, 1.362], mean_best_reward: --\n",
      " 21944/100000: episode: 864, duration: 0.022s, episode steps: 46, steps per second: 2139, episode reward: 46.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.522 [0.000, 1.000], mean observation: 0.042 [-0.605, 1.006], mean_best_reward: --\n",
      " 21972/100000: episode: 865, duration: 0.012s, episode steps: 28, steps per second: 2251, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.085 [-0.604, 0.949], mean_best_reward: --\n",
      " 22011/100000: episode: 866, duration: 0.017s, episode steps: 39, steps per second: 2326, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.487 [0.000, 1.000], mean observation: -0.060 [-1.085, 0.579], mean_best_reward: --\n",
      " 22067/100000: episode: 867, duration: 0.024s, episode steps: 56, steps per second: 2346, episode reward: 56.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.464 [0.000, 1.000], mean observation: -0.144 [-1.077, 0.774], mean_best_reward: --\n",
      " 22094/100000: episode: 868, duration: 0.013s, episode steps: 27, steps per second: 2133, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.481 [0.000, 1.000], mean observation: 0.050 [-0.778, 1.166], mean_best_reward: --\n",
      " 22110/100000: episode: 869, duration: 0.008s, episode steps: 16, steps per second: 1931, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.688 [0.000, 1.000], mean observation: -0.087 [-2.053, 1.147], mean_best_reward: --\n",
      " 22140/100000: episode: 870, duration: 0.014s, episode steps: 30, steps per second: 2199, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.061 [-0.904, 0.598], mean_best_reward: --\n",
      " 22166/100000: episode: 871, duration: 0.012s, episode steps: 26, steps per second: 2130, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.114 [-0.382, 0.965], mean_best_reward: --\n",
      " 22180/100000: episode: 872, duration: 0.008s, episode steps: 14, steps per second: 1726, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: 0.084 [-0.831, 1.315], mean_best_reward: --\n",
      " 22204/100000: episode: 873, duration: 0.016s, episode steps: 24, steps per second: 1540, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.542 [0.000, 1.000], mean observation: -0.080 [-1.199, 0.762], mean_best_reward: --\n",
      " 22248/100000: episode: 874, duration: 0.024s, episode steps: 44, steps per second: 1838, episode reward: 44.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.523 [0.000, 1.000], mean observation: -0.103 [-1.829, 0.767], mean_best_reward: --\n",
      " 22265/100000: episode: 875, duration: 0.009s, episode steps: 17, steps per second: 1828, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.529 [0.000, 1.000], mean observation: -0.095 [-1.253, 0.776], mean_best_reward: --\n",
      " 22282/100000: episode: 876, duration: 0.009s, episode steps: 17, steps per second: 1948, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.706 [0.000, 1.000], mean observation: -0.042 [-2.383, 1.609], mean_best_reward: --\n",
      " 22295/100000: episode: 877, duration: 0.007s, episode steps: 13, steps per second: 1786, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.385 [0.000, 1.000], mean observation: 0.085 [-1.011, 1.530], mean_best_reward: --\n",
      " 22311/100000: episode: 878, duration: 0.008s, episode steps: 16, steps per second: 1964, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.312 [0.000, 1.000], mean observation: 0.102 [-1.172, 2.126], mean_best_reward: --\n",
      " 22361/100000: episode: 879, duration: 0.022s, episode steps: 50, steps per second: 2308, episode reward: 50.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: 0.030 [-0.800, 1.217], mean_best_reward: --\n",
      " 22376/100000: episode: 880, duration: 0.008s, episode steps: 15, steps per second: 1889, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.533 [0.000, 1.000], mean observation: 0.118 [-0.602, 1.121], mean_best_reward: --\n",
      " 22493/100000: episode: 881, duration: 0.048s, episode steps: 117, steps per second: 2452, episode reward: 117.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: 0.278 [-1.173, 1.883], mean_best_reward: --\n",
      " 22555/100000: episode: 882, duration: 0.027s, episode steps: 62, steps per second: 2293, episode reward: 62.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.468 [0.000, 1.000], mean observation: -0.123 [-1.173, 0.933], mean_best_reward: --\n",
      " 22584/100000: episode: 883, duration: 0.014s, episode steps: 29, steps per second: 2033, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.517 [0.000, 1.000], mean observation: -0.060 [-1.272, 0.638], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22595/100000: episode: 884, duration: 0.007s, episode steps: 11, steps per second: 1533, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.727 [0.000, 1.000], mean observation: -0.127 [-1.936, 1.223], mean_best_reward: --\n",
      " 22637/100000: episode: 885, duration: 0.026s, episode steps: 42, steps per second: 1591, episode reward: 42.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.112 [-0.958, 0.568], mean_best_reward: --\n",
      " 22671/100000: episode: 886, duration: 0.016s, episode steps: 34, steps per second: 2126, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.070 [-0.656, 1.466], mean_best_reward: --\n",
      " 22698/100000: episode: 887, duration: 0.013s, episode steps: 27, steps per second: 2125, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.481 [0.000, 1.000], mean observation: -0.095 [-1.445, 0.956], mean_best_reward: --\n",
      " 22762/100000: episode: 888, duration: 0.029s, episode steps: 64, steps per second: 2224, episode reward: 64.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.484 [0.000, 1.000], mean observation: -0.134 [-1.165, 0.980], mean_best_reward: --\n",
      " 22772/100000: episode: 889, duration: 0.006s, episode steps: 10, steps per second: 1732, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.119 [-1.631, 1.016], mean_best_reward: --\n",
      " 22796/100000: episode: 890, duration: 0.011s, episode steps: 24, steps per second: 2177, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.542 [0.000, 1.000], mean observation: -0.085 [-1.236, 0.768], mean_best_reward: --\n",
      " 22873/100000: episode: 891, duration: 0.032s, episode steps: 77, steps per second: 2403, episode reward: 77.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.571 [0.000, 1.000], mean observation: 0.225 [-1.461, 2.223], mean_best_reward: --\n",
      " 22948/100000: episode: 892, duration: 0.033s, episode steps: 75, steps per second: 2261, episode reward: 75.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.029 [-1.058, 0.662], mean_best_reward: --\n",
      " 22959/100000: episode: 893, duration: 0.006s, episode steps: 11, steps per second: 1716, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.636 [0.000, 1.000], mean observation: -0.126 [-1.835, 1.177], mean_best_reward: --\n",
      " 22997/100000: episode: 894, duration: 0.017s, episode steps: 38, steps per second: 2212, episode reward: 38.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: 0.022 [-0.819, 1.454], mean_best_reward: --\n",
      " 23015/100000: episode: 895, duration: 0.009s, episode steps: 18, steps per second: 2028, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.081 [-2.118, 1.199], mean_best_reward: --\n",
      " 23032/100000: episode: 896, duration: 0.011s, episode steps: 17, steps per second: 1550, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.824 [0.000, 1.000], mean observation: -0.059 [-3.248, 2.158], mean_best_reward: --\n",
      " 23086/100000: episode: 897, duration: 0.037s, episode steps: 54, steps per second: 1474, episode reward: 54.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.095 [-0.770, 1.274], mean_best_reward: --\n",
      " 23190/100000: episode: 898, duration: 0.046s, episode steps: 104, steps per second: 2241, episode reward: 104.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.548 [0.000, 1.000], mean observation: 0.256 [-1.772, 2.054], mean_best_reward: --\n",
      " 23338/100000: episode: 899, duration: 0.061s, episode steps: 148, steps per second: 2444, episode reward: 148.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.466 [0.000, 1.000], mean observation: 0.009 [-1.985, 2.619], mean_best_reward: --\n",
      " 23349/100000: episode: 900, duration: 0.006s, episode steps: 11, steps per second: 1746, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.636 [0.000, 1.000], mean observation: -0.118 [-1.704, 1.005], mean_best_reward: --\n",
      " 23381/100000: episode: 901, duration: 0.015s, episode steps: 32, steps per second: 2142, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.531 [0.000, 1.000], mean observation: 0.089 [-0.603, 0.961], mean_best_reward: 101.000000\n",
      " 23493/100000: episode: 902, duration: 0.059s, episode steps: 112, steps per second: 1912, episode reward: 112.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: -0.338 [-2.219, 0.837], mean_best_reward: --\n",
      " 23521/100000: episode: 903, duration: 0.014s, episode steps: 28, steps per second: 2052, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.464 [0.000, 1.000], mean observation: 0.064 [-1.017, 1.807], mean_best_reward: --\n",
      " 23534/100000: episode: 904, duration: 0.007s, episode steps: 13, steps per second: 1773, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.615 [0.000, 1.000], mean observation: -0.074 [-1.607, 1.005], mean_best_reward: --\n",
      " 23609/100000: episode: 905, duration: 0.044s, episode steps: 75, steps per second: 1707, episode reward: 75.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.560 [0.000, 1.000], mean observation: 0.050 [-1.885, 1.678], mean_best_reward: --\n",
      " 23626/100000: episode: 906, duration: 0.009s, episode steps: 17, steps per second: 1812, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.105 [-0.983, 0.597], mean_best_reward: --\n",
      " 23642/100000: episode: 907, duration: 0.018s, episode steps: 16, steps per second: 875, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.111 [-1.020, 0.614], mean_best_reward: --\n",
      " 23660/100000: episode: 908, duration: 0.028s, episode steps: 18, steps per second: 642, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.444 [0.000, 1.000], mean observation: 0.096 [-0.556, 1.206], mean_best_reward: --\n",
      " 23699/100000: episode: 909, duration: 0.040s, episode steps: 39, steps per second: 983, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.641 [0.000, 1.000], mean observation: 0.013 [-2.835, 2.098], mean_best_reward: --\n",
      " 23731/100000: episode: 910, duration: 0.026s, episode steps: 32, steps per second: 1212, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: -0.100 [-0.878, 0.402], mean_best_reward: --\n",
      " 23873/100000: episode: 911, duration: 0.171s, episode steps: 142, steps per second: 831, episode reward: 142.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.493 [0.000, 1.000], mean observation: -0.352 [-1.836, 0.970], mean_best_reward: --\n",
      " 23896/100000: episode: 912, duration: 0.015s, episode steps: 23, steps per second: 1567, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.565 [0.000, 1.000], mean observation: -0.032 [-1.294, 0.828], mean_best_reward: --\n",
      " 23909/100000: episode: 913, duration: 0.007s, episode steps: 13, steps per second: 1893, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.692 [0.000, 1.000], mean observation: -0.111 [-1.971, 1.160], mean_best_reward: --\n",
      " 23957/100000: episode: 914, duration: 0.021s, episode steps: 48, steps per second: 2327, episode reward: 48.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.083 [-1.079, 0.665], mean_best_reward: --\n",
      " 23976/100000: episode: 915, duration: 0.009s, episode steps: 19, steps per second: 2024, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.421 [0.000, 1.000], mean observation: 0.072 [-1.013, 1.675], mean_best_reward: --\n",
      " 24088/100000: episode: 916, duration: 0.046s, episode steps: 112, steps per second: 2447, episode reward: 112.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.464 [0.000, 1.000], mean observation: -0.259 [-1.738, 1.158], mean_best_reward: --\n",
      " 24116/100000: episode: 917, duration: 0.013s, episode steps: 28, steps per second: 2195, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.536 [0.000, 1.000], mean observation: -0.108 [-1.585, 0.619], mean_best_reward: --\n",
      " 24174/100000: episode: 918, duration: 0.025s, episode steps: 58, steps per second: 2338, episode reward: 58.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.534 [0.000, 1.000], mean observation: 0.126 [-0.561, 0.914], mean_best_reward: --\n",
      " 24220/100000: episode: 919, duration: 0.020s, episode steps: 46, steps per second: 2353, episode reward: 46.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: -0.087 [-0.957, 0.434], mean_best_reward: --\n",
      " 24261/100000: episode: 920, duration: 0.018s, episode steps: 41, steps per second: 2222, episode reward: 41.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.561 [0.000, 1.000], mean observation: 0.028 [-1.477, 0.976], mean_best_reward: --\n",
      " 24303/100000: episode: 921, duration: 0.019s, episode steps: 42, steps per second: 2194, episode reward: 42.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.054 [-0.823, 0.536], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24317/100000: episode: 922, duration: 0.008s, episode steps: 14, steps per second: 1684, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.094 [-1.007, 0.627], mean_best_reward: --\n",
      " 24354/100000: episode: 923, duration: 0.026s, episode steps: 37, steps per second: 1401, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.459 [0.000, 1.000], mean observation: -0.059 [-0.771, 0.432], mean_best_reward: --\n",
      " 24372/100000: episode: 924, duration: 0.011s, episode steps: 18, steps per second: 1676, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.389 [0.000, 1.000], mean observation: 0.096 [-0.805, 1.660], mean_best_reward: --\n",
      " 24469/100000: episode: 925, duration: 0.046s, episode steps: 97, steps per second: 2106, episode reward: 97.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: -0.087 [-1.118, 0.557], mean_best_reward: --\n",
      " 24532/100000: episode: 926, duration: 0.030s, episode steps: 63, steps per second: 2085, episode reward: 63.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.524 [0.000, 1.000], mean observation: 0.037 [-1.544, 1.532], mean_best_reward: --\n",
      " 24550/100000: episode: 927, duration: 0.010s, episode steps: 18, steps per second: 1757, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.444 [0.000, 1.000], mean observation: 0.091 [-0.966, 1.535], mean_best_reward: --\n",
      " 24587/100000: episode: 928, duration: 0.018s, episode steps: 37, steps per second: 2024, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.459 [0.000, 1.000], mean observation: -0.117 [-1.057, 0.627], mean_best_reward: --\n",
      " 24611/100000: episode: 929, duration: 0.012s, episode steps: 24, steps per second: 2056, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.068 [-0.813, 1.181], mean_best_reward: --\n",
      " 24679/100000: episode: 930, duration: 0.032s, episode steps: 68, steps per second: 2156, episode reward: 68.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.456 [0.000, 1.000], mean observation: -0.119 [-1.154, 1.397], mean_best_reward: --\n",
      " 24760/100000: episode: 931, duration: 0.041s, episode steps: 81, steps per second: 1962, episode reward: 81.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.457 [0.000, 1.000], mean observation: -0.200 [-1.648, 1.375], mean_best_reward: --\n",
      " 24827/100000: episode: 932, duration: 0.038s, episode steps: 67, steps per second: 1766, episode reward: 67.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.507 [0.000, 1.000], mean observation: -0.081 [-1.424, 0.763], mean_best_reward: --\n",
      " 24865/100000: episode: 933, duration: 0.019s, episode steps: 38, steps per second: 2047, episode reward: 38.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: -0.016 [-1.105, 0.884], mean_best_reward: --\n",
      " 24925/100000: episode: 934, duration: 0.025s, episode steps: 60, steps per second: 2358, episode reward: 60.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.064 [-0.770, 1.174], mean_best_reward: --\n",
      " 24991/100000: episode: 935, duration: 0.028s, episode steps: 66, steps per second: 2358, episode reward: 66.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.035 [-0.947, 1.299], mean_best_reward: --\n",
      " 25041/100000: episode: 936, duration: 0.023s, episode steps: 50, steps per second: 2166, episode reward: 50.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.580 [0.000, 1.000], mean observation: 0.059 [-1.910, 1.730], mean_best_reward: --\n",
      " 25075/100000: episode: 937, duration: 0.015s, episode steps: 34, steps per second: 2232, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.036 [-0.991, 0.641], mean_best_reward: --\n",
      " 25159/100000: episode: 938, duration: 0.035s, episode steps: 84, steps per second: 2385, episode reward: 84.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: -0.040 [-0.907, 0.503], mean_best_reward: --\n",
      " 25187/100000: episode: 939, duration: 0.014s, episode steps: 28, steps per second: 2072, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.065 [-1.006, 0.589], mean_best_reward: --\n",
      " 25222/100000: episode: 940, duration: 0.022s, episode steps: 35, steps per second: 1616, episode reward: 35.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: 0.132 [-0.588, 1.108], mean_best_reward: --\n",
      " 25336/100000: episode: 941, duration: 0.054s, episode steps: 114, steps per second: 2130, episode reward: 114.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.535 [0.000, 1.000], mean observation: 0.236 [-1.447, 2.110], mean_best_reward: --\n",
      " 25397/100000: episode: 942, duration: 0.035s, episode steps: 61, steps per second: 1767, episode reward: 61.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.459 [0.000, 1.000], mean observation: -0.089 [-1.079, 0.801], mean_best_reward: --\n",
      " 25455/100000: episode: 943, duration: 0.057s, episode steps: 58, steps per second: 1012, episode reward: 58.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.466 [0.000, 1.000], mean observation: -0.093 [-0.738, 0.869], mean_best_reward: --\n",
      " 25514/100000: episode: 944, duration: 0.053s, episode steps: 59, steps per second: 1119, episode reward: 59.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.542 [0.000, 1.000], mean observation: 0.155 [-0.483, 1.092], mean_best_reward: --\n",
      " 25553/100000: episode: 945, duration: 0.042s, episode steps: 39, steps per second: 925, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.122 [-0.768, 0.426], mean_best_reward: --\n",
      " 25618/100000: episode: 946, duration: 0.032s, episode steps: 65, steps per second: 2059, episode reward: 65.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.508 [0.000, 1.000], mean observation: 0.047 [-1.089, 1.185], mean_best_reward: --\n",
      " 25630/100000: episode: 947, duration: 0.006s, episode steps: 12, steps per second: 1859, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.105 [-1.842, 1.201], mean_best_reward: --\n",
      " 25671/100000: episode: 948, duration: 0.030s, episode steps: 41, steps per second: 1388, episode reward: 41.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.463 [0.000, 1.000], mean observation: -0.081 [-1.356, 0.976], mean_best_reward: --\n",
      " 25772/100000: episode: 949, duration: 0.044s, episode steps: 101, steps per second: 2270, episode reward: 101.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.036 [-0.793, 1.461], mean_best_reward: --\n",
      " 25794/100000: episode: 950, duration: 0.012s, episode steps: 22, steps per second: 1881, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: -0.080 [-1.118, 0.606], mean_best_reward: --\n",
      " 25818/100000: episode: 951, duration: 0.013s, episode steps: 24, steps per second: 1885, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.085 [-1.144, 0.755], mean_best_reward: 80.500000\n",
      " 25848/100000: episode: 952, duration: 0.015s, episode steps: 30, steps per second: 2057, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.053 [-1.060, 0.453], mean_best_reward: --\n",
      " 25877/100000: episode: 953, duration: 0.014s, episode steps: 29, steps per second: 2140, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.448 [0.000, 1.000], mean observation: -0.141 [-1.001, 0.609], mean_best_reward: --\n",
      " 25937/100000: episode: 954, duration: 0.026s, episode steps: 60, steps per second: 2327, episode reward: 60.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.517 [0.000, 1.000], mean observation: 0.044 [-0.626, 1.023], mean_best_reward: --\n",
      " 25973/100000: episode: 955, duration: 0.020s, episode steps: 36, steps per second: 1824, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.611 [0.000, 1.000], mean observation: -0.002 [-2.260, 1.555], mean_best_reward: --\n",
      " 26013/100000: episode: 956, duration: 0.026s, episode steps: 40, steps per second: 1547, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: 0.051 [-0.631, 1.461], mean_best_reward: --\n",
      " 26043/100000: episode: 957, duration: 0.022s, episode steps: 30, steps per second: 1387, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.533 [0.000, 1.000], mean observation: 0.123 [-0.424, 0.787], mean_best_reward: --\n",
      " 26076/100000: episode: 958, duration: 0.027s, episode steps: 33, steps per second: 1204, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.075 [-0.585, 0.916], mean_best_reward: --\n",
      " 26088/100000: episode: 959, duration: 0.015s, episode steps: 12, steps per second: 789, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.143 [-2.182, 1.320], mean_best_reward: --\n",
      " 26189/100000: episode: 960, duration: 0.080s, episode steps: 101, steps per second: 1264, episode reward: 101.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.110 [-1.091, 1.093], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26229/100000: episode: 961, duration: 0.043s, episode steps: 40, steps per second: 936, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.084 [-1.088, 0.560], mean_best_reward: --\n",
      " 26247/100000: episode: 962, duration: 0.022s, episode steps: 18, steps per second: 835, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.444 [0.000, 1.000], mean observation: 0.105 [-0.550, 1.195], mean_best_reward: --\n",
      " 26258/100000: episode: 963, duration: 0.009s, episode steps: 11, steps per second: 1160, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: -0.124 [-1.242, 0.746], mean_best_reward: --\n",
      " 26298/100000: episode: 964, duration: 0.046s, episode steps: 40, steps per second: 877, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.675 [0.000, 1.000], mean observation: 0.108 [-2.997, 2.684], mean_best_reward: --\n",
      " 26484/100000: episode: 965, duration: 0.181s, episode steps: 186, steps per second: 1027, episode reward: 186.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.484 [0.000, 1.000], mean observation: -0.118 [-1.815, 1.048], mean_best_reward: --\n",
      " 26500/100000: episode: 966, duration: 0.017s, episode steps: 16, steps per second: 918, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.076 [-0.778, 1.272], mean_best_reward: --\n",
      " 26606/100000: episode: 967, duration: 0.099s, episode steps: 106, steps per second: 1075, episode reward: 106.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.519 [0.000, 1.000], mean observation: -0.019 [-0.787, 0.925], mean_best_reward: --\n",
      " 26626/100000: episode: 968, duration: 0.014s, episode steps: 20, steps per second: 1477, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.450 [0.000, 1.000], mean observation: 0.107 [-0.606, 1.397], mean_best_reward: --\n",
      " 26650/100000: episode: 969, duration: 0.018s, episode steps: 24, steps per second: 1350, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.095 [-0.552, 1.106], mean_best_reward: --\n",
      " 26689/100000: episode: 970, duration: 0.040s, episode steps: 39, steps per second: 978, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.513 [0.000, 1.000], mean observation: 0.133 [-0.427, 1.169], mean_best_reward: --\n",
      " 26699/100000: episode: 971, duration: 0.012s, episode steps: 10, steps per second: 838, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.800 [0.000, 1.000], mean observation: -0.136 [-2.038, 1.173], mean_best_reward: --\n",
      " 26713/100000: episode: 972, duration: 0.020s, episode steps: 14, steps per second: 705, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.571 [0.000, 1.000], mean observation: -0.118 [-1.439, 0.753], mean_best_reward: --\n",
      " 26730/100000: episode: 973, duration: 0.022s, episode steps: 17, steps per second: 780, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.529 [0.000, 1.000], mean observation: 0.105 [-0.582, 1.034], mean_best_reward: --\n",
      " 26768/100000: episode: 974, duration: 0.039s, episode steps: 38, steps per second: 975, episode reward: 38.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.526 [0.000, 1.000], mean observation: 0.106 [-0.586, 0.926], mean_best_reward: --\n",
      " 26777/100000: episode: 975, duration: 0.012s, episode steps: 9, steps per second: 754, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.222 [0.000, 1.000], mean observation: 0.115 [-1.406, 2.143], mean_best_reward: --\n",
      " 26804/100000: episode: 976, duration: 0.037s, episode steps: 27, steps per second: 724, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.519 [0.000, 1.000], mean observation: 0.065 [-0.555, 0.923], mean_best_reward: --\n",
      " 26825/100000: episode: 977, duration: 0.026s, episode steps: 21, steps per second: 808, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: 0.074 [-0.789, 1.234], mean_best_reward: --\n",
      " 26889/100000: episode: 978, duration: 0.062s, episode steps: 64, steps per second: 1030, episode reward: 64.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.531 [0.000, 1.000], mean observation: 0.085 [-0.579, 1.193], mean_best_reward: --\n",
      " 26975/100000: episode: 979, duration: 0.102s, episode steps: 86, steps per second: 843, episode reward: 86.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.465 [0.000, 1.000], mean observation: -0.206 [-1.513, 0.664], mean_best_reward: --\n",
      " 27019/100000: episode: 980, duration: 0.048s, episode steps: 44, steps per second: 911, episode reward: 44.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.477 [0.000, 1.000], mean observation: -0.002 [-0.755, 1.156], mean_best_reward: --\n",
      " 27034/100000: episode: 981, duration: 0.017s, episode steps: 15, steps per second: 870, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.068 [-1.424, 1.025], mean_best_reward: --\n",
      " 27068/100000: episode: 982, duration: 0.044s, episode steps: 34, steps per second: 769, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.529 [0.000, 1.000], mean observation: 0.070 [-0.449, 0.923], mean_best_reward: --\n",
      " 27268/100000: episode: 983, duration: 0.104s, episode steps: 200, steps per second: 1920, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: 0.059 [-1.349, 1.000], mean_best_reward: --\n",
      " 27320/100000: episode: 984, duration: 0.025s, episode steps: 52, steps per second: 2109, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.481 [0.000, 1.000], mean observation: -0.065 [-1.201, 0.606], mean_best_reward: --\n",
      " 27367/100000: episode: 985, duration: 0.021s, episode steps: 47, steps per second: 2198, episode reward: 47.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.511 [0.000, 1.000], mean observation: 0.150 [-0.553, 1.251], mean_best_reward: --\n",
      " 27481/100000: episode: 986, duration: 0.049s, episode steps: 114, steps per second: 2325, episode reward: 114.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.491 [0.000, 1.000], mean observation: 0.018 [-1.059, 0.829], mean_best_reward: --\n",
      " 27515/100000: episode: 987, duration: 0.022s, episode steps: 34, steps per second: 1551, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.056 [-0.802, 1.096], mean_best_reward: --\n",
      " 27540/100000: episode: 988, duration: 0.015s, episode steps: 25, steps per second: 1614, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.400 [0.000, 1.000], mean observation: 0.047 [-0.983, 1.738], mean_best_reward: --\n",
      " 27589/100000: episode: 989, duration: 0.032s, episode steps: 49, steps per second: 1520, episode reward: 49.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.531 [0.000, 1.000], mean observation: 0.026 [-1.176, 0.934], mean_best_reward: --\n",
      " 27645/100000: episode: 990, duration: 0.027s, episode steps: 56, steps per second: 2113, episode reward: 56.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.464 [0.000, 1.000], mean observation: -0.014 [-1.147, 1.393], mean_best_reward: --\n",
      " 27722/100000: episode: 991, duration: 0.034s, episode steps: 77, steps per second: 2279, episode reward: 77.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.610 [0.000, 1.000], mean observation: 0.234 [-2.783, 3.188], mean_best_reward: --\n",
      " 27773/100000: episode: 992, duration: 0.023s, episode steps: 51, steps per second: 2212, episode reward: 51.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.017 [-1.538, 1.449], mean_best_reward: --\n",
      " 27839/100000: episode: 993, duration: 0.031s, episode steps: 66, steps per second: 2145, episode reward: 66.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: 0.032 [-0.743, 1.328], mean_best_reward: --\n",
      " 27856/100000: episode: 994, duration: 0.009s, episode steps: 17, steps per second: 1818, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.647 [0.000, 1.000], mean observation: -0.093 [-2.004, 1.198], mean_best_reward: --\n",
      " 27908/100000: episode: 995, duration: 0.023s, episode steps: 52, steps per second: 2256, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.442 [0.000, 1.000], mean observation: -0.168 [-1.073, 0.604], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27970/100000: episode: 996, duration: 0.046s, episode steps: 62, steps per second: 1362, episode reward: 62.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.532 [0.000, 1.000], mean observation: 0.200 [-0.555, 1.325], mean_best_reward: --\n",
      " 27995/100000: episode: 997, duration: 0.013s, episode steps: 25, steps per second: 1896, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.560 [0.000, 1.000], mean observation: -0.023 [-1.493, 0.984], mean_best_reward: --\n",
      " 28021/100000: episode: 998, duration: 0.014s, episode steps: 26, steps per second: 1810, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.052 [-0.615, 1.233], mean_best_reward: --\n",
      " 28053/100000: episode: 999, duration: 0.022s, episode steps: 32, steps per second: 1436, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.562 [0.000, 1.000], mean observation: -0.037 [-1.809, 0.977], mean_best_reward: --\n",
      " 28085/100000: episode: 1000, duration: 0.016s, episode steps: 32, steps per second: 2003, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.531 [0.000, 1.000], mean observation: 0.065 [-0.612, 0.825], mean_best_reward: --\n",
      " 28107/100000: episode: 1001, duration: 0.013s, episode steps: 22, steps per second: 1703, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.066 [-0.946, 0.622], mean_best_reward: 99.000000\n",
      " 28122/100000: episode: 1002, duration: 0.009s, episode steps: 15, steps per second: 1683, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.100 [-1.757, 0.998], mean_best_reward: --\n",
      " 28231/100000: episode: 1003, duration: 0.051s, episode steps: 109, steps per second: 2130, episode reward: 109.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.459 [0.000, 1.000], mean observation: -0.300 [-2.441, 1.554], mean_best_reward: --\n",
      " 28301/100000: episode: 1004, duration: 0.036s, episode steps: 70, steps per second: 1938, episode reward: 70.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.486 [0.000, 1.000], mean observation: 0.050 [-0.986, 0.972], mean_best_reward: --\n",
      " 28443/100000: episode: 1005, duration: 0.074s, episode steps: 142, steps per second: 1920, episode reward: 142.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.458 [0.000, 1.000], mean observation: -0.412 [-2.413, 0.935], mean_best_reward: --\n",
      " 28499/100000: episode: 1006, duration: 0.028s, episode steps: 56, steps per second: 1984, episode reward: 56.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.060 [-0.414, 1.280], mean_best_reward: --\n",
      " 28516/100000: episode: 1007, duration: 0.009s, episode steps: 17, steps per second: 1865, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.765 [0.000, 1.000], mean observation: -0.089 [-2.756, 1.710], mean_best_reward: --\n",
      " 28579/100000: episode: 1008, duration: 0.031s, episode steps: 63, steps per second: 2056, episode reward: 63.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.492 [0.000, 1.000], mean observation: -0.028 [-1.373, 0.724], mean_best_reward: --\n",
      " 28612/100000: episode: 1009, duration: 0.017s, episode steps: 33, steps per second: 1966, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: -0.056 [-1.686, 0.778], mean_best_reward: --\n",
      " 28663/100000: episode: 1010, duration: 0.026s, episode steps: 51, steps per second: 1968, episode reward: 51.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.608 [0.000, 1.000], mean observation: 0.039 [-2.907, 2.175], mean_best_reward: --\n",
      " 28676/100000: episode: 1011, duration: 0.008s, episode steps: 13, steps per second: 1685, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.692 [0.000, 1.000], mean observation: -0.112 [-1.963, 1.215], mean_best_reward: --\n",
      " 28708/100000: episode: 1012, duration: 0.016s, episode steps: 32, steps per second: 1971, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.531 [0.000, 1.000], mean observation: -0.028 [-1.732, 1.033], mean_best_reward: --\n",
      " 28737/100000: episode: 1013, duration: 0.014s, episode steps: 29, steps per second: 2027, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.517 [0.000, 1.000], mean observation: -0.054 [-1.353, 0.762], mean_best_reward: --\n",
      " 28766/100000: episode: 1014, duration: 0.014s, episode steps: 29, steps per second: 2011, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.517 [0.000, 1.000], mean observation: -0.030 [-1.146, 0.825], mean_best_reward: --\n",
      " 28787/100000: episode: 1015, duration: 0.011s, episode steps: 21, steps per second: 1885, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.097 [-2.512, 1.404], mean_best_reward: --\n",
      " 28808/100000: episode: 1016, duration: 0.011s, episode steps: 21, steps per second: 1962, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.524 [0.000, 1.000], mean observation: -0.135 [-1.238, 0.755], mean_best_reward: --\n",
      " 28820/100000: episode: 1017, duration: 0.007s, episode steps: 12, steps per second: 1818, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.122 [-1.540, 0.773], mean_best_reward: --\n",
      " 28915/100000: episode: 1018, duration: 0.057s, episode steps: 95, steps per second: 1661, episode reward: 95.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.453 [0.000, 1.000], mean observation: -0.113 [-1.946, 1.756], mean_best_reward: --\n",
      " 29002/100000: episode: 1019, duration: 0.044s, episode steps: 87, steps per second: 1985, episode reward: 87.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.483 [0.000, 1.000], mean observation: -0.119 [-0.914, 0.674], mean_best_reward: --\n",
      " 29055/100000: episode: 1020, duration: 0.026s, episode steps: 53, steps per second: 2032, episode reward: 53.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.491 [0.000, 1.000], mean observation: -0.052 [-1.261, 0.941], mean_best_reward: --\n",
      " 29128/100000: episode: 1021, duration: 0.035s, episode steps: 73, steps per second: 2073, episode reward: 73.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.507 [0.000, 1.000], mean observation: 0.042 [-1.157, 0.948], mean_best_reward: --\n",
      " 29168/100000: episode: 1022, duration: 0.020s, episode steps: 40, steps per second: 1987, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.525 [0.000, 1.000], mean observation: -0.150 [-1.890, 0.489], mean_best_reward: --\n",
      " 29190/100000: episode: 1023, duration: 0.012s, episode steps: 22, steps per second: 1815, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: -0.062 [-1.395, 0.799], mean_best_reward: --\n",
      " 29202/100000: episode: 1024, duration: 0.006s, episode steps: 12, steps per second: 1868, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.102 [-2.279, 1.395], mean_best_reward: --\n",
      " 29223/100000: episode: 1025, duration: 0.011s, episode steps: 21, steps per second: 1951, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: -0.095 [-1.173, 0.796], mean_best_reward: --\n",
      " 29239/100000: episode: 1026, duration: 0.009s, episode steps: 16, steps per second: 1861, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.562 [0.000, 1.000], mean observation: -0.063 [-1.490, 0.991], mean_best_reward: --\n",
      " 29365/100000: episode: 1027, duration: 0.070s, episode steps: 126, steps per second: 1805, episode reward: 126.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.038 [-1.247, 1.124], mean_best_reward: --\n",
      " 29381/100000: episode: 1028, duration: 0.009s, episode steps: 16, steps per second: 1822, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.090 [-0.975, 0.568], mean_best_reward: --\n",
      " 29393/100000: episode: 1029, duration: 0.011s, episode steps: 12, steps per second: 1095, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.833 [0.000, 1.000], mean observation: -0.104 [-2.521, 1.598], mean_best_reward: --\n",
      " 29440/100000: episode: 1030, duration: 0.022s, episode steps: 47, steps per second: 2144, episode reward: 47.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.489 [0.000, 1.000], mean observation: -0.106 [-0.957, 0.536], mean_best_reward: --\n",
      " 29482/100000: episode: 1031, duration: 0.021s, episode steps: 42, steps per second: 2005, episode reward: 42.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.548 [0.000, 1.000], mean observation: -0.107 [-2.033, 0.796], mean_best_reward: --\n",
      " 29572/100000: episode: 1032, duration: 0.038s, episode steps: 90, steps per second: 2342, episode reward: 90.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.456 [0.000, 1.000], mean observation: -0.311 [-2.032, 1.176], mean_best_reward: --\n",
      " 29613/100000: episode: 1033, duration: 0.018s, episode steps: 41, steps per second: 2220, episode reward: 41.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.463 [0.000, 1.000], mean observation: -0.066 [-1.216, 0.848], mean_best_reward: --\n",
      " 29692/100000: episode: 1034, duration: 0.033s, episode steps: 79, steps per second: 2364, episode reward: 79.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.532 [0.000, 1.000], mean observation: 0.109 [-1.558, 1.025], mean_best_reward: --\n",
      " 29740/100000: episode: 1035, duration: 0.021s, episode steps: 48, steps per second: 2325, episode reward: 48.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.052 [-1.313, 1.195], mean_best_reward: --\n",
      " 29762/100000: episode: 1036, duration: 0.011s, episode steps: 22, steps per second: 2026, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.636 [0.000, 1.000], mean observation: -0.064 [-2.251, 1.400], mean_best_reward: --\n",
      " 29775/100000: episode: 1037, duration: 0.007s, episode steps: 13, steps per second: 1753, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.692 [0.000, 1.000], mean observation: -0.091 [-1.960, 1.191], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 29849/100000: episode: 1038, duration: 0.046s, episode steps: 74, steps per second: 1593, episode reward: 74.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.446 [0.000, 1.000], mean observation: -0.147 [-1.427, 0.426], mean_best_reward: --\n",
      " 29883/100000: episode: 1039, duration: 0.017s, episode steps: 34, steps per second: 2032, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.105 [-1.014, 0.546], mean_best_reward: --\n",
      " 29950/100000: episode: 1040, duration: 0.043s, episode steps: 67, steps per second: 1542, episode reward: 67.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.493 [0.000, 1.000], mean observation: -0.061 [-1.066, 0.772], mean_best_reward: --\n",
      " 29990/100000: episode: 1041, duration: 0.018s, episode steps: 40, steps per second: 2210, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.106 [-1.149, 0.564], mean_best_reward: --\n",
      " 30002/100000: episode: 1042, duration: 0.007s, episode steps: 12, steps per second: 1631, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.101 [-2.103, 1.220], mean_best_reward: --\n",
      " 30162/100000: episode: 1043, duration: 0.067s, episode steps: 160, steps per second: 2395, episode reward: 160.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.150 [-1.538, 2.024], mean_best_reward: --\n",
      " 30182/100000: episode: 1044, duration: 0.010s, episode steps: 20, steps per second: 2046, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.550 [0.000, 1.000], mean observation: -0.068 [-1.572, 0.980], mean_best_reward: --\n",
      " 30198/100000: episode: 1045, duration: 0.009s, episode steps: 16, steps per second: 1730, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.562 [0.000, 1.000], mean observation: -0.108 [-1.324, 0.627], mean_best_reward: --\n",
      " 30210/100000: episode: 1046, duration: 0.009s, episode steps: 12, steps per second: 1339, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.116 [-1.948, 1.150], mean_best_reward: --\n",
      " 30221/100000: episode: 1047, duration: 0.014s, episode steps: 11, steps per second: 768, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.121 [-2.175, 1.353], mean_best_reward: --\n",
      " 30414/100000: episode: 1048, duration: 0.220s, episode steps: 193, steps per second: 876, episode reward: 193.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.534 [0.000, 1.000], mean observation: 0.212 [-1.760, 2.453], mean_best_reward: --\n",
      " 30471/100000: episode: 1049, duration: 0.062s, episode steps: 57, steps per second: 927, episode reward: 57.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: -0.107 [-1.093, 0.736], mean_best_reward: --\n",
      " 30498/100000: episode: 1050, duration: 0.016s, episode steps: 27, steps per second: 1665, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.481 [0.000, 1.000], mean observation: -0.135 [-0.785, 0.190], mean_best_reward: --\n",
      " 30556/100000: episode: 1051, duration: 0.026s, episode steps: 58, steps per second: 2251, episode reward: 58.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.483 [0.000, 1.000], mean observation: -0.190 [-1.387, 0.573], mean_best_reward: 141.500000\n",
      " 30575/100000: episode: 1052, duration: 0.009s, episode steps: 19, steps per second: 2100, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: -0.076 [-1.011, 0.639], mean_best_reward: --\n",
      " 30605/100000: episode: 1053, duration: 0.014s, episode steps: 30, steps per second: 2206, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.567 [0.000, 1.000], mean observation: -0.087 [-1.960, 0.998], mean_best_reward: --\n",
      " 30655/100000: episode: 1054, duration: 0.022s, episode steps: 50, steps per second: 2321, episode reward: 50.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.460 [0.000, 1.000], mean observation: -0.136 [-1.108, 0.588], mean_best_reward: --\n",
      " 30672/100000: episode: 1055, duration: 0.009s, episode steps: 17, steps per second: 1988, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.529 [0.000, 1.000], mean observation: -0.103 [-0.985, 0.585], mean_best_reward: --\n",
      " 30682/100000: episode: 1056, duration: 0.006s, episode steps: 10, steps per second: 1744, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 1.000 [1.000, 1.000], mean observation: -0.175 [-3.138, 1.926], mean_best_reward: --\n",
      " 30696/100000: episode: 1057, duration: 0.007s, episode steps: 14, steps per second: 1910, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.714 [0.000, 1.000], mean observation: -0.125 [-2.069, 1.141], mean_best_reward: --\n",
      " 30825/100000: episode: 1058, duration: 0.071s, episode steps: 129, steps per second: 1825, episode reward: 129.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.566 [0.000, 1.000], mean observation: 0.037 [-3.634, 3.278], mean_best_reward: --\n",
      " 30911/100000: episode: 1059, duration: 0.049s, episode steps: 86, steps per second: 1765, episode reward: 86.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.523 [0.000, 1.000], mean observation: 0.176 [-1.025, 1.159], mean_best_reward: --\n",
      " 31011/100000: episode: 1060, duration: 0.119s, episode steps: 100, steps per second: 840, episode reward: 100.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.107 [-1.114, 1.036], mean_best_reward: --\n",
      " 31023/100000: episode: 1061, duration: 0.017s, episode steps: 12, steps per second: 690, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.097 [-0.989, 1.582], mean_best_reward: --\n",
      " 31065/100000: episode: 1062, duration: 0.044s, episode steps: 42, steps per second: 945, episode reward: 42.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: -0.208 [-1.233, 0.637], mean_best_reward: --\n",
      " 31080/100000: episode: 1063, duration: 0.018s, episode steps: 15, steps per second: 811, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.733 [0.000, 1.000], mean observation: -0.090 [-2.171, 1.334], mean_best_reward: --\n",
      " 31144/100000: episode: 1064, duration: 0.063s, episode steps: 64, steps per second: 1010, episode reward: 64.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.484 [0.000, 1.000], mean observation: -0.085 [-1.192, 0.589], mean_best_reward: --\n",
      " 31180/100000: episode: 1065, duration: 0.032s, episode steps: 36, steps per second: 1112, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.444 [0.000, 1.000], mean observation: -0.097 [-0.873, 0.555], mean_best_reward: --\n",
      " 31205/100000: episode: 1066, duration: 0.015s, episode steps: 25, steps per second: 1684, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: -0.082 [-1.396, 0.757], mean_best_reward: --\n",
      " 31257/100000: episode: 1067, duration: 0.029s, episode steps: 52, steps per second: 1777, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.481 [0.000, 1.000], mean observation: -0.109 [-1.030, 0.613], mean_best_reward: --\n",
      " 31268/100000: episode: 1068, duration: 0.006s, episode steps: 11, steps per second: 1725, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.364 [0.000, 1.000], mean observation: 0.116 [-1.160, 1.884], mean_best_reward: --\n",
      " 31313/100000: episode: 1069, duration: 0.020s, episode steps: 45, steps per second: 2272, episode reward: 45.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.444 [0.000, 1.000], mean observation: -0.144 [-0.887, 0.419], mean_best_reward: --\n",
      " 31358/100000: episode: 1070, duration: 0.020s, episode steps: 45, steps per second: 2276, episode reward: 45.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.533 [0.000, 1.000], mean observation: 0.003 [-1.581, 1.179], mean_best_reward: --\n",
      " 31420/100000: episode: 1071, duration: 0.051s, episode steps: 62, steps per second: 1227, episode reward: 62.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.033 [-0.992, 0.800], mean_best_reward: --\n",
      " 31453/100000: episode: 1072, duration: 0.018s, episode steps: 33, steps per second: 1884, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.072 [-0.551, 0.853], mean_best_reward: --\n",
      " 31551/100000: episode: 1073, duration: 0.042s, episode steps: 98, steps per second: 2326, episode reward: 98.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.449 [0.000, 1.000], mean observation: -0.170 [-2.098, 2.054], mean_best_reward: --\n",
      " 31589/100000: episode: 1074, duration: 0.017s, episode steps: 38, steps per second: 2277, episode reward: 38.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: -0.097 [-1.165, 0.312], mean_best_reward: --\n",
      " 31615/100000: episode: 1075, duration: 0.012s, episode steps: 26, steps per second: 2154, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.075 [-0.776, 1.226], mean_best_reward: --\n",
      " 31633/100000: episode: 1076, duration: 0.009s, episode steps: 18, steps per second: 2054, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.556 [0.000, 1.000], mean observation: -0.089 [-1.126, 0.635], mean_best_reward: --\n",
      " 31669/100000: episode: 1077, duration: 0.016s, episode steps: 36, steps per second: 2277, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.472 [0.000, 1.000], mean observation: -0.131 [-0.905, 0.396], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31751/100000: episode: 1078, duration: 0.044s, episode steps: 82, steps per second: 1849, episode reward: 82.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: -0.153 [-1.269, 0.919], mean_best_reward: --\n",
      " 31761/100000: episode: 1079, duration: 0.011s, episode steps: 10, steps per second: 888, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 1.000 [1.000, 1.000], mean observation: -0.141 [-3.014, 1.916], mean_best_reward: --\n",
      " 31852/100000: episode: 1080, duration: 0.052s, episode steps: 91, steps per second: 1751, episode reward: 91.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.230 [-1.468, 0.820], mean_best_reward: --\n",
      " 31884/100000: episode: 1081, duration: 0.015s, episode steps: 32, steps per second: 2074, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.562 [0.000, 1.000], mean observation: -0.064 [-1.792, 0.993], mean_best_reward: --\n",
      " 31939/100000: episode: 1082, duration: 0.025s, episode steps: 55, steps per second: 2210, episode reward: 55.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.473 [0.000, 1.000], mean observation: -0.097 [-0.766, 0.737], mean_best_reward: --\n",
      " 32021/100000: episode: 1083, duration: 0.039s, episode steps: 82, steps per second: 2117, episode reward: 82.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.537 [0.000, 1.000], mean observation: 0.010 [-1.655, 1.175], mean_best_reward: --\n",
      " 32032/100000: episode: 1084, duration: 0.006s, episode steps: 11, steps per second: 1795, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.727 [0.000, 1.000], mean observation: -0.120 [-1.785, 1.017], mean_best_reward: --\n",
      " 32077/100000: episode: 1085, duration: 0.027s, episode steps: 45, steps per second: 1640, episode reward: 45.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.556 [0.000, 1.000], mean observation: 0.013 [-1.736, 1.009], mean_best_reward: --\n",
      " 32107/100000: episode: 1086, duration: 0.015s, episode steps: 30, steps per second: 2037, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.120 [-0.913, 0.451], mean_best_reward: --\n",
      " 32127/100000: episode: 1087, duration: 0.012s, episode steps: 20, steps per second: 1643, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.097 [-1.707, 0.807], mean_best_reward: --\n",
      " 32184/100000: episode: 1088, duration: 0.037s, episode steps: 57, steps per second: 1538, episode reward: 57.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.509 [0.000, 1.000], mean observation: 0.098 [-0.788, 1.006], mean_best_reward: --\n",
      " 32197/100000: episode: 1089, duration: 0.008s, episode steps: 13, steps per second: 1683, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.846 [0.000, 1.000], mean observation: -0.129 [-2.839, 1.718], mean_best_reward: --\n",
      " 32219/100000: episode: 1090, duration: 0.012s, episode steps: 22, steps per second: 1846, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: 0.116 [-0.350, 0.901], mean_best_reward: --\n",
      " 32253/100000: episode: 1091, duration: 0.016s, episode steps: 34, steps per second: 2091, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.529 [0.000, 1.000], mean observation: -0.038 [-1.157, 0.559], mean_best_reward: --\n",
      " 32329/100000: episode: 1092, duration: 0.033s, episode steps: 76, steps per second: 2323, episode reward: 76.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.447 [0.000, 1.000], mean observation: -0.226 [-1.634, 0.486], mean_best_reward: --\n",
      " 32412/100000: episode: 1093, duration: 0.035s, episode steps: 83, steps per second: 2343, episode reward: 83.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.458 [0.000, 1.000], mean observation: -0.319 [-1.915, 1.088], mean_best_reward: --\n",
      " 32454/100000: episode: 1094, duration: 0.018s, episode steps: 42, steps per second: 2289, episode reward: 42.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.452 [0.000, 1.000], mean observation: 0.009 [-1.037, 1.791], mean_best_reward: --\n",
      " 32552/100000: episode: 1095, duration: 0.043s, episode steps: 98, steps per second: 2267, episode reward: 98.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: -0.141 [-2.371, 0.596], mean_best_reward: --\n",
      " 32596/100000: episode: 1096, duration: 0.032s, episode steps: 44, steps per second: 1373, episode reward: 44.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.523 [0.000, 1.000], mean observation: -0.037 [-1.266, 0.597], mean_best_reward: --\n",
      " 32626/100000: episode: 1097, duration: 0.016s, episode steps: 30, steps per second: 1912, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.533 [0.000, 1.000], mean observation: -0.103 [-1.322, 0.820], mean_best_reward: --\n",
      " 32674/100000: episode: 1098, duration: 0.024s, episode steps: 48, steps per second: 1960, episode reward: 48.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.458 [0.000, 1.000], mean observation: -0.128 [-0.779, 0.769], mean_best_reward: --\n",
      " 32795/100000: episode: 1099, duration: 0.064s, episode steps: 121, steps per second: 1896, episode reward: 121.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: -0.098 [-1.195, 0.820], mean_best_reward: --\n",
      " 32811/100000: episode: 1100, duration: 0.010s, episode steps: 16, steps per second: 1630, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.113 [-1.095, 0.603], mean_best_reward: --\n",
      " 32855/100000: episode: 1101, duration: 0.023s, episode steps: 44, steps per second: 1906, episode reward: 44.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: -0.084 [-0.890, 0.632], mean_best_reward: 149.000000\n",
      " 32890/100000: episode: 1102, duration: 0.018s, episode steps: 35, steps per second: 1986, episode reward: 35.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: -0.010 [-1.634, 1.026], mean_best_reward: --\n",
      " 33089/100000: episode: 1103, duration: 0.117s, episode steps: 199, steps per second: 1705, episode reward: 199.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.528 [0.000, 1.000], mean observation: 0.165 [-0.621, 1.976], mean_best_reward: --\n",
      " 33188/100000: episode: 1104, duration: 0.050s, episode steps: 99, steps per second: 2000, episode reward: 99.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.444 [0.000, 1.000], mean observation: -0.270 [-1.958, 0.720], mean_best_reward: --\n",
      " 33265/100000: episode: 1105, duration: 0.037s, episode steps: 77, steps per second: 2085, episode reward: 77.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.571 [0.000, 1.000], mean observation: 0.280 [-1.947, 2.797], mean_best_reward: --\n",
      " 33316/100000: episode: 1106, duration: 0.023s, episode steps: 51, steps per second: 2196, episode reward: 51.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.529 [0.000, 1.000], mean observation: 0.026 [-1.664, 1.348], mean_best_reward: --\n",
      " 33342/100000: episode: 1107, duration: 0.012s, episode steps: 26, steps per second: 2097, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.084 [-1.019, 0.422], mean_best_reward: --\n",
      " 33407/100000: episode: 1108, duration: 0.031s, episode steps: 65, steps per second: 2066, episode reward: 65.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.477 [0.000, 1.000], mean observation: -0.069 [-1.383, 1.545], mean_best_reward: --\n",
      " 33483/100000: episode: 1109, duration: 0.034s, episode steps: 76, steps per second: 2211, episode reward: 76.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.434 [0.000, 1.000], mean observation: -0.240 [-2.285, 1.555], mean_best_reward: --\n",
      " 33639/100000: episode: 1110, duration: 0.079s, episode steps: 156, steps per second: 1964, episode reward: 156.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.487 [0.000, 1.000], mean observation: -0.120 [-1.543, 1.375], mean_best_reward: --\n",
      " 33652/100000: episode: 1111, duration: 0.007s, episode steps: 13, steps per second: 1763, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.615 [0.000, 1.000], mean observation: -0.116 [-1.551, 0.792], mean_best_reward: --\n",
      " 33661/100000: episode: 1112, duration: 0.006s, episode steps: 9, steps per second: 1590, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.123 [-1.892, 1.202], mean_best_reward: --\n",
      " 33677/100000: episode: 1113, duration: 0.009s, episode steps: 16, steps per second: 1856, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.625 [0.000, 1.000], mean observation: -0.089 [-1.701, 1.012], mean_best_reward: --\n",
      " 33728/100000: episode: 1114, duration: 0.024s, episode steps: 51, steps per second: 2162, episode reward: 51.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: -0.026 [-1.099, 0.629], mean_best_reward: --\n",
      " 33754/100000: episode: 1115, duration: 0.013s, episode steps: 26, steps per second: 2079, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: -0.061 [-1.299, 0.586], mean_best_reward: --\n",
      " 33772/100000: episode: 1116, duration: 0.011s, episode steps: 18, steps per second: 1652, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.556 [0.000, 1.000], mean observation: -0.083 [-1.678, 0.958], mean_best_reward: --\n",
      " 33849/100000: episode: 1117, duration: 0.064s, episode steps: 77, steps per second: 1209, episode reward: 77.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.558 [0.000, 1.000], mean observation: 0.110 [-1.980, 1.746], mean_best_reward: --\n",
      " 33912/100000: episode: 1118, duration: 0.032s, episode steps: 63, steps per second: 1946, episode reward: 63.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.492 [0.000, 1.000], mean observation: 0.036 [-0.798, 0.740], mean_best_reward: --\n",
      " 33954/100000: episode: 1119, duration: 0.028s, episode steps: 42, steps per second: 1509, episode reward: 42.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.452 [0.000, 1.000], mean observation: -0.077 [-1.163, 0.827], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 33994/100000: episode: 1120, duration: 0.022s, episode steps: 40, steps per second: 1794, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.525 [0.000, 1.000], mean observation: -0.063 [-1.578, 0.757], mean_best_reward: --\n",
      " 34121/100000: episode: 1121, duration: 0.063s, episode steps: 127, steps per second: 2028, episode reward: 127.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.034 [-1.848, 1.292], mean_best_reward: --\n",
      " 34290/100000: episode: 1122, duration: 0.073s, episode steps: 169, steps per second: 2304, episode reward: 169.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.509 [0.000, 1.000], mean observation: 0.037 [-1.322, 0.732], mean_best_reward: --\n",
      " 34318/100000: episode: 1123, duration: 0.014s, episode steps: 28, steps per second: 2051, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.536 [0.000, 1.000], mean observation: -0.073 [-1.474, 0.762], mean_best_reward: --\n",
      " 34351/100000: episode: 1124, duration: 0.016s, episode steps: 33, steps per second: 2038, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.143 [-1.205, 0.813], mean_best_reward: --\n",
      " 34397/100000: episode: 1125, duration: 0.022s, episode steps: 46, steps per second: 2079, episode reward: 46.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: -0.079 [-1.086, 0.811], mean_best_reward: --\n",
      " 34470/100000: episode: 1126, duration: 0.043s, episode steps: 73, steps per second: 1690, episode reward: 73.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.452 [0.000, 1.000], mean observation: -0.134 [-1.245, 0.473], mean_best_reward: --\n",
      " 34493/100000: episode: 1127, duration: 0.013s, episode steps: 23, steps per second: 1774, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.652 [0.000, 1.000], mean observation: -0.083 [-2.384, 1.377], mean_best_reward: --\n",
      " 34516/100000: episode: 1128, duration: 0.012s, episode steps: 23, steps per second: 1972, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.565 [0.000, 1.000], mean observation: -0.076 [-1.908, 1.161], mean_best_reward: --\n",
      " 34531/100000: episode: 1129, duration: 0.008s, episode steps: 15, steps per second: 1816, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.800 [0.000, 1.000], mean observation: -0.061 [-2.722, 1.784], mean_best_reward: --\n",
      " 34602/100000: episode: 1130, duration: 0.031s, episode steps: 71, steps per second: 2302, episode reward: 71.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.606 [0.000, 1.000], mean observation: 0.078 [-3.120, 3.016], mean_best_reward: --\n",
      " 34611/100000: episode: 1131, duration: 0.006s, episode steps: 9, steps per second: 1629, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.889 [0.000, 1.000], mean observation: -0.140 [-2.247, 1.368], mean_best_reward: --\n",
      " 34662/100000: episode: 1132, duration: 0.028s, episode steps: 51, steps per second: 1854, episode reward: 51.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.588 [0.000, 1.000], mean observation: 0.079 [-2.525, 2.149], mean_best_reward: --\n",
      " 34683/100000: episode: 1133, duration: 0.011s, episode steps: 21, steps per second: 1890, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.524 [0.000, 1.000], mean observation: -0.058 [-1.231, 0.815], mean_best_reward: --\n",
      " 34716/100000: episode: 1134, duration: 0.016s, episode steps: 33, steps per second: 2041, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: 0.074 [-0.822, 1.774], mean_best_reward: --\n",
      " 34789/100000: episode: 1135, duration: 0.032s, episode steps: 73, steps per second: 2291, episode reward: 73.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.603 [0.000, 1.000], mean observation: 0.140 [-2.689, 2.858], mean_best_reward: --\n",
      " 34837/100000: episode: 1136, duration: 0.021s, episode steps: 48, steps per second: 2313, episode reward: 48.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.479 [0.000, 1.000], mean observation: -0.049 [-0.974, 1.046], mean_best_reward: --\n",
      " 34916/100000: episode: 1137, duration: 0.035s, episode steps: 79, steps per second: 2260, episode reward: 79.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.506 [0.000, 1.000], mean observation: 0.056 [-0.941, 1.303], mean_best_reward: --\n",
      " 34996/100000: episode: 1138, duration: 0.047s, episode steps: 80, steps per second: 1689, episode reward: 80.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.299 [-1.916, 1.085], mean_best_reward: --\n",
      " 35035/100000: episode: 1139, duration: 0.017s, episode steps: 39, steps per second: 2255, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.436 [0.000, 1.000], mean observation: -0.148 [-0.956, 0.613], mean_best_reward: --\n",
      " 35088/100000: episode: 1140, duration: 0.026s, episode steps: 53, steps per second: 2074, episode reward: 53.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.566 [0.000, 1.000], mean observation: 0.119 [-1.471, 1.375], mean_best_reward: --\n",
      " 35103/100000: episode: 1141, duration: 0.008s, episode steps: 15, steps per second: 1790, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.400 [0.000, 1.000], mean observation: 0.099 [-0.995, 1.545], mean_best_reward: --\n",
      " 35113/100000: episode: 1142, duration: 0.006s, episode steps: 10, steps per second: 1608, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.900 [0.000, 1.000], mean observation: -0.123 [-2.532, 1.600], mean_best_reward: --\n",
      " 35153/100000: episode: 1143, duration: 0.019s, episode steps: 40, steps per second: 2135, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.208 [-1.595, 0.627], mean_best_reward: --\n",
      " 35173/100000: episode: 1144, duration: 0.010s, episode steps: 20, steps per second: 1977, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.550 [0.000, 1.000], mean observation: -0.093 [-1.380, 0.640], mean_best_reward: --\n",
      " 35244/100000: episode: 1145, duration: 0.031s, episode steps: 71, steps per second: 2271, episode reward: 71.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.549 [0.000, 1.000], mean observation: 0.182 [-0.660, 1.480], mean_best_reward: --\n",
      " 35307/100000: episode: 1146, duration: 0.027s, episode steps: 63, steps per second: 2311, episode reward: 63.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.556 [0.000, 1.000], mean observation: 0.004 [-2.390, 1.380], mean_best_reward: --\n",
      " 35324/100000: episode: 1147, duration: 0.015s, episode steps: 17, steps per second: 1139, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.085 [-1.345, 0.784], mean_best_reward: --\n",
      " 35408/100000: episode: 1148, duration: 0.047s, episode steps: 84, steps per second: 1784, episode reward: 84.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.512 [0.000, 1.000], mean observation: -0.131 [-1.759, 0.701], mean_best_reward: --\n",
      " 35440/100000: episode: 1149, duration: 0.016s, episode steps: 32, steps per second: 1992, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.406 [0.000, 1.000], mean observation: 0.054 [-1.197, 2.120], mean_best_reward: --\n",
      " 35489/100000: episode: 1150, duration: 0.022s, episode steps: 49, steps per second: 2230, episode reward: 49.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: -0.043 [-1.236, 0.817], mean_best_reward: --\n",
      " 35504/100000: episode: 1151, duration: 0.008s, episode steps: 15, steps per second: 1856, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.107 [-1.393, 0.796], mean_best_reward: 162.500000\n",
      " 35551/100000: episode: 1152, duration: 0.021s, episode steps: 47, steps per second: 2253, episode reward: 47.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.511 [0.000, 1.000], mean observation: 0.004 [-1.274, 1.002], mean_best_reward: --\n",
      " 35578/100000: episode: 1153, duration: 0.013s, episode steps: 27, steps per second: 2116, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.370 [0.000, 1.000], mean observation: -0.001 [-1.712, 2.170], mean_best_reward: --\n",
      " 35620/100000: episode: 1154, duration: 0.020s, episode steps: 42, steps per second: 2143, episode reward: 42.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.003 [-0.771, 1.158], mean_best_reward: --\n",
      " 35662/100000: episode: 1155, duration: 0.020s, episode steps: 42, steps per second: 2058, episode reward: 42.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.080 [-1.226, 0.424], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35765/100000: episode: 1156, duration: 0.051s, episode steps: 103, steps per second: 2016, episode reward: 103.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: -0.113 [-1.129, 0.606], mean_best_reward: --\n",
      " 35830/100000: episode: 1157, duration: 0.033s, episode steps: 65, steps per second: 1967, episode reward: 65.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.202 [-1.071, 0.706], mean_best_reward: --\n",
      " 35857/100000: episode: 1158, duration: 0.013s, episode steps: 27, steps per second: 2026, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.630 [0.000, 1.000], mean observation: -0.066 [-2.334, 1.382], mean_best_reward: --\n",
      " 35877/100000: episode: 1159, duration: 0.010s, episode steps: 20, steps per second: 1949, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.136 [-0.543, 0.975], mean_best_reward: --\n",
      " 35909/100000: episode: 1160, duration: 0.014s, episode steps: 32, steps per second: 2248, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: -0.112 [-0.762, 0.424], mean_best_reward: --\n",
      " 35977/100000: episode: 1161, duration: 0.034s, episode steps: 68, steps per second: 2028, episode reward: 68.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.397 [0.000, 1.000], mean observation: -0.254 [-2.979, 2.159], mean_best_reward: --\n",
      " 36027/100000: episode: 1162, duration: 0.032s, episode steps: 50, steps per second: 1567, episode reward: 50.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.155 [-1.302, 0.452], mean_best_reward: --\n",
      " 36084/100000: episode: 1163, duration: 0.052s, episode steps: 57, steps per second: 1087, episode reward: 57.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.544 [0.000, 1.000], mean observation: -0.053 [-2.161, 1.002], mean_best_reward: --\n",
      " 36131/100000: episode: 1164, duration: 0.026s, episode steps: 47, steps per second: 1789, episode reward: 47.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.489 [0.000, 1.000], mean observation: -0.071 [-0.957, 0.838], mean_best_reward: --\n",
      " 36225/100000: episode: 1165, duration: 0.043s, episode steps: 94, steps per second: 2198, episode reward: 94.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.532 [0.000, 1.000], mean observation: 0.228 [-0.984, 1.504], mean_best_reward: --\n",
      " 36277/100000: episode: 1166, duration: 0.023s, episode steps: 52, steps per second: 2277, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.481 [0.000, 1.000], mean observation: -0.027 [-1.044, 0.794], mean_best_reward: --\n",
      " 36347/100000: episode: 1167, duration: 0.030s, episode steps: 70, steps per second: 2304, episode reward: 70.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.075 [-1.334, 0.387], mean_best_reward: --\n",
      " 36368/100000: episode: 1168, duration: 0.010s, episode steps: 21, steps per second: 2149, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.571 [0.000, 1.000], mean observation: -0.071 [-1.457, 0.777], mean_best_reward: --\n",
      " 36452/100000: episode: 1169, duration: 0.061s, episode steps: 84, steps per second: 1384, episode reward: 84.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.440 [0.000, 1.000], mean observation: -0.302 [-2.189, 1.174], mean_best_reward: --\n",
      " 36532/100000: episode: 1170, duration: 0.066s, episode steps: 80, steps per second: 1206, episode reward: 80.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.525 [0.000, 1.000], mean observation: 0.225 [-0.635, 1.123], mean_best_reward: --\n",
      " 36610/100000: episode: 1171, duration: 0.056s, episode steps: 78, steps per second: 1390, episode reward: 78.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.001 [-0.798, 1.323], mean_best_reward: --\n",
      " 36635/100000: episode: 1172, duration: 0.012s, episode steps: 25, steps per second: 2045, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.064 [-1.809, 0.994], mean_best_reward: --\n",
      " 36659/100000: episode: 1173, duration: 0.013s, episode steps: 24, steps per second: 1879, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.417 [0.000, 1.000], mean observation: 0.033 [-0.997, 1.565], mean_best_reward: --\n",
      " 36738/100000: episode: 1174, duration: 0.035s, episode steps: 79, steps per second: 2271, episode reward: 79.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.468 [0.000, 1.000], mean observation: -0.251 [-1.517, 0.545], mean_best_reward: --\n",
      " 36799/100000: episode: 1175, duration: 0.029s, episode steps: 61, steps per second: 2122, episode reward: 61.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.459 [0.000, 1.000], mean observation: -0.092 [-1.062, 0.619], mean_best_reward: --\n",
      " 36903/100000: episode: 1176, duration: 0.044s, episode steps: 104, steps per second: 2350, episode reward: 104.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.442 [0.000, 1.000], mean observation: -0.207 [-2.618, 1.973], mean_best_reward: --\n",
      " 36962/100000: episode: 1177, duration: 0.031s, episode steps: 59, steps per second: 1895, episode reward: 59.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.056 [-0.991, 0.786], mean_best_reward: --\n",
      " 37030/100000: episode: 1178, duration: 0.036s, episode steps: 68, steps per second: 1909, episode reward: 68.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.099 [-0.852, 1.025], mean_best_reward: --\n",
      " 37062/100000: episode: 1179, duration: 0.015s, episode steps: 32, steps per second: 2073, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.112 [-1.289, 0.403], mean_best_reward: --\n",
      " 37097/100000: episode: 1180, duration: 0.017s, episode steps: 35, steps per second: 2054, episode reward: 35.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: -0.075 [-1.186, 0.583], mean_best_reward: --\n",
      " 37130/100000: episode: 1181, duration: 0.015s, episode steps: 33, steps per second: 2237, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: -0.059 [-1.676, 0.973], mean_best_reward: --\n",
      " 37167/100000: episode: 1182, duration: 0.019s, episode steps: 37, steps per second: 1906, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.486 [0.000, 1.000], mean observation: -0.110 [-1.020, 0.597], mean_best_reward: --\n",
      " 37243/100000: episode: 1183, duration: 0.035s, episode steps: 76, steps per second: 2193, episode reward: 76.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.025 [-1.222, 0.410], mean_best_reward: --\n",
      " 37265/100000: episode: 1184, duration: 0.011s, episode steps: 22, steps per second: 1995, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.084 [-0.952, 0.427], mean_best_reward: --\n",
      " 37346/100000: episode: 1185, duration: 0.035s, episode steps: 81, steps per second: 2327, episode reward: 81.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: -0.186 [-1.341, 0.947], mean_best_reward: --\n",
      " 37463/100000: episode: 1186, duration: 0.063s, episode steps: 117, steps per second: 1848, episode reward: 117.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.270 [-2.244, 0.979], mean_best_reward: --\n",
      " 37517/100000: episode: 1187, duration: 0.025s, episode steps: 54, steps per second: 2119, episode reward: 54.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.481 [0.000, 1.000], mean observation: -0.084 [-1.179, 0.589], mean_best_reward: --\n",
      " 37550/100000: episode: 1188, duration: 0.015s, episode steps: 33, steps per second: 2215, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.576 [0.000, 1.000], mean observation: -0.078 [-1.977, 0.985], mean_best_reward: --\n",
      " 37615/100000: episode: 1189, duration: 0.027s, episode steps: 65, steps per second: 2399, episode reward: 65.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.508 [0.000, 1.000], mean observation: -0.045 [-1.567, 0.980], mean_best_reward: --\n",
      " 37718/100000: episode: 1190, duration: 0.049s, episode steps: 103, steps per second: 2119, episode reward: 103.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: -0.081 [-1.194, 0.918], mean_best_reward: --\n",
      " 37744/100000: episode: 1191, duration: 0.012s, episode steps: 26, steps per second: 2091, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: -0.104 [-1.427, 0.444], mean_best_reward: --\n",
      " 37796/100000: episode: 1192, duration: 0.023s, episode steps: 52, steps per second: 2258, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.519 [0.000, 1.000], mean observation: 0.170 [-0.829, 1.604], mean_best_reward: --\n",
      " 37872/100000: episode: 1193, duration: 0.033s, episode steps: 76, steps per second: 2281, episode reward: 76.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.592 [0.000, 1.000], mean observation: 0.255 [-2.300, 2.674], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 37996/100000: episode: 1194, duration: 0.063s, episode steps: 124, steps per second: 1965, episode reward: 124.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.540 [0.000, 1.000], mean observation: 0.080 [-1.875, 2.054], mean_best_reward: --\n",
      " 38141/100000: episode: 1195, duration: 0.062s, episode steps: 145, steps per second: 2331, episode reward: 145.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.249 [-2.244, 1.269], mean_best_reward: --\n",
      " 38190/100000: episode: 1196, duration: 0.021s, episode steps: 49, steps per second: 2340, episode reward: 49.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: -0.155 [-1.068, 0.429], mean_best_reward: --\n",
      " 38240/100000: episode: 1197, duration: 0.021s, episode steps: 50, steps per second: 2368, episode reward: 50.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: -0.027 [-1.366, 0.858], mean_best_reward: --\n",
      " 38303/100000: episode: 1198, duration: 0.029s, episode steps: 63, steps per second: 2208, episode reward: 63.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.460 [0.000, 1.000], mean observation: -0.203 [-1.275, 0.405], mean_best_reward: --\n",
      " 38335/100000: episode: 1199, duration: 0.015s, episode steps: 32, steps per second: 2099, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.531 [0.000, 1.000], mean observation: -0.072 [-1.324, 0.579], mean_best_reward: --\n",
      " 38360/100000: episode: 1200, duration: 0.011s, episode steps: 25, steps per second: 2182, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: -0.095 [-1.155, 0.403], mean_best_reward: --\n",
      " 38433/100000: episode: 1201, duration: 0.033s, episode steps: 73, steps per second: 2209, episode reward: 73.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.521 [0.000, 1.000], mean observation: 0.125 [-0.638, 1.117], mean_best_reward: 136.000000\n",
      " 38452/100000: episode: 1202, duration: 0.012s, episode steps: 19, steps per second: 1593, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.526 [0.000, 1.000], mean observation: -0.108 [-1.168, 0.617], mean_best_reward: --\n",
      " 38618/100000: episode: 1203, duration: 0.078s, episode steps: 166, steps per second: 2120, episode reward: 166.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.512 [0.000, 1.000], mean observation: -0.008 [-0.818, 1.143], mean_best_reward: --\n",
      " 38695/100000: episode: 1204, duration: 0.036s, episode steps: 77, steps per second: 2156, episode reward: 77.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.481 [0.000, 1.000], mean observation: -0.154 [-1.364, 1.065], mean_best_reward: --\n",
      " 38714/100000: episode: 1205, duration: 0.011s, episode steps: 19, steps per second: 1727, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: -0.102 [-1.089, 0.593], mean_best_reward: --\n",
      " 38780/100000: episode: 1206, duration: 0.029s, episode steps: 66, steps per second: 2268, episode reward: 66.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.409 [0.000, 1.000], mean observation: -0.128 [-2.433, 2.199], mean_best_reward: --\n",
      " 38801/100000: episode: 1207, duration: 0.011s, episode steps: 21, steps per second: 1872, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.571 [0.000, 1.000], mean observation: -0.050 [-1.619, 1.158], mean_best_reward: --\n",
      " 38825/100000: episode: 1208, duration: 0.012s, episode steps: 24, steps per second: 2086, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.458 [0.000, 1.000], mean observation: 0.122 [-0.568, 1.335], mean_best_reward: --\n",
      " 38919/100000: episode: 1209, duration: 0.054s, episode steps: 94, steps per second: 1741, episode reward: 94.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.511 [0.000, 1.000], mean observation: 0.152 [-0.667, 1.590], mean_best_reward: --\n",
      " 38980/100000: episode: 1210, duration: 0.027s, episode steps: 61, steps per second: 2249, episode reward: 61.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.443 [0.000, 1.000], mean observation: -0.105 [-1.492, 1.455], mean_best_reward: --\n",
      " 39025/100000: episode: 1211, duration: 0.021s, episode steps: 45, steps per second: 2149, episode reward: 45.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.511 [0.000, 1.000], mean observation: -0.071 [-1.356, 0.612], mean_best_reward: --\n",
      " 39054/100000: episode: 1212, duration: 0.014s, episode steps: 29, steps per second: 2005, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.483 [0.000, 1.000], mean observation: -0.056 [-1.104, 0.746], mean_best_reward: --\n",
      " 39111/100000: episode: 1213, duration: 0.025s, episode steps: 57, steps per second: 2281, episode reward: 57.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.456 [0.000, 1.000], mean observation: -0.178 [-1.136, 0.479], mean_best_reward: --\n",
      " 39186/100000: episode: 1214, duration: 0.034s, episode steps: 75, steps per second: 2222, episode reward: 75.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.573 [0.000, 1.000], mean observation: 0.169 [-1.908, 2.439], mean_best_reward: --\n",
      " 39237/100000: episode: 1215, duration: 0.025s, episode steps: 51, steps per second: 2045, episode reward: 51.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.119 [-1.182, 0.794], mean_best_reward: --\n",
      " 39270/100000: episode: 1216, duration: 0.016s, episode steps: 33, steps per second: 2027, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: -0.105 [-1.188, 0.559], mean_best_reward: --\n",
      " 39306/100000: episode: 1217, duration: 0.017s, episode steps: 36, steps per second: 2064, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.528 [0.000, 1.000], mean observation: 0.152 [-0.556, 0.964], mean_best_reward: --\n",
      " 39378/100000: episode: 1218, duration: 0.037s, episode steps: 72, steps per second: 1969, episode reward: 72.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.486 [0.000, 1.000], mean observation: 0.022 [-1.004, 0.821], mean_best_reward: --\n",
      " 39408/100000: episode: 1219, duration: 0.018s, episode steps: 30, steps per second: 1628, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.400 [0.000, 1.000], mean observation: 0.024 [-1.178, 1.927], mean_best_reward: --\n",
      " 39484/100000: episode: 1220, duration: 0.033s, episode steps: 76, steps per second: 2284, episode reward: 76.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.447 [0.000, 1.000], mean observation: -0.158 [-2.031, 1.716], mean_best_reward: --\n",
      " 39566/100000: episode: 1221, duration: 0.038s, episode steps: 82, steps per second: 2180, episode reward: 82.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: -0.065 [-1.235, 0.711], mean_best_reward: --\n",
      " 39583/100000: episode: 1222, duration: 0.009s, episode steps: 17, steps per second: 1903, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.353 [0.000, 1.000], mean observation: 0.070 [-1.035, 1.860], mean_best_reward: --\n",
      " 39631/100000: episode: 1223, duration: 0.021s, episode steps: 48, steps per second: 2275, episode reward: 48.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.015 [-1.439, 1.143], mean_best_reward: --\n",
      " 39689/100000: episode: 1224, duration: 0.027s, episode steps: 58, steps per second: 2148, episode reward: 58.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.112 [-0.558, 1.413], mean_best_reward: --\n",
      " 39757/100000: episode: 1225, duration: 0.031s, episode steps: 68, steps per second: 2191, episode reward: 68.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.544 [0.000, 1.000], mean observation: 0.132 [-0.613, 1.114], mean_best_reward: --\n",
      " 39800/100000: episode: 1226, duration: 0.020s, episode steps: 43, steps per second: 2186, episode reward: 43.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.442 [0.000, 1.000], mean observation: 0.018 [-1.200, 1.774], mean_best_reward: --\n",
      " 39823/100000: episode: 1227, duration: 0.019s, episode steps: 23, steps per second: 1196, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.522 [0.000, 1.000], mean observation: 0.069 [-0.801, 1.245], mean_best_reward: --\n",
      " 39834/100000: episode: 1228, duration: 0.010s, episode steps: 11, steps per second: 1152, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.636 [0.000, 1.000], mean observation: -0.099 [-1.894, 1.203], mean_best_reward: --\n",
      " 39920/100000: episode: 1229, duration: 0.042s, episode steps: 86, steps per second: 2026, episode reward: 86.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.523 [0.000, 1.000], mean observation: -0.036 [-1.945, 0.992], mean_best_reward: --\n",
      " 39979/100000: episode: 1230, duration: 0.028s, episode steps: 59, steps per second: 2119, episode reward: 59.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.576 [0.000, 1.000], mean observation: -0.009 [-2.803, 1.739], mean_best_reward: --\n",
      " 40098/100000: episode: 1231, duration: 0.050s, episode steps: 119, steps per second: 2359, episode reward: 119.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.504 [0.000, 1.000], mean observation: 0.110 [-1.170, 0.917], mean_best_reward: --\n",
      " 40140/100000: episode: 1232, duration: 0.020s, episode steps: 42, steps per second: 2050, episode reward: 42.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.548 [0.000, 1.000], mean observation: -0.028 [-1.642, 0.957], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40264/100000: episode: 1233, duration: 0.056s, episode steps: 124, steps per second: 2229, episode reward: 124.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.484 [0.000, 1.000], mean observation: -0.137 [-1.859, 1.370], mean_best_reward: --\n",
      " 40301/100000: episode: 1234, duration: 0.032s, episode steps: 37, steps per second: 1145, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.541 [0.000, 1.000], mean observation: -0.089 [-1.581, 0.772], mean_best_reward: --\n",
      " 40324/100000: episode: 1235, duration: 0.012s, episode steps: 23, steps per second: 1963, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.565 [0.000, 1.000], mean observation: -0.082 [-1.704, 0.801], mean_best_reward: --\n",
      " 40524/100000: episode: 1236, duration: 0.084s, episode steps: 200, steps per second: 2382, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.075 [-1.272, 1.342], mean_best_reward: --\n",
      " 40623/100000: episode: 1237, duration: 0.040s, episode steps: 99, steps per second: 2472, episode reward: 99.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: -0.268 [-2.246, 1.259], mean_best_reward: --\n",
      " 40658/100000: episode: 1238, duration: 0.015s, episode steps: 35, steps per second: 2273, episode reward: 35.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: 0.111 [-0.480, 0.935], mean_best_reward: --\n",
      " 40699/100000: episode: 1239, duration: 0.027s, episode steps: 41, steps per second: 1516, episode reward: 41.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.463 [0.000, 1.000], mean observation: -0.104 [-1.035, 0.552], mean_best_reward: --\n",
      " 40749/100000: episode: 1240, duration: 0.040s, episode steps: 50, steps per second: 1249, episode reward: 50.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.151 [-1.249, 0.579], mean_best_reward: --\n",
      " 40814/100000: episode: 1241, duration: 0.050s, episode steps: 65, steps per second: 1313, episode reward: 65.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.508 [0.000, 1.000], mean observation: 0.214 [-0.787, 1.508], mean_best_reward: --\n",
      " 40862/100000: episode: 1242, duration: 0.038s, episode steps: 48, steps per second: 1274, episode reward: 48.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.521 [0.000, 1.000], mean observation: -0.116 [-1.662, 0.948], mean_best_reward: --\n",
      " 40975/100000: episode: 1243, duration: 0.046s, episode steps: 113, steps per second: 2459, episode reward: 113.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.460 [0.000, 1.000], mean observation: -0.371 [-2.437, 0.781], mean_best_reward: --\n",
      " 41011/100000: episode: 1244, duration: 0.017s, episode steps: 36, steps per second: 2130, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.444 [0.000, 1.000], mean observation: -0.087 [-0.954, 0.580], mean_best_reward: --\n",
      " 41189/100000: episode: 1245, duration: 0.086s, episode steps: 178, steps per second: 2081, episode reward: 178.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.489 [0.000, 1.000], mean observation: -0.342 [-2.412, 0.801], mean_best_reward: --\n",
      " 41281/100000: episode: 1246, duration: 0.040s, episode steps: 92, steps per second: 2300, episode reward: 92.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.457 [0.000, 1.000], mean observation: -0.177 [-1.631, 0.670], mean_best_reward: --\n",
      " 41301/100000: episode: 1247, duration: 0.010s, episode steps: 20, steps per second: 2075, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.065 [-1.484, 1.015], mean_best_reward: --\n",
      " 41353/100000: episode: 1248, duration: 0.023s, episode steps: 52, steps per second: 2281, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.519 [0.000, 1.000], mean observation: -0.040 [-1.684, 0.984], mean_best_reward: --\n",
      " 41425/100000: episode: 1249, duration: 0.030s, episode steps: 72, steps per second: 2406, episode reward: 72.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.556 [0.000, 1.000], mean observation: 0.213 [-0.439, 1.414], mean_best_reward: --\n",
      " 41454/100000: episode: 1250, duration: 0.013s, episode steps: 29, steps per second: 2182, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.552 [0.000, 1.000], mean observation: -0.081 [-1.705, 0.637], mean_best_reward: --\n",
      " 41505/100000: episode: 1251, duration: 0.022s, episode steps: 51, steps per second: 2289, episode reward: 51.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.549 [0.000, 1.000], mean observation: 0.120 [-0.805, 1.144], mean_best_reward: 107.500000\n",
      " 41592/100000: episode: 1252, duration: 0.036s, episode steps: 87, steps per second: 2435, episode reward: 87.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.494 [0.000, 1.000], mean observation: -0.018 [-0.980, 0.995], mean_best_reward: --\n",
      " 41657/100000: episode: 1253, duration: 0.033s, episode steps: 65, steps per second: 1979, episode reward: 65.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.492 [0.000, 1.000], mean observation: -0.009 [-0.812, 1.359], mean_best_reward: --\n",
      " 41704/100000: episode: 1254, duration: 0.036s, episode steps: 47, steps per second: 1313, episode reward: 47.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.468 [0.000, 1.000], mean observation: -0.122 [-1.115, 0.922], mean_best_reward: --\n",
      " 41763/100000: episode: 1255, duration: 0.028s, episode steps: 59, steps per second: 2130, episode reward: 59.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.525 [0.000, 1.000], mean observation: 0.109 [-0.775, 1.103], mean_best_reward: --\n",
      " 41849/100000: episode: 1256, duration: 0.036s, episode steps: 86, steps per second: 2405, episode reward: 86.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.512 [0.000, 1.000], mean observation: 0.170 [-1.196, 1.524], mean_best_reward: --\n",
      " 42000/100000: episode: 1257, duration: 0.065s, episode steps: 151, steps per second: 2329, episode reward: 151.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.080 [-1.534, 1.199], mean_best_reward: --\n",
      " 42026/100000: episode: 1258, duration: 0.012s, episode steps: 26, steps per second: 2141, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.079 [-1.244, 0.789], mean_best_reward: --\n",
      " 42095/100000: episode: 1259, duration: 0.035s, episode steps: 69, steps per second: 1995, episode reward: 69.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.522 [0.000, 1.000], mean observation: 0.135 [-0.683, 1.100], mean_best_reward: --\n",
      " 42107/100000: episode: 1260, duration: 0.014s, episode steps: 12, steps per second: 863, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.114 [-0.794, 1.554], mean_best_reward: --\n",
      " 42142/100000: episode: 1261, duration: 0.016s, episode steps: 35, steps per second: 2122, episode reward: 35.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.543 [0.000, 1.000], mean observation: 0.002 [-1.485, 1.019], mean_best_reward: --\n",
      " 42193/100000: episode: 1262, duration: 0.023s, episode steps: 51, steps per second: 2183, episode reward: 51.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.135 [-0.634, 1.312], mean_best_reward: --\n",
      " 42228/100000: episode: 1263, duration: 0.016s, episode steps: 35, steps per second: 2223, episode reward: 35.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.486 [0.000, 1.000], mean observation: -0.074 [-1.434, 0.759], mean_best_reward: --\n",
      " 42278/100000: episode: 1264, duration: 0.022s, episode steps: 50, steps per second: 2294, episode reward: 50.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.057 [-1.174, 0.406], mean_best_reward: --\n",
      " 42407/100000: episode: 1265, duration: 0.057s, episode steps: 129, steps per second: 2273, episode reward: 129.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: -0.192 [-1.322, 0.912], mean_best_reward: --\n",
      " 42476/100000: episode: 1266, duration: 0.030s, episode steps: 69, steps per second: 2328, episode reward: 69.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: -0.028 [-1.151, 1.356], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 42522/100000: episode: 1267, duration: 0.022s, episode steps: 46, steps per second: 2062, episode reward: 46.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: -0.157 [-1.250, 0.463], mean_best_reward: --\n",
      " 42550/100000: episode: 1268, duration: 0.018s, episode steps: 28, steps per second: 1515, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.110 [-1.037, 0.380], mean_best_reward: --\n",
      " 42583/100000: episode: 1269, duration: 0.019s, episode steps: 33, steps per second: 1743, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.089 [-0.842, 0.367], mean_best_reward: --\n",
      " 42602/100000: episode: 1270, duration: 0.010s, episode steps: 19, steps per second: 1955, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.421 [0.000, 1.000], mean observation: 0.057 [-1.019, 1.542], mean_best_reward: --\n",
      " 42701/100000: episode: 1271, duration: 0.042s, episode steps: 99, steps per second: 2346, episode reward: 99.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: 0.283 [-0.973, 1.972], mean_best_reward: --\n",
      " 42744/100000: episode: 1272, duration: 0.020s, episode steps: 43, steps per second: 2151, episode reward: 43.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.465 [0.000, 1.000], mean observation: -0.106 [-0.979, 0.581], mean_best_reward: --\n",
      " 42838/100000: episode: 1273, duration: 0.040s, episode steps: 94, steps per second: 2349, episode reward: 94.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.426 [0.000, 1.000], mean observation: -0.536 [-2.807, 0.871], mean_best_reward: --\n",
      " 42859/100000: episode: 1274, duration: 0.010s, episode steps: 21, steps per second: 2092, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: -0.085 [-1.199, 0.777], mean_best_reward: --\n",
      " 42918/100000: episode: 1275, duration: 0.025s, episode steps: 59, steps per second: 2330, episode reward: 59.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.508 [0.000, 1.000], mean observation: -0.021 [-1.199, 0.744], mean_best_reward: --\n",
      " 43027/100000: episode: 1276, duration: 0.060s, episode steps: 109, steps per second: 1822, episode reward: 109.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.486 [0.000, 1.000], mean observation: -0.174 [-1.551, 1.316], mean_best_reward: --\n",
      " 43087/100000: episode: 1277, duration: 0.027s, episode steps: 60, steps per second: 2222, episode reward: 60.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.533 [0.000, 1.000], mean observation: 0.037 [-0.823, 1.236], mean_best_reward: --\n",
      " 43140/100000: episode: 1278, duration: 0.023s, episode steps: 53, steps per second: 2289, episode reward: 53.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.528 [0.000, 1.000], mean observation: 0.043 [-0.972, 1.205], mean_best_reward: --\n",
      " 43177/100000: episode: 1279, duration: 0.017s, episode steps: 37, steps per second: 2164, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.459 [0.000, 1.000], mean observation: -0.117 [-0.846, 0.241], mean_best_reward: --\n",
      " 43217/100000: episode: 1280, duration: 0.018s, episode steps: 40, steps per second: 2248, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.525 [0.000, 1.000], mean observation: -0.060 [-1.678, 0.941], mean_best_reward: --\n",
      " 43236/100000: episode: 1281, duration: 0.010s, episode steps: 19, steps per second: 1845, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: 0.085 [-0.798, 1.233], mean_best_reward: --\n",
      " 43340/100000: episode: 1282, duration: 0.046s, episode steps: 104, steps per second: 2247, episode reward: 104.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.204 [-1.465, 0.710], mean_best_reward: --\n",
      " 43359/100000: episode: 1283, duration: 0.010s, episode steps: 19, steps per second: 1957, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.526 [0.000, 1.000], mean observation: -0.077 [-1.311, 0.812], mean_best_reward: --\n",
      " 43379/100000: episode: 1284, duration: 0.010s, episode steps: 20, steps per second: 2055, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.122 [-0.589, 1.041], mean_best_reward: --\n",
      " 43489/100000: episode: 1285, duration: 0.061s, episode steps: 110, steps per second: 1815, episode reward: 110.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.068 [-0.872, 0.721], mean_best_reward: --\n",
      " 43622/100000: episode: 1286, duration: 0.057s, episode steps: 133, steps per second: 2317, episode reward: 133.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.489 [0.000, 1.000], mean observation: -0.114 [-1.658, 1.130], mean_best_reward: --\n",
      " 43649/100000: episode: 1287, duration: 0.014s, episode steps: 27, steps per second: 2000, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.481 [0.000, 1.000], mean observation: -0.113 [-0.994, 0.577], mean_best_reward: --\n",
      " 43691/100000: episode: 1288, duration: 0.018s, episode steps: 42, steps per second: 2329, episode reward: 42.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.524 [0.000, 1.000], mean observation: 0.117 [-0.639, 1.038], mean_best_reward: --\n",
      " 43771/100000: episode: 1289, duration: 0.035s, episode steps: 80, steps per second: 2298, episode reward: 80.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.512 [0.000, 1.000], mean observation: 0.062 [-0.954, 0.943], mean_best_reward: --\n",
      " 43867/100000: episode: 1290, duration: 0.042s, episode steps: 96, steps per second: 2284, episode reward: 96.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.155 [-0.991, 1.082], mean_best_reward: --\n",
      " 43932/100000: episode: 1291, duration: 0.028s, episode steps: 65, steps per second: 2354, episode reward: 65.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.477 [0.000, 1.000], mean observation: -0.053 [-0.986, 1.195], mean_best_reward: --\n",
      " 43966/100000: episode: 1292, duration: 0.023s, episode steps: 34, steps per second: 1456, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.013 [-1.197, 1.007], mean_best_reward: --\n",
      " 43993/100000: episode: 1293, duration: 0.018s, episode steps: 27, steps per second: 1461, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.519 [0.000, 1.000], mean observation: -0.033 [-1.643, 1.024], mean_best_reward: --\n",
      " 44017/100000: episode: 1294, duration: 0.012s, episode steps: 24, steps per second: 2044, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.075 [-0.829, 1.499], mean_best_reward: --\n",
      " 44062/100000: episode: 1295, duration: 0.020s, episode steps: 45, steps per second: 2229, episode reward: 45.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.511 [0.000, 1.000], mean observation: 0.082 [-0.632, 1.090], mean_best_reward: --\n",
      " 44139/100000: episode: 1296, duration: 0.033s, episode steps: 77, steps per second: 2313, episode reward: 77.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: -0.312 [-1.646, 0.969], mean_best_reward: --\n",
      " 44183/100000: episode: 1297, duration: 0.020s, episode steps: 44, steps per second: 2229, episode reward: 44.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: -0.132 [-2.174, 0.772], mean_best_reward: --\n",
      " 44214/100000: episode: 1298, duration: 0.014s, episode steps: 31, steps per second: 2176, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.484 [0.000, 1.000], mean observation: 0.094 [-0.582, 1.263], mean_best_reward: --\n",
      " 44255/100000: episode: 1299, duration: 0.018s, episode steps: 41, steps per second: 2277, episode reward: 41.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: -0.117 [-1.047, 0.350], mean_best_reward: --\n",
      " 44444/100000: episode: 1300, duration: 0.083s, episode steps: 189, steps per second: 2285, episode reward: 189.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.529 [0.000, 1.000], mean observation: 0.227 [-1.382, 2.810], mean_best_reward: --\n",
      " 44496/100000: episode: 1301, duration: 0.028s, episode steps: 52, steps per second: 1876, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.519 [0.000, 1.000], mean observation: 0.133 [-0.421, 1.014], mean_best_reward: 193.000000\n",
      " 44539/100000: episode: 1302, duration: 0.020s, episode steps: 43, steps per second: 2148, episode reward: 43.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.558 [0.000, 1.000], mean observation: -0.071 [-2.099, 0.993], mean_best_reward: --\n",
      " 44605/100000: episode: 1303, duration: 0.029s, episode steps: 66, steps per second: 2279, episode reward: 66.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.039 [-1.338, 1.787], mean_best_reward: --\n",
      " 44634/100000: episode: 1304, duration: 0.013s, episode steps: 29, steps per second: 2215, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.517 [0.000, 1.000], mean observation: -0.061 [-1.375, 0.788], mean_best_reward: --\n",
      " 44671/100000: episode: 1305, duration: 0.017s, episode steps: 37, steps per second: 2178, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.595 [0.000, 1.000], mean observation: 0.034 [-2.058, 1.541], mean_best_reward: --\n",
      " 44683/100000: episode: 1306, duration: 0.007s, episode steps: 12, steps per second: 1844, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.833 [0.000, 1.000], mean observation: -0.070 [-2.622, 1.786], mean_best_reward: --\n",
      " 44856/100000: episode: 1307, duration: 0.070s, episode steps: 173, steps per second: 2470, episode reward: 173.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.486 [0.000, 1.000], mean observation: -0.135 [-1.683, 1.310], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44912/100000: episode: 1308, duration: 0.028s, episode steps: 56, steps per second: 1971, episode reward: 56.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.482 [0.000, 1.000], mean observation: -0.135 [-1.305, 0.521], mean_best_reward: --\n",
      " 44957/100000: episode: 1309, duration: 0.030s, episode steps: 45, steps per second: 1483, episode reward: 45.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.175 [-1.281, 0.788], mean_best_reward: --\n",
      " 45088/100000: episode: 1310, duration: 0.056s, episode steps: 131, steps per second: 2339, episode reward: 131.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.542 [0.000, 1.000], mean observation: 0.161 [-1.918, 2.114], mean_best_reward: --\n",
      " 45112/100000: episode: 1311, duration: 0.012s, episode steps: 24, steps per second: 2074, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.458 [0.000, 1.000], mean observation: -0.052 [-1.152, 0.635], mean_best_reward: --\n",
      " 45131/100000: episode: 1312, duration: 0.010s, episode steps: 19, steps per second: 1957, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.632 [0.000, 1.000], mean observation: -0.072 [-1.865, 1.038], mean_best_reward: --\n",
      " 45191/100000: episode: 1313, duration: 0.025s, episode steps: 60, steps per second: 2376, episode reward: 60.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.550 [0.000, 1.000], mean observation: -0.010 [-1.939, 1.173], mean_best_reward: --\n",
      " 45332/100000: episode: 1314, duration: 0.057s, episode steps: 141, steps per second: 2462, episode reward: 141.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.518 [0.000, 1.000], mean observation: 0.329 [-0.886, 2.067], mean_best_reward: --\n",
      " 45350/100000: episode: 1315, duration: 0.010s, episode steps: 18, steps per second: 1821, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.389 [0.000, 1.000], mean observation: 0.088 [-1.004, 1.850], mean_best_reward: --\n",
      " 45452/100000: episode: 1316, duration: 0.056s, episode steps: 102, steps per second: 1834, episode reward: 102.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.153 [-0.991, 1.201], mean_best_reward: --\n",
      " 45476/100000: episode: 1317, duration: 0.012s, episode steps: 24, steps per second: 2010, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.417 [0.000, 1.000], mean observation: -0.114 [-1.010, 0.566], mean_best_reward: --\n",
      " 45515/100000: episode: 1318, duration: 0.018s, episode steps: 39, steps per second: 2124, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: -0.091 [-1.696, 0.660], mean_best_reward: --\n",
      " 45627/100000: episode: 1319, duration: 0.045s, episode steps: 112, steps per second: 2474, episode reward: 112.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: -0.031 [-2.606, 1.895], mean_best_reward: --\n",
      " 45753/100000: episode: 1320, duration: 0.054s, episode steps: 126, steps per second: 2327, episode reward: 126.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: -0.135 [-1.667, 1.028], mean_best_reward: --\n",
      " 45797/100000: episode: 1321, duration: 0.024s, episode steps: 44, steps per second: 1856, episode reward: 44.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.477 [0.000, 1.000], mean observation: 0.067 [-0.903, 1.552], mean_best_reward: --\n",
      " 45955/100000: episode: 1322, duration: 0.077s, episode steps: 158, steps per second: 2064, episode reward: 158.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.544 [0.000, 1.000], mean observation: 0.017 [-2.403, 2.819], mean_best_reward: --\n",
      " 45969/100000: episode: 1323, duration: 0.007s, episode steps: 14, steps per second: 1939, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.643 [0.000, 1.000], mean observation: -0.073 [-1.425, 1.006], mean_best_reward: --\n",
      " 46020/100000: episode: 1324, duration: 0.023s, episode steps: 51, steps per second: 2264, episode reward: 51.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.549 [0.000, 1.000], mean observation: 0.038 [-1.865, 1.507], mean_best_reward: --\n",
      " 46079/100000: episode: 1325, duration: 0.033s, episode steps: 59, steps per second: 1814, episode reward: 59.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.508 [0.000, 1.000], mean observation: 0.020 [-0.703, 1.126], mean_best_reward: --\n",
      " 46196/100000: episode: 1326, duration: 0.049s, episode steps: 117, steps per second: 2396, episode reward: 117.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.573 [0.000, 1.000], mean observation: 0.220 [-2.613, 3.201], mean_best_reward: --\n",
      " 46311/100000: episode: 1327, duration: 0.057s, episode steps: 115, steps per second: 2013, episode reward: 115.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.513 [0.000, 1.000], mean observation: -0.003 [-1.002, 1.172], mean_best_reward: --\n",
      " 46364/100000: episode: 1328, duration: 0.023s, episode steps: 53, steps per second: 2312, episode reward: 53.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.472 [0.000, 1.000], mean observation: -0.033 [-1.317, 1.387], mean_best_reward: --\n",
      " 46415/100000: episode: 1329, duration: 0.023s, episode steps: 51, steps per second: 2192, episode reward: 51.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.076 [-1.373, 0.981], mean_best_reward: --\n",
      " 46515/100000: episode: 1330, duration: 0.042s, episode steps: 100, steps per second: 2356, episode reward: 100.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.169 [-1.688, 1.161], mean_best_reward: --\n",
      " 46595/100000: episode: 1331, duration: 0.034s, episode steps: 80, steps per second: 2367, episode reward: 80.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.438 [0.000, 1.000], mean observation: -0.247 [-2.094, 1.764], mean_best_reward: --\n",
      " 46625/100000: episode: 1332, duration: 0.014s, episode steps: 30, steps per second: 2096, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.567 [0.000, 1.000], mean observation: -0.083 [-1.888, 0.822], mean_best_reward: --\n",
      " 46729/100000: episode: 1333, duration: 0.043s, episode steps: 104, steps per second: 2398, episode reward: 104.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.106 [-1.068, 1.122], mean_best_reward: --\n",
      " 46775/100000: episode: 1334, duration: 0.022s, episode steps: 46, steps per second: 2072, episode reward: 46.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.457 [0.000, 1.000], mean observation: 0.048 [-1.022, 1.722], mean_best_reward: --\n",
      " 46855/100000: episode: 1335, duration: 0.043s, episode steps: 80, steps per second: 1853, episode reward: 80.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.525 [0.000, 1.000], mean observation: 0.124 [-1.323, 1.526], mean_best_reward: --\n",
      " 46972/100000: episode: 1336, duration: 0.049s, episode steps: 117, steps per second: 2379, episode reward: 117.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.358 [-2.406, 1.203], mean_best_reward: --\n",
      " 47037/100000: episode: 1337, duration: 0.028s, episode steps: 65, steps per second: 2296, episode reward: 65.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.492 [0.000, 1.000], mean observation: 0.093 [-0.514, 1.320], mean_best_reward: --\n",
      " 47085/100000: episode: 1338, duration: 0.022s, episode steps: 48, steps per second: 2225, episode reward: 48.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.521 [0.000, 1.000], mean observation: -0.059 [-1.573, 0.632], mean_best_reward: --\n",
      " 47114/100000: episode: 1339, duration: 0.014s, episode steps: 29, steps per second: 2102, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.586 [0.000, 1.000], mean observation: -0.009 [-1.666, 1.032], mean_best_reward: --\n",
      " 47141/100000: episode: 1340, duration: 0.013s, episode steps: 27, steps per second: 2053, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.630 [0.000, 1.000], mean observation: -0.060 [-2.478, 1.424], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 47286/100000: episode: 1341, duration: 0.076s, episode steps: 145, steps per second: 1916, episode reward: 145.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.150 [-1.535, 1.006], mean_best_reward: --\n",
      " 47312/100000: episode: 1342, duration: 0.013s, episode steps: 26, steps per second: 1993, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.577 [0.000, 1.000], mean observation: -0.054 [-1.526, 0.967], mean_best_reward: --\n",
      " 47365/100000: episode: 1343, duration: 0.024s, episode steps: 53, steps per second: 2185, episode reward: 53.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.509 [0.000, 1.000], mean observation: 0.042 [-1.044, 0.994], mean_best_reward: --\n",
      " 47416/100000: episode: 1344, duration: 0.023s, episode steps: 51, steps per second: 2217, episode reward: 51.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.549 [0.000, 1.000], mean observation: 0.145 [-0.625, 1.064], mean_best_reward: --\n",
      " 47430/100000: episode: 1345, duration: 0.007s, episode steps: 14, steps per second: 1899, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.643 [0.000, 1.000], mean observation: -0.085 [-1.599, 0.832], mean_best_reward: --\n",
      " 47557/100000: episode: 1346, duration: 0.052s, episode steps: 127, steps per second: 2431, episode reward: 127.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.433 [0.000, 1.000], mean observation: -0.387 [-3.327, 1.563], mean_best_reward: --\n",
      " 47589/100000: episode: 1347, duration: 0.016s, episode steps: 32, steps per second: 2042, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.594 [0.000, 1.000], mean observation: -0.023 [-2.188, 1.405], mean_best_reward: --\n",
      " 47655/100000: episode: 1348, duration: 0.028s, episode steps: 66, steps per second: 2354, episode reward: 66.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.576 [0.000, 1.000], mean observation: 0.125 [-2.085, 1.911], mean_best_reward: --\n",
      " 47716/100000: episode: 1349, duration: 0.026s, episode steps: 61, steps per second: 2372, episode reward: 61.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.492 [0.000, 1.000], mean observation: 0.025 [-1.007, 0.920], mean_best_reward: --\n",
      " 47800/100000: episode: 1350, duration: 0.049s, episode steps: 84, steps per second: 1723, episode reward: 84.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: -0.051 [-0.849, 0.604], mean_best_reward: --\n",
      " 47867/100000: episode: 1351, duration: 0.030s, episode steps: 67, steps per second: 2208, episode reward: 67.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: -0.048 [-1.015, 0.591], mean_best_reward: 180.500000\n",
      " 47888/100000: episode: 1352, duration: 0.011s, episode steps: 21, steps per second: 1942, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.619 [0.000, 1.000], mean observation: -0.057 [-1.809, 0.997], mean_best_reward: --\n",
      " 47939/100000: episode: 1353, duration: 0.023s, episode steps: 51, steps per second: 2241, episode reward: 51.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.135 [-1.047, 0.442], mean_best_reward: --\n",
      " 47956/100000: episode: 1354, duration: 0.008s, episode steps: 17, steps per second: 2002, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.072 [-1.264, 0.784], mean_best_reward: --\n",
      " 47990/100000: episode: 1355, duration: 0.016s, episode steps: 34, steps per second: 2166, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.559 [0.000, 1.000], mean observation: 0.135 [-0.438, 0.941], mean_best_reward: --\n",
      " 48036/100000: episode: 1356, duration: 0.020s, episode steps: 46, steps per second: 2264, episode reward: 46.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: -0.102 [-1.181, 1.261], mean_best_reward: --\n",
      " 48205/100000: episode: 1357, duration: 0.078s, episode steps: 169, steps per second: 2157, episode reward: 169.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.497 [0.000, 1.000], mean observation: -0.155 [-1.333, 0.770], mean_best_reward: --\n",
      " 48269/100000: episode: 1358, duration: 0.034s, episode steps: 64, steps per second: 1861, episode reward: 64.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.578 [0.000, 1.000], mean observation: 0.124 [-1.832, 2.063], mean_best_reward: --\n",
      " 48282/100000: episode: 1359, duration: 0.011s, episode steps: 13, steps per second: 1170, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.769 [0.000, 1.000], mean observation: -0.085 [-2.259, 1.401], mean_best_reward: --\n",
      " 48310/100000: episode: 1360, duration: 0.013s, episode steps: 28, steps per second: 2108, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.571 [0.000, 1.000], mean observation: 0.131 [-0.591, 0.884], mean_best_reward: --\n",
      " 48348/100000: episode: 1361, duration: 0.018s, episode steps: 38, steps per second: 2107, episode reward: 38.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.447 [0.000, 1.000], mean observation: -0.060 [-1.100, 0.807], mean_best_reward: --\n",
      " 48435/100000: episode: 1362, duration: 0.040s, episode steps: 87, steps per second: 2184, episode reward: 87.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.540 [0.000, 1.000], mean observation: 0.236 [-0.939, 1.647], mean_best_reward: --\n",
      " 48455/100000: episode: 1363, duration: 0.010s, episode steps: 20, steps per second: 1905, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.108 [-1.092, 0.368], mean_best_reward: --\n",
      " 48472/100000: episode: 1364, duration: 0.009s, episode steps: 17, steps per second: 1821, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.588 [0.000, 1.000], mean observation: -0.092 [-1.354, 0.760], mean_best_reward: --\n",
      " 48493/100000: episode: 1365, duration: 0.010s, episode steps: 21, steps per second: 2095, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.032 [-1.598, 2.278], mean_best_reward: --\n",
      " 48542/100000: episode: 1366, duration: 0.021s, episode steps: 49, steps per second: 2312, episode reward: 49.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.132 [-0.706, 1.252], mean_best_reward: --\n",
      " 48680/100000: episode: 1367, duration: 0.055s, episode steps: 138, steps per second: 2487, episode reward: 138.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.529 [0.000, 1.000], mean observation: -0.075 [-1.589, 1.738], mean_best_reward: --\n",
      " 48715/100000: episode: 1368, duration: 0.020s, episode steps: 35, steps per second: 1784, episode reward: 35.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.486 [0.000, 1.000], mean observation: 0.082 [-0.453, 1.299], mean_best_reward: --\n",
      " 48772/100000: episode: 1369, duration: 0.034s, episode steps: 57, steps per second: 1672, episode reward: 57.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.491 [0.000, 1.000], mean observation: -0.048 [-1.045, 0.623], mean_best_reward: --\n",
      " 48796/100000: episode: 1370, duration: 0.012s, episode steps: 24, steps per second: 1958, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.113 [-0.372, 1.110], mean_best_reward: --\n",
      " 48815/100000: episode: 1371, duration: 0.009s, episode steps: 19, steps per second: 2001, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.526 [0.000, 1.000], mean observation: 0.116 [-0.589, 1.055], mean_best_reward: --\n",
      " 48950/100000: episode: 1372, duration: 0.055s, episode steps: 135, steps per second: 2476, episode reward: 135.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.496 [0.000, 1.000], mean observation: -0.268 [-1.641, 0.773], mean_best_reward: --\n",
      " 49043/100000: episode: 1373, duration: 0.040s, episode steps: 93, steps per second: 2316, episode reward: 93.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.602 [0.000, 1.000], mean observation: 0.111 [-3.258, 3.552], mean_best_reward: --\n",
      " 49118/100000: episode: 1374, duration: 0.033s, episode steps: 75, steps per second: 2296, episode reward: 75.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.059 [-1.528, 1.604], mean_best_reward: --\n",
      " 49132/100000: episode: 1375, duration: 0.008s, episode steps: 14, steps per second: 1717, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.857 [0.000, 1.000], mean observation: -0.100 [-3.006, 1.919], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 49157/100000: episode: 1376, duration: 0.016s, episode steps: 25, steps per second: 1541, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: 0.084 [-0.589, 0.946], mean_best_reward: --\n",
      " 49200/100000: episode: 1377, duration: 0.030s, episode steps: 43, steps per second: 1419, episode reward: 43.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.465 [0.000, 1.000], mean observation: -0.065 [-1.158, 1.153], mean_best_reward: --\n",
      " 49278/100000: episode: 1378, duration: 0.033s, episode steps: 78, steps per second: 2346, episode reward: 78.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.487 [0.000, 1.000], mean observation: -0.083 [-1.178, 1.117], mean_best_reward: --\n",
      " 49324/100000: episode: 1379, duration: 0.021s, episode steps: 46, steps per second: 2169, episode reward: 46.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.652 [0.000, 1.000], mean observation: 0.106 [-3.179, 2.722], mean_best_reward: --\n",
      " 49350/100000: episode: 1380, duration: 0.012s, episode steps: 26, steps per second: 2122, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: 0.076 [-0.798, 1.208], mean_best_reward: --\n",
      " 49431/100000: episode: 1381, duration: 0.033s, episode steps: 81, steps per second: 2419, episode reward: 81.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.457 [0.000, 1.000], mean observation: -0.226 [-1.506, 0.823], mean_best_reward: --\n",
      " 49521/100000: episode: 1382, duration: 0.038s, episode steps: 90, steps per second: 2348, episode reward: 90.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.456 [0.000, 1.000], mean observation: -0.064 [-1.565, 2.387], mean_best_reward: --\n",
      " 49617/100000: episode: 1383, duration: 0.049s, episode steps: 96, steps per second: 1963, episode reward: 96.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.448 [0.000, 1.000], mean observation: -0.176 [-2.582, 1.723], mean_best_reward: --\n",
      " 49668/100000: episode: 1384, duration: 0.029s, episode steps: 51, steps per second: 1784, episode reward: 51.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.627 [0.000, 1.000], mean observation: 0.123 [-2.671, 2.460], mean_best_reward: --\n",
      " 49692/100000: episode: 1385, duration: 0.012s, episode steps: 24, steps per second: 1984, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.458 [0.000, 1.000], mean observation: 0.031 [-1.178, 1.697], mean_best_reward: --\n",
      " 49714/100000: episode: 1386, duration: 0.010s, episode steps: 22, steps per second: 2168, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: 0.017 [-1.180, 1.617], mean_best_reward: --\n",
      " 49754/100000: episode: 1387, duration: 0.018s, episode steps: 40, steps per second: 2249, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.049 [-1.268, 1.164], mean_best_reward: --\n",
      " 49817/100000: episode: 1388, duration: 0.027s, episode steps: 63, steps per second: 2345, episode reward: 63.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.460 [0.000, 1.000], mean observation: -0.161 [-1.697, 1.281], mean_best_reward: --\n",
      " 49875/100000: episode: 1389, duration: 0.024s, episode steps: 58, steps per second: 2384, episode reward: 58.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.076 [-0.679, 1.516], mean_best_reward: --\n",
      " 49967/100000: episode: 1390, duration: 0.040s, episode steps: 92, steps per second: 2301, episode reward: 92.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.457 [0.000, 1.000], mean observation: -0.357 [-1.841, 1.081], mean_best_reward: --\n",
      " 49987/100000: episode: 1391, duration: 0.010s, episode steps: 20, steps per second: 2072, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.042 [-2.862, 1.938], mean_best_reward: --\n",
      " 50008/100000: episode: 1392, duration: 0.010s, episode steps: 21, steps per second: 2134, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.524 [0.000, 1.000], mean observation: -0.081 [-1.406, 0.926], mean_best_reward: --\n",
      " 50072/100000: episode: 1393, duration: 0.031s, episode steps: 64, steps per second: 2073, episode reward: 64.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.484 [0.000, 1.000], mean observation: 0.061 [-1.216, 1.986], mean_best_reward: --\n",
      " 50261/100000: episode: 1394, duration: 0.085s, episode steps: 189, steps per second: 2234, episode reward: 189.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.497 [0.000, 1.000], mean observation: 0.111 [-0.995, 1.173], mean_best_reward: --\n",
      " 50318/100000: episode: 1395, duration: 0.024s, episode steps: 57, steps per second: 2334, episode reward: 57.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.491 [0.000, 1.000], mean observation: -0.091 [-1.199, 0.412], mean_best_reward: --\n",
      " 50355/100000: episode: 1396, duration: 0.017s, episode steps: 37, steps per second: 2230, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.486 [0.000, 1.000], mean observation: -0.024 [-1.447, 1.014], mean_best_reward: --\n",
      " 50429/100000: episode: 1397, duration: 0.031s, episode steps: 74, steps per second: 2390, episode reward: 74.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.527 [0.000, 1.000], mean observation: 0.047 [-1.678, 1.372], mean_best_reward: --\n",
      " 50560/100000: episode: 1398, duration: 0.059s, episode steps: 131, steps per second: 2235, episode reward: 131.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.550 [0.000, 1.000], mean observation: 0.391 [-1.694, 2.426], mean_best_reward: --\n",
      " 50585/100000: episode: 1399, duration: 0.016s, episode steps: 25, steps per second: 1534, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.560 [0.000, 1.000], mean observation: -0.063 [-1.786, 1.038], mean_best_reward: --\n",
      " 50637/100000: episode: 1400, duration: 0.024s, episode steps: 52, steps per second: 2140, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.163 [-1.119, 0.461], mean_best_reward: --\n",
      " 50675/100000: episode: 1401, duration: 0.017s, episode steps: 38, steps per second: 2175, episode reward: 38.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.042 [-0.937, 0.452], mean_best_reward: 194.000000\n",
      " 50728/100000: episode: 1402, duration: 0.023s, episode steps: 53, steps per second: 2353, episode reward: 53.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.491 [0.000, 1.000], mean observation: -0.041 [-0.979, 0.732], mean_best_reward: --\n",
      " 50841/100000: episode: 1403, duration: 0.046s, episode steps: 113, steps per second: 2432, episode reward: 113.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.513 [0.000, 1.000], mean observation: 0.254 [-1.060, 1.681], mean_best_reward: --\n",
      " 50905/100000: episode: 1404, duration: 0.029s, episode steps: 64, steps per second: 2195, episode reward: 64.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.516 [0.000, 1.000], mean observation: 0.128 [-0.610, 1.065], mean_best_reward: --\n",
      " 50987/100000: episode: 1405, duration: 0.034s, episode steps: 82, steps per second: 2426, episode reward: 82.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: -0.176 [-1.210, 0.497], mean_best_reward: --\n",
      " 51070/100000: episode: 1406, duration: 0.044s, episode steps: 83, steps per second: 1880, episode reward: 83.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.494 [0.000, 1.000], mean observation: 0.112 [-1.304, 1.439], mean_best_reward: --\n",
      " 51103/100000: episode: 1407, duration: 0.015s, episode steps: 33, steps per second: 2148, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.025 [-0.633, 0.991], mean_best_reward: --\n",
      " 51126/100000: episode: 1408, duration: 0.012s, episode steps: 23, steps per second: 1976, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: -0.072 [-1.399, 0.802], mean_best_reward: --\n",
      " 51166/100000: episode: 1409, duration: 0.019s, episode steps: 40, steps per second: 2076, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.085 [-1.136, 0.553], mean_best_reward: --\n",
      " 51274/100000: episode: 1410, duration: 0.044s, episode steps: 108, steps per second: 2458, episode reward: 108.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.509 [0.000, 1.000], mean observation: -0.228 [-1.773, 0.786], mean_best_reward: --\n",
      " 51321/100000: episode: 1411, duration: 0.021s, episode steps: 47, steps per second: 2277, episode reward: 47.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.574 [0.000, 1.000], mean observation: -0.033 [-2.412, 1.555], mean_best_reward: --\n",
      " 51454/100000: episode: 1412, duration: 0.060s, episode steps: 133, steps per second: 2218, episode reward: 133.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.496 [0.000, 1.000], mean observation: -0.156 [-1.073, 1.235], mean_best_reward: --\n",
      " 51484/100000: episode: 1413, duration: 0.013s, episode steps: 30, steps per second: 2231, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.633 [0.000, 1.000], mean observation: -0.045 [-2.319, 1.506], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 51526/100000: episode: 1414, duration: 0.019s, episode steps: 42, steps per second: 2241, episode reward: 42.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.524 [0.000, 1.000], mean observation: 0.113 [-0.409, 0.859], mean_best_reward: --\n",
      " 51657/100000: episode: 1415, duration: 0.069s, episode steps: 131, steps per second: 1901, episode reward: 131.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.534 [0.000, 1.000], mean observation: 0.073 [-2.256, 1.776], mean_best_reward: --\n",
      " 51683/100000: episode: 1416, duration: 0.012s, episode steps: 26, steps per second: 2081, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.615 [0.000, 1.000], mean observation: -0.051 [-1.976, 1.184], mean_best_reward: --\n",
      " 51714/100000: episode: 1417, duration: 0.014s, episode steps: 31, steps per second: 2241, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.516 [0.000, 1.000], mean observation: 0.066 [-0.999, 1.444], mean_best_reward: --\n",
      " 51783/100000: episode: 1418, duration: 0.029s, episode steps: 69, steps per second: 2365, episode reward: 69.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.507 [0.000, 1.000], mean observation: 0.072 [-1.182, 1.190], mean_best_reward: --\n",
      " 51911/100000: episode: 1419, duration: 0.054s, episode steps: 128, steps per second: 2357, episode reward: 128.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.555 [0.000, 1.000], mean observation: 0.424 [-0.927, 2.929], mean_best_reward: --\n",
      " 51942/100000: episode: 1420, duration: 0.014s, episode steps: 31, steps per second: 2182, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.548 [0.000, 1.000], mean observation: 0.126 [-0.269, 0.857], mean_best_reward: --\n",
      " 52045/100000: episode: 1421, duration: 0.055s, episode steps: 103, steps per second: 1888, episode reward: 103.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.544 [0.000, 1.000], mean observation: 0.255 [-1.422, 1.706], mean_best_reward: --\n",
      " 52218/100000: episode: 1422, duration: 0.073s, episode steps: 173, steps per second: 2381, episode reward: 173.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.491 [0.000, 1.000], mean observation: -0.224 [-1.450, 1.149], mean_best_reward: --\n",
      " 52251/100000: episode: 1423, duration: 0.015s, episode steps: 33, steps per second: 2214, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.077 [-0.917, 0.549], mean_best_reward: --\n",
      " 52451/100000: episode: 1424, duration: 0.083s, episode steps: 200, steps per second: 2406, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: 0.127 [-1.121, 0.926], mean_best_reward: --\n",
      " 52477/100000: episode: 1425, duration: 0.013s, episode steps: 26, steps per second: 2058, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: 0.038 [-0.972, 1.518], mean_best_reward: --\n",
      " 52551/100000: episode: 1426, duration: 0.037s, episode steps: 74, steps per second: 1996, episode reward: 74.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: 0.123 [-1.122, 1.282], mean_best_reward: --\n",
      " 52607/100000: episode: 1427, duration: 0.029s, episode steps: 56, steps per second: 1931, episode reward: 56.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.133 [-1.723, 1.127], mean_best_reward: --\n",
      " 52635/100000: episode: 1428, duration: 0.014s, episode steps: 28, steps per second: 1964, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.058 [-0.843, 1.490], mean_best_reward: --\n",
      " 52671/100000: episode: 1429, duration: 0.018s, episode steps: 36, steps per second: 2027, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.528 [0.000, 1.000], mean observation: 0.101 [-0.513, 1.088], mean_best_reward: --\n",
      " 52724/100000: episode: 1430, duration: 0.025s, episode steps: 53, steps per second: 2146, episode reward: 53.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.528 [0.000, 1.000], mean observation: 0.101 [-0.580, 0.927], mean_best_reward: --\n",
      " 52741/100000: episode: 1431, duration: 0.009s, episode steps: 17, steps per second: 1844, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.529 [0.000, 1.000], mean observation: -0.120 [-1.034, 0.597], mean_best_reward: --\n",
      " 52775/100000: episode: 1432, duration: 0.016s, episode steps: 34, steps per second: 2179, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.014 [-0.627, 0.929], mean_best_reward: --\n",
      " 52816/100000: episode: 1433, duration: 0.018s, episode steps: 41, steps per second: 2259, episode reward: 41.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.512 [0.000, 1.000], mean observation: 0.111 [-0.393, 1.246], mean_best_reward: --\n",
      " 52875/100000: episode: 1434, duration: 0.025s, episode steps: 59, steps per second: 2328, episode reward: 59.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.458 [0.000, 1.000], mean observation: -0.099 [-1.129, 1.358], mean_best_reward: --\n",
      " 52912/100000: episode: 1435, duration: 0.016s, episode steps: 37, steps per second: 2262, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: 0.028 [-0.761, 1.069], mean_best_reward: --\n",
      " 52945/100000: episode: 1436, duration: 0.015s, episode steps: 33, steps per second: 2271, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.103 [-0.368, 0.996], mean_best_reward: --\n",
      " 52962/100000: episode: 1437, duration: 0.008s, episode steps: 17, steps per second: 2010, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: 0.095 [-0.793, 1.456], mean_best_reward: --\n",
      " 53065/100000: episode: 1438, duration: 0.056s, episode steps: 103, steps per second: 1852, episode reward: 103.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.094 [-0.638, 1.515], mean_best_reward: --\n",
      " 53151/100000: episode: 1439, duration: 0.038s, episode steps: 86, steps per second: 2271, episode reward: 86.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: -0.077 [-1.170, 1.337], mean_best_reward: --\n",
      " 53162/100000: episode: 1440, duration: 0.006s, episode steps: 11, steps per second: 1745, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.636 [0.000, 1.000], mean observation: -0.106 [-1.750, 1.191], mean_best_reward: --\n",
      " 53182/100000: episode: 1441, duration: 0.010s, episode steps: 20, steps per second: 2043, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.069 [-1.215, 0.638], mean_best_reward: --\n",
      " 53238/100000: episode: 1442, duration: 0.024s, episode steps: 56, steps per second: 2340, episode reward: 56.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.037 [-0.628, 1.245], mean_best_reward: --\n",
      " 53321/100000: episode: 1443, duration: 0.036s, episode steps: 83, steps per second: 2286, episode reward: 83.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.506 [0.000, 1.000], mean observation: 0.143 [-0.913, 1.386], mean_best_reward: --\n",
      " 53410/100000: episode: 1444, duration: 0.037s, episode steps: 89, steps per second: 2404, episode reward: 89.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.562 [0.000, 1.000], mean observation: 0.225 [-1.576, 2.294], mean_best_reward: --\n",
      " 53487/100000: episode: 1445, duration: 0.035s, episode steps: 77, steps per second: 2177, episode reward: 77.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.558 [0.000, 1.000], mean observation: 0.213 [-1.410, 2.058], mean_best_reward: --\n",
      " 53553/100000: episode: 1446, duration: 0.040s, episode steps: 66, steps per second: 1656, episode reward: 66.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: -0.056 [-1.315, 0.675], mean_best_reward: --\n",
      " 53581/100000: episode: 1447, duration: 0.015s, episode steps: 28, steps per second: 1888, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.119 [-0.904, 0.380], mean_best_reward: --\n",
      " 53689/100000: episode: 1448, duration: 0.047s, episode steps: 108, steps per second: 2309, episode reward: 108.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.546 [0.000, 1.000], mean observation: 0.387 [-0.863, 1.846], mean_best_reward: --\n",
      " 53805/100000: episode: 1449, duration: 0.048s, episode steps: 116, steps per second: 2409, episode reward: 116.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.466 [0.000, 1.000], mean observation: -0.496 [-2.311, 1.019], mean_best_reward: --\n",
      " 53840/100000: episode: 1450, duration: 0.016s, episode steps: 35, steps per second: 2255, episode reward: 35.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.543 [0.000, 1.000], mean observation: 0.096 [-0.387, 0.730], mean_best_reward: --\n",
      " 53864/100000: episode: 1451, duration: 0.012s, episode steps: 24, steps per second: 2041, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.458 [0.000, 1.000], mean observation: -0.111 [-1.099, 0.610], mean_best_reward: 164.000000\n",
      " 53913/100000: episode: 1452, duration: 0.021s, episode steps: 49, steps per second: 2307, episode reward: 49.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.408 [0.000, 1.000], mean observation: -0.105 [-1.902, 1.801], mean_best_reward: --\n",
      " 53952/100000: episode: 1453, duration: 0.019s, episode steps: 39, steps per second: 2016, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.487 [0.000, 1.000], mean observation: -0.077 [-0.923, 0.550], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 54022/100000: episode: 1454, duration: 0.031s, episode steps: 70, steps per second: 2268, episode reward: 70.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.486 [0.000, 1.000], mean observation: -0.031 [-0.985, 0.786], mean_best_reward: --\n",
      " 54087/100000: episode: 1455, duration: 0.036s, episode steps: 65, steps per second: 1822, episode reward: 65.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.569 [0.000, 1.000], mean observation: -0.030 [-2.467, 1.777], mean_best_reward: --\n",
      " 54161/100000: episode: 1456, duration: 0.033s, episode steps: 74, steps per second: 2224, episode reward: 74.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.541 [0.000, 1.000], mean observation: 0.182 [-0.586, 1.475], mean_best_reward: --\n",
      " 54175/100000: episode: 1457, duration: 0.008s, episode steps: 14, steps per second: 1800, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.714 [0.000, 1.000], mean observation: -0.084 [-2.154, 1.352], mean_best_reward: --\n",
      " 54193/100000: episode: 1458, duration: 0.009s, episode steps: 18, steps per second: 1996, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.444 [0.000, 1.000], mean observation: 0.063 [-0.838, 1.435], mean_best_reward: --\n",
      " 54289/100000: episode: 1459, duration: 0.040s, episode steps: 96, steps per second: 2412, episode reward: 96.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.552 [0.000, 1.000], mean observation: 0.059 [-2.239, 2.273], mean_best_reward: --\n",
      " 54309/100000: episode: 1460, duration: 0.010s, episode steps: 20, steps per second: 2078, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.114 [-0.581, 1.040], mean_best_reward: --\n",
      " 54424/100000: episode: 1461, duration: 0.047s, episode steps: 115, steps per second: 2429, episode reward: 115.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.461 [0.000, 1.000], mean observation: -0.183 [-2.241, 1.641], mean_best_reward: --\n",
      " 54454/100000: episode: 1462, duration: 0.013s, episode steps: 30, steps per second: 2229, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.567 [0.000, 1.000], mean observation: -0.028 [-1.573, 0.788], mean_best_reward: --\n",
      " 54506/100000: episode: 1463, duration: 0.032s, episode steps: 52, steps per second: 1627, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: 0.198 [-0.564, 1.124], mean_best_reward: --\n",
      " 54565/100000: episode: 1464, duration: 0.030s, episode steps: 59, steps per second: 1936, episode reward: 59.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.458 [0.000, 1.000], mean observation: -0.153 [-1.509, 1.132], mean_best_reward: --\n",
      " 54584/100000: episode: 1465, duration: 0.016s, episode steps: 19, steps per second: 1220, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.526 [0.000, 1.000], mean observation: 0.059 [-0.834, 1.268], mean_best_reward: --\n",
      " 54614/100000: episode: 1466, duration: 0.015s, episode steps: 30, steps per second: 2016, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.061 [-0.602, 1.186], mean_best_reward: --\n",
      " 54653/100000: episode: 1467, duration: 0.018s, episode steps: 39, steps per second: 2166, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.487 [0.000, 1.000], mean observation: -0.040 [-0.866, 0.629], mean_best_reward: --\n",
      " 54682/100000: episode: 1468, duration: 0.013s, episode steps: 29, steps per second: 2205, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.414 [0.000, 1.000], mean observation: 0.065 [-1.168, 2.023], mean_best_reward: --\n",
      " 54696/100000: episode: 1469, duration: 0.007s, episode steps: 14, steps per second: 1934, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.786 [0.000, 1.000], mean observation: -0.099 [-2.630, 1.591], mean_best_reward: --\n",
      " 54780/100000: episode: 1470, duration: 0.036s, episode steps: 84, steps per second: 2362, episode reward: 84.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.595 [0.000, 1.000], mean observation: 0.276 [-2.445, 2.976], mean_best_reward: --\n",
      " 54868/100000: episode: 1471, duration: 0.036s, episode steps: 88, steps per second: 2431, episode reward: 88.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.466 [0.000, 1.000], mean observation: -0.150 [-1.614, 0.792], mean_best_reward: --\n",
      " 54892/100000: episode: 1472, duration: 0.012s, episode steps: 24, steps per second: 2014, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.625 [0.000, 1.000], mean observation: -0.042 [-2.015, 1.188], mean_best_reward: --\n",
      " 54906/100000: episode: 1473, duration: 0.008s, episode steps: 14, steps per second: 1861, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: 0.085 [-1.015, 1.441], mean_best_reward: --\n",
      " 54918/100000: episode: 1474, duration: 0.007s, episode steps: 12, steps per second: 1698, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.101 [-1.957, 1.190], mean_best_reward: --\n",
      " 54934/100000: episode: 1475, duration: 0.010s, episode steps: 16, steps per second: 1544, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.087 [-1.408, 0.790], mean_best_reward: --\n",
      " 54950/100000: episode: 1476, duration: 0.014s, episode steps: 16, steps per second: 1134, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.062 [-2.506, 1.614], mean_best_reward: --\n",
      " 55067/100000: episode: 1477, duration: 0.052s, episode steps: 117, steps per second: 2233, episode reward: 117.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.573 [0.000, 1.000], mean observation: 0.131 [-2.411, 3.158], mean_best_reward: --\n",
      " 55093/100000: episode: 1478, duration: 0.012s, episode steps: 26, steps per second: 2112, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.423 [0.000, 1.000], mean observation: 0.031 [-0.950, 1.540], mean_best_reward: --\n",
      " 55107/100000: episode: 1479, duration: 0.007s, episode steps: 14, steps per second: 2003, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.643 [0.000, 1.000], mean observation: -0.082 [-1.556, 1.026], mean_best_reward: --\n",
      " 55120/100000: episode: 1480, duration: 0.007s, episode steps: 13, steps per second: 1872, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.692 [0.000, 1.000], mean observation: -0.129 [-1.831, 0.947], mean_best_reward: --\n",
      " 55165/100000: episode: 1481, duration: 0.019s, episode steps: 45, steps per second: 2351, episode reward: 45.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.489 [0.000, 1.000], mean observation: -0.083 [-1.169, 0.642], mean_best_reward: --\n",
      " 55179/100000: episode: 1482, duration: 0.007s, episode steps: 14, steps per second: 1906, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.714 [0.000, 1.000], mean observation: -0.107 [-2.044, 1.157], mean_best_reward: --\n",
      " 55244/100000: episode: 1483, duration: 0.028s, episode steps: 65, steps per second: 2312, episode reward: 65.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.569 [0.000, 1.000], mean observation: 0.149 [-2.133, 1.908], mean_best_reward: --\n",
      " 55266/100000: episode: 1484, duration: 0.010s, episode steps: 22, steps per second: 2096, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.098 [-0.993, 0.581], mean_best_reward: --\n",
      " 55379/100000: episode: 1485, duration: 0.054s, episode steps: 113, steps per second: 2105, episode reward: 113.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.540 [0.000, 1.000], mean observation: 0.219 [-0.723, 1.873], mean_best_reward: --\n",
      " 55388/100000: episode: 1486, duration: 0.006s, episode steps: 9, steps per second: 1410, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 1.000 [1.000, 1.000], mean observation: -0.139 [-2.833, 1.796], mean_best_reward: --\n",
      " 55415/100000: episode: 1487, duration: 0.016s, episode steps: 27, steps per second: 1708, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.519 [0.000, 1.000], mean observation: -0.091 [-1.008, 0.579], mean_best_reward: --\n",
      " 55435/100000: episode: 1488, duration: 0.010s, episode steps: 20, steps per second: 1989, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.450 [0.000, 1.000], mean observation: -0.109 [-1.267, 0.735], mean_best_reward: --\n",
      " 55459/100000: episode: 1489, duration: 0.012s, episode steps: 24, steps per second: 2023, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.100 [-1.433, 0.625], mean_best_reward: --\n",
      " 55518/100000: episode: 1490, duration: 0.026s, episode steps: 59, steps per second: 2294, episode reward: 59.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.424 [0.000, 1.000], mean observation: -0.022 [-1.896, 2.513], mean_best_reward: --\n",
      " 55547/100000: episode: 1491, duration: 0.014s, episode steps: 29, steps per second: 2071, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.552 [0.000, 1.000], mean observation: -0.044 [-1.530, 0.801], mean_best_reward: --\n",
      " 55570/100000: episode: 1492, duration: 0.012s, episode steps: 23, steps per second: 1891, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.696 [0.000, 1.000], mean observation: -0.047 [-2.642, 1.727], mean_best_reward: --\n",
      " 55705/100000: episode: 1493, duration: 0.056s, episode steps: 135, steps per second: 2431, episode reward: 135.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.511 [0.000, 1.000], mean observation: -0.012 [-1.267, 1.005], mean_best_reward: --\n",
      " 55753/100000: episode: 1494, duration: 0.021s, episode steps: 48, steps per second: 2320, episode reward: 48.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.479 [0.000, 1.000], mean observation: -0.147 [-1.202, 0.428], mean_best_reward: --\n",
      " 55768/100000: episode: 1495, duration: 0.008s, episode steps: 15, steps per second: 1942, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.094 [-1.156, 2.006], mean_best_reward: --\n",
      " 55776/100000: episode: 1496, duration: 0.005s, episode steps: 8, steps per second: 1593, episode reward: 8.000, mean reward: 1.000 [1.000, 1.000], mean action: 1.000 [1.000, 1.000], mean observation: -0.151 [-2.547, 1.581], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 55903/100000: episode: 1497, duration: 0.051s, episode steps: 127, steps per second: 2491, episode reward: 127.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.528 [0.000, 1.000], mean observation: 0.256 [-0.986, 1.904], mean_best_reward: --\n",
      " 55948/100000: episode: 1498, duration: 0.026s, episode steps: 45, steps per second: 1715, episode reward: 45.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.533 [0.000, 1.000], mean observation: 0.084 [-0.780, 1.081], mean_best_reward: --\n",
      " 56006/100000: episode: 1499, duration: 0.033s, episode steps: 58, steps per second: 1748, episode reward: 58.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.552 [0.000, 1.000], mean observation: -0.072 [-2.357, 1.186], mean_best_reward: --\n",
      " 56037/100000: episode: 1500, duration: 0.014s, episode steps: 31, steps per second: 2251, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.516 [0.000, 1.000], mean observation: -0.060 [-1.146, 0.642], mean_best_reward: --\n",
      " 56237/100000: episode: 1501, duration: 0.086s, episode steps: 200, steps per second: 2322, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.069 [-1.137, 0.947], mean_best_reward: 165.500000\n",
      " 56303/100000: episode: 1502, duration: 0.027s, episode steps: 66, steps per second: 2429, episode reward: 66.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: 0.132 [-0.532, 1.074], mean_best_reward: --\n",
      " 56356/100000: episode: 1503, duration: 0.026s, episode steps: 53, steps per second: 2020, episode reward: 53.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.509 [0.000, 1.000], mean observation: -0.075 [-1.183, 0.549], mean_best_reward: --\n",
      " 56384/100000: episode: 1504, duration: 0.015s, episode steps: 28, steps per second: 1911, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.536 [0.000, 1.000], mean observation: -0.087 [-1.194, 0.599], mean_best_reward: --\n",
      " 56403/100000: episode: 1505, duration: 0.014s, episode steps: 19, steps per second: 1404, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.579 [0.000, 1.000], mean observation: -0.117 [-1.604, 0.764], mean_best_reward: --\n",
      " 56536/100000: episode: 1506, duration: 0.055s, episode steps: 133, steps per second: 2418, episode reward: 133.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.504 [0.000, 1.000], mean observation: -0.156 [-1.324, 1.149], mean_best_reward: --\n",
      " 56609/100000: episode: 1507, duration: 0.031s, episode steps: 73, steps per second: 2368, episode reward: 73.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.479 [0.000, 1.000], mean observation: -0.087 [-1.015, 1.303], mean_best_reward: --\n",
      " 56637/100000: episode: 1508, duration: 0.013s, episode steps: 28, steps per second: 2097, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.464 [0.000, 1.000], mean observation: 0.050 [-0.755, 1.239], mean_best_reward: --\n",
      " 56682/100000: episode: 1509, duration: 0.019s, episode steps: 45, steps per second: 2352, episode reward: 45.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.489 [0.000, 1.000], mean observation: -0.066 [-0.980, 0.570], mean_best_reward: --\n",
      " 56882/100000: episode: 1510, duration: 0.091s, episode steps: 200, steps per second: 2201, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.210 [-2.237, 1.459], mean_best_reward: --\n",
      " 56948/100000: episode: 1511, duration: 0.030s, episode steps: 66, steps per second: 2204, episode reward: 66.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.019 [-0.568, 1.180], mean_best_reward: --\n",
      " 56963/100000: episode: 1512, duration: 0.008s, episode steps: 15, steps per second: 1877, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.400 [0.000, 1.000], mean observation: 0.093 [-0.965, 1.503], mean_best_reward: --\n",
      " 57027/100000: episode: 1513, duration: 0.028s, episode steps: 64, steps per second: 2254, episode reward: 64.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.484 [0.000, 1.000], mean observation: -0.106 [-1.096, 0.751], mean_best_reward: --\n",
      " 57157/100000: episode: 1514, duration: 0.054s, episode steps: 130, steps per second: 2386, episode reward: 130.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.508 [0.000, 1.000], mean observation: 0.010 [-1.113, 1.125], mean_best_reward: --\n",
      " 57220/100000: episode: 1515, duration: 0.028s, episode steps: 63, steps per second: 2263, episode reward: 63.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: -0.029 [-0.948, 1.367], mean_best_reward: --\n",
      " 57309/100000: episode: 1516, duration: 0.038s, episode steps: 89, steps per second: 2346, episode reward: 89.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.551 [0.000, 1.000], mean observation: 0.288 [-1.404, 2.015], mean_best_reward: --\n",
      " 57442/100000: episode: 1517, duration: 0.071s, episode steps: 133, steps per second: 1869, episode reward: 133.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.504 [0.000, 1.000], mean observation: -0.271 [-1.497, 1.028], mean_best_reward: --\n",
      " 57642/100000: episode: 1518, duration: 0.081s, episode steps: 200, steps per second: 2459, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.134 [-0.920, 0.937], mean_best_reward: --\n",
      " 57723/100000: episode: 1519, duration: 0.038s, episode steps: 81, steps per second: 2148, episode reward: 81.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.556 [0.000, 1.000], mean observation: 0.261 [-1.638, 2.100], mean_best_reward: --\n",
      " 57834/100000: episode: 1520, duration: 0.046s, episode steps: 111, steps per second: 2408, episode reward: 111.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.441 [0.000, 1.000], mean observation: 0.109 [-2.495, 3.295], mean_best_reward: --\n",
      " 57883/100000: episode: 1521, duration: 0.023s, episode steps: 49, steps per second: 2106, episode reward: 49.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.143 [-1.031, 0.754], mean_best_reward: --\n",
      " 57912/100000: episode: 1522, duration: 0.017s, episode steps: 29, steps per second: 1719, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.552 [0.000, 1.000], mean observation: 0.085 [-0.642, 1.060], mean_best_reward: --\n",
      " 57981/100000: episode: 1523, duration: 0.042s, episode steps: 69, steps per second: 1654, episode reward: 69.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.507 [0.000, 1.000], mean observation: -0.045 [-1.300, 0.727], mean_best_reward: --\n",
      " 58053/100000: episode: 1524, duration: 0.032s, episode steps: 72, steps per second: 2276, episode reward: 72.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: -0.053 [-1.454, 0.706], mean_best_reward: --\n",
      " 58073/100000: episode: 1525, duration: 0.009s, episode steps: 20, steps per second: 2133, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.045 [-2.066, 1.380], mean_best_reward: --\n",
      " 58108/100000: episode: 1526, duration: 0.015s, episode steps: 35, steps per second: 2312, episode reward: 35.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: 0.094 [-0.346, 0.842], mean_best_reward: --\n",
      " 58147/100000: episode: 1527, duration: 0.018s, episode steps: 39, steps per second: 2198, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.487 [0.000, 1.000], mean observation: 0.039 [-0.796, 1.321], mean_best_reward: --\n",
      " 58347/100000: episode: 1528, duration: 0.083s, episode steps: 200, steps per second: 2420, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.093 [-1.106, 0.774], mean_best_reward: --\n",
      " 58386/100000: episode: 1529, duration: 0.028s, episode steps: 39, steps per second: 1370, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: 0.079 [-0.441, 0.785], mean_best_reward: --\n",
      " 58414/100000: episode: 1530, duration: 0.017s, episode steps: 28, steps per second: 1632, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.464 [0.000, 1.000], mean observation: -0.115 [-0.981, 0.445], mean_best_reward: --\n",
      " 58474/100000: episode: 1531, duration: 0.027s, episode steps: 60, steps per second: 2252, episode reward: 60.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.517 [0.000, 1.000], mean observation: 0.007 [-0.647, 1.163], mean_best_reward: --\n",
      " 58519/100000: episode: 1532, duration: 0.020s, episode steps: 45, steps per second: 2306, episode reward: 45.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.489 [0.000, 1.000], mean observation: -0.116 [-0.986, 0.398], mean_best_reward: --\n",
      " 58609/100000: episode: 1533, duration: 0.038s, episode steps: 90, steps per second: 2369, episode reward: 90.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: -0.143 [-1.285, 1.266], mean_best_reward: --\n",
      " 58642/100000: episode: 1534, duration: 0.014s, episode steps: 33, steps per second: 2302, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.115 [-0.441, 1.040], mean_best_reward: --\n",
      " 58734/100000: episode: 1535, duration: 0.041s, episode steps: 92, steps per second: 2234, episode reward: 92.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.576 [0.000, 1.000], mean observation: 0.225 [-2.477, 2.852], mean_best_reward: --\n",
      " 58772/100000: episode: 1536, duration: 0.017s, episode steps: 38, steps per second: 2173, episode reward: 38.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.112 [-1.641, 0.756], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 58910/100000: episode: 1537, duration: 0.073s, episode steps: 138, steps per second: 1900, episode reward: 138.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.493 [0.000, 1.000], mean observation: -0.153 [-1.247, 1.091], mean_best_reward: --\n",
      " 58962/100000: episode: 1538, duration: 0.024s, episode steps: 52, steps per second: 2162, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.519 [0.000, 1.000], mean observation: 0.108 [-0.607, 1.088], mean_best_reward: --\n",
      " 59158/100000: episode: 1539, duration: 0.082s, episode steps: 196, steps per second: 2400, episode reward: 196.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.536 [0.000, 1.000], mean observation: 0.095 [-2.801, 2.674], mean_best_reward: --\n",
      " 59237/100000: episode: 1540, duration: 0.033s, episode steps: 79, steps per second: 2386, episode reward: 79.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.481 [0.000, 1.000], mean observation: -0.053 [-0.980, 1.382], mean_best_reward: --\n",
      " 59303/100000: episode: 1541, duration: 0.030s, episode steps: 66, steps per second: 2217, episode reward: 66.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.058 [-0.619, 1.146], mean_best_reward: --\n",
      " 59316/100000: episode: 1542, duration: 0.008s, episode steps: 13, steps per second: 1720, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.769 [0.000, 1.000], mean observation: -0.137 [-2.327, 1.339], mean_best_reward: --\n",
      " 59364/100000: episode: 1543, duration: 0.020s, episode steps: 48, steps per second: 2358, episode reward: 48.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.521 [0.000, 1.000], mean observation: 0.059 [-0.567, 0.950], mean_best_reward: --\n",
      " 59404/100000: episode: 1544, duration: 0.034s, episode steps: 40, steps per second: 1192, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.074 [-0.599, 1.238], mean_best_reward: --\n",
      " 59487/100000: episode: 1545, duration: 0.036s, episode steps: 83, steps per second: 2282, episode reward: 83.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.506 [0.000, 1.000], mean observation: -0.100 [-1.540, 0.716], mean_best_reward: --\n",
      " 59541/100000: episode: 1546, duration: 0.024s, episode steps: 54, steps per second: 2272, episode reward: 54.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.537 [0.000, 1.000], mean observation: 0.130 [-0.796, 1.113], mean_best_reward: --\n",
      " 59582/100000: episode: 1547, duration: 0.019s, episode steps: 41, steps per second: 2122, episode reward: 41.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.610 [0.000, 1.000], mean observation: -0.016 [-2.691, 1.731], mean_best_reward: --\n",
      " 59629/100000: episode: 1548, duration: 0.021s, episode steps: 47, steps per second: 2283, episode reward: 47.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.511 [0.000, 1.000], mean observation: 0.041 [-0.449, 1.207], mean_best_reward: --\n",
      " 59693/100000: episode: 1549, duration: 0.027s, episode steps: 64, steps per second: 2368, episode reward: 64.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.547 [0.000, 1.000], mean observation: -0.036 [-2.248, 1.175], mean_best_reward: --\n",
      " 59830/100000: episode: 1550, duration: 0.058s, episode steps: 137, steps per second: 2370, episode reward: 137.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.511 [0.000, 1.000], mean observation: -0.066 [-1.348, 1.200], mean_best_reward: --\n",
      " 59921/100000: episode: 1551, duration: 0.049s, episode steps: 91, steps per second: 1870, episode reward: 91.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.440 [0.000, 1.000], mean observation: -0.211 [-2.661, 2.402], mean_best_reward: 151.500000\n",
      " 59938/100000: episode: 1552, duration: 0.009s, episode steps: 17, steps per second: 1900, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.706 [0.000, 1.000], mean observation: -0.083 [-2.341, 1.372], mean_best_reward: --\n",
      " 59961/100000: episode: 1553, duration: 0.012s, episode steps: 23, steps per second: 1929, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.435 [0.000, 1.000], mean observation: -0.144 [-0.776, 0.346], mean_best_reward: --\n",
      " 60119/100000: episode: 1554, duration: 0.065s, episode steps: 158, steps per second: 2448, episode reward: 158.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.551 [0.000, 1.000], mean observation: 0.154 [-2.985, 3.231], mean_best_reward: --\n",
      " 60150/100000: episode: 1555, duration: 0.014s, episode steps: 31, steps per second: 2190, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.484 [0.000, 1.000], mean observation: -0.087 [-0.867, 0.606], mean_best_reward: --\n",
      " 60179/100000: episode: 1556, duration: 0.013s, episode steps: 29, steps per second: 2194, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.448 [0.000, 1.000], mean observation: -0.106 [-1.221, 0.786], mean_best_reward: --\n",
      " 60206/100000: episode: 1557, duration: 0.013s, episode steps: 27, steps per second: 2069, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.556 [0.000, 1.000], mean observation: -0.064 [-1.477, 1.018], mean_best_reward: --\n",
      " 60362/100000: episode: 1558, duration: 0.067s, episode steps: 156, steps per second: 2339, episode reward: 156.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.519 [0.000, 1.000], mean observation: 0.071 [-1.621, 1.135], mean_best_reward: --\n",
      " 60389/100000: episode: 1559, duration: 0.015s, episode steps: 27, steps per second: 1758, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.519 [0.000, 1.000], mean observation: -0.090 [-1.358, 0.612], mean_best_reward: --\n",
      " 60540/100000: episode: 1560, duration: 0.071s, episode steps: 151, steps per second: 2128, episode reward: 151.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: 0.130 [-1.013, 1.183], mean_best_reward: --\n",
      " 60700/100000: episode: 1561, duration: 0.065s, episode steps: 160, steps per second: 2460, episode reward: 160.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.556 [0.000, 1.000], mean observation: 0.255 [-2.380, 3.565], mean_best_reward: --\n",
      " 60832/100000: episode: 1562, duration: 0.056s, episode steps: 132, steps per second: 2378, episode reward: 132.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: 0.197 [-2.318, 2.283], mean_best_reward: --\n",
      " 60877/100000: episode: 1563, duration: 0.033s, episode steps: 45, steps per second: 1380, episode reward: 45.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.489 [0.000, 1.000], mean observation: -0.032 [-1.074, 0.414], mean_best_reward: --\n",
      " 60965/100000: episode: 1564, duration: 0.038s, episode steps: 88, steps per second: 2309, episode reward: 88.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.489 [0.000, 1.000], mean observation: -0.059 [-1.119, 0.604], mean_best_reward: --\n",
      " 61082/100000: episode: 1565, duration: 0.049s, episode steps: 117, steps per second: 2407, episode reward: 117.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.530 [0.000, 1.000], mean observation: 0.195 [-1.659, 2.091], mean_best_reward: --\n",
      " 61163/100000: episode: 1566, duration: 0.036s, episode steps: 81, steps per second: 2228, episode reward: 81.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.506 [0.000, 1.000], mean observation: 0.177 [-1.153, 1.590], mean_best_reward: --\n",
      " 61182/100000: episode: 1567, duration: 0.010s, episode steps: 19, steps per second: 1881, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: -0.101 [-1.263, 0.644], mean_best_reward: --\n",
      " 61235/100000: episode: 1568, duration: 0.024s, episode steps: 53, steps per second: 2225, episode reward: 53.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.453 [0.000, 1.000], mean observation: 0.004 [-1.375, 1.937], mean_best_reward: --\n",
      " 61325/100000: episode: 1569, duration: 0.040s, episode steps: 90, steps per second: 2238, episode reward: 90.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.489 [0.000, 1.000], mean observation: -0.091 [-1.282, 0.632], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 61400/100000: episode: 1570, duration: 0.042s, episode steps: 75, steps per second: 1780, episode reward: 75.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.493 [0.000, 1.000], mean observation: -0.146 [-1.162, 0.955], mean_best_reward: --\n",
      " 61600/100000: episode: 1571, duration: 0.084s, episode steps: 200, steps per second: 2387, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.089 [-0.967, 1.365], mean_best_reward: --\n",
      " 61728/100000: episode: 1572, duration: 0.053s, episode steps: 128, steps per second: 2401, episode reward: 128.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.484 [0.000, 1.000], mean observation: -0.321 [-1.912, 1.401], mean_best_reward: --\n",
      " 61837/100000: episode: 1573, duration: 0.045s, episode steps: 109, steps per second: 2430, episode reward: 109.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.550 [0.000, 1.000], mean observation: 0.292 [-1.944, 2.108], mean_best_reward: --\n",
      " 61938/100000: episode: 1574, duration: 0.052s, episode steps: 101, steps per second: 1942, episode reward: 101.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.224 [-2.092, 1.177], mean_best_reward: --\n",
      " 62077/100000: episode: 1575, duration: 0.057s, episode steps: 139, steps per second: 2424, episode reward: 139.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.532 [0.000, 1.000], mean observation: 0.100 [-1.566, 1.875], mean_best_reward: --\n",
      " 62233/100000: episode: 1576, duration: 0.062s, episode steps: 156, steps per second: 2501, episode reward: 156.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.002 [-1.311, 0.984], mean_best_reward: --\n",
      " 62433/100000: episode: 1577, duration: 0.082s, episode steps: 200, steps per second: 2431, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.525 [0.000, 1.000], mean observation: -0.145 [-1.359, 1.990], mean_best_reward: --\n",
      " 62457/100000: episode: 1578, duration: 0.018s, episode steps: 24, steps per second: 1322, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.583 [0.000, 1.000], mean observation: -0.050 [-1.431, 0.969], mean_best_reward: --\n",
      " 62531/100000: episode: 1579, duration: 0.033s, episode steps: 74, steps per second: 2260, episode reward: 74.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.486 [0.000, 1.000], mean observation: -0.013 [-0.968, 1.127], mean_best_reward: --\n",
      " 62731/100000: episode: 1580, duration: 0.085s, episode steps: 200, steps per second: 2355, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.042 [-0.884, 0.847], mean_best_reward: --\n",
      " 62824/100000: episode: 1581, duration: 0.039s, episode steps: 93, steps per second: 2380, episode reward: 93.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: -0.163 [-1.340, 0.959], mean_best_reward: --\n",
      " 62902/100000: episode: 1582, duration: 0.036s, episode steps: 78, steps per second: 2178, episode reward: 78.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.487 [0.000, 1.000], mean observation: -0.080 [-1.039, 0.459], mean_best_reward: --\n",
      " 62947/100000: episode: 1583, duration: 0.027s, episode steps: 45, steps per second: 1653, episode reward: 45.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.533 [0.000, 1.000], mean observation: 0.109 [-0.798, 1.640], mean_best_reward: --\n",
      " 62984/100000: episode: 1584, duration: 0.019s, episode steps: 37, steps per second: 1907, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: -0.066 [-1.510, 1.062], mean_best_reward: --\n",
      " 63031/100000: episode: 1585, duration: 0.021s, episode steps: 47, steps per second: 2279, episode reward: 47.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.532 [0.000, 1.000], mean observation: -0.037 [-1.410, 0.814], mean_best_reward: --\n",
      " 63231/100000: episode: 1586, duration: 0.083s, episode steps: 200, steps per second: 2399, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: -0.162 [-1.354, 1.030], mean_best_reward: --\n",
      " 63286/100000: episode: 1587, duration: 0.023s, episode steps: 55, steps per second: 2346, episode reward: 55.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: 0.015 [-1.201, 1.635], mean_best_reward: --\n",
      " 63331/100000: episode: 1588, duration: 0.019s, episode steps: 45, steps per second: 2312, episode reward: 45.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.511 [0.000, 1.000], mean observation: 0.139 [-0.665, 1.190], mean_best_reward: --\n",
      " 63370/100000: episode: 1589, duration: 0.019s, episode steps: 39, steps per second: 2057, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.436 [0.000, 1.000], mean observation: 0.017 [-1.014, 1.830], mean_best_reward: --\n",
      " 63403/100000: episode: 1590, duration: 0.025s, episode steps: 33, steps per second: 1329, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.158 [-1.090, 0.365], mean_best_reward: --\n",
      " 63462/100000: episode: 1591, duration: 0.026s, episode steps: 59, steps per second: 2267, episode reward: 59.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.508 [0.000, 1.000], mean observation: -0.084 [-1.306, 0.845], mean_best_reward: --\n",
      " 63478/100000: episode: 1592, duration: 0.008s, episode steps: 16, steps per second: 1883, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.098 [-2.696, 1.578], mean_best_reward: --\n",
      " 63505/100000: episode: 1593, duration: 0.013s, episode steps: 27, steps per second: 2038, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.593 [0.000, 1.000], mean observation: -0.063 [-1.967, 1.021], mean_best_reward: --\n",
      " 63605/100000: episode: 1594, duration: 0.043s, episode steps: 100, steps per second: 2350, episode reward: 100.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.326 [-2.552, 0.968], mean_best_reward: --\n",
      " 63659/100000: episode: 1595, duration: 0.023s, episode steps: 54, steps per second: 2367, episode reward: 54.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.067 [-1.200, 0.573], mean_best_reward: --\n",
      " 63692/100000: episode: 1596, duration: 0.015s, episode steps: 33, steps per second: 2229, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.636 [0.000, 1.000], mean observation: -0.014 [-2.680, 1.738], mean_best_reward: --\n",
      " 63794/100000: episode: 1597, duration: 0.042s, episode steps: 102, steps per second: 2452, episode reward: 102.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.549 [0.000, 1.000], mean observation: 0.185 [-1.908, 1.890], mean_best_reward: --\n",
      " 63845/100000: episode: 1598, duration: 0.033s, episode steps: 51, steps per second: 1565, episode reward: 51.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.062 [-0.988, 0.594], mean_best_reward: --\n",
      " 63867/100000: episode: 1599, duration: 0.015s, episode steps: 22, steps per second: 1478, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: -0.077 [-1.458, 0.989], mean_best_reward: --\n",
      " 63921/100000: episode: 1600, duration: 0.025s, episode steps: 54, steps per second: 2149, episode reward: 54.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.481 [0.000, 1.000], mean observation: -0.018 [-0.982, 1.405], mean_best_reward: --\n",
      " 63996/100000: episode: 1601, duration: 0.032s, episode steps: 75, steps per second: 2353, episode reward: 75.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.640 [0.000, 1.000], mean observation: 0.305 [-3.685, 4.018], mean_best_reward: 144.500000\n",
      " 64110/100000: episode: 1602, duration: 0.050s, episode steps: 114, steps per second: 2266, episode reward: 114.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.526 [0.000, 1.000], mean observation: 0.103 [-2.199, 1.171], mean_best_reward: --\n",
      " 64227/100000: episode: 1603, duration: 0.050s, episode steps: 117, steps per second: 2340, episode reward: 117.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.521 [0.000, 1.000], mean observation: 0.086 [-0.899, 1.105], mean_best_reward: --\n",
      " 64248/100000: episode: 1604, duration: 0.011s, episode steps: 21, steps per second: 1990, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.619 [0.000, 1.000], mean observation: -0.066 [-1.857, 1.023], mean_best_reward: --\n",
      " 64266/100000: episode: 1605, duration: 0.009s, episode steps: 18, steps per second: 2048, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.059 [-1.467, 0.998], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64285/100000: episode: 1606, duration: 0.012s, episode steps: 19, steps per second: 1636, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: 0.064 [-0.792, 1.212], mean_best_reward: --\n",
      " 64319/100000: episode: 1607, duration: 0.025s, episode steps: 34, steps per second: 1362, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.039 [-1.073, 0.608], mean_best_reward: --\n",
      " 64371/100000: episode: 1608, duration: 0.029s, episode steps: 52, steps per second: 1821, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.519 [0.000, 1.000], mean observation: 0.068 [-1.685, 1.396], mean_best_reward: --\n",
      " 64415/100000: episode: 1609, duration: 0.021s, episode steps: 44, steps per second: 2101, episode reward: 44.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: 0.119 [-0.591, 0.919], mean_best_reward: --\n",
      " 64455/100000: episode: 1610, duration: 0.021s, episode steps: 40, steps per second: 1946, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: 0.053 [-0.782, 1.590], mean_best_reward: --\n",
      " 64621/100000: episode: 1611, duration: 0.068s, episode steps: 166, steps per second: 2437, episode reward: 166.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.512 [0.000, 1.000], mean observation: 0.142 [-0.598, 1.297], mean_best_reward: --\n",
      " 64638/100000: episode: 1612, duration: 0.008s, episode steps: 17, steps per second: 2048, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.073 [-1.180, 0.819], mean_best_reward: --\n",
      " 64756/100000: episode: 1613, duration: 0.063s, episode steps: 118, steps per second: 1872, episode reward: 118.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.466 [0.000, 1.000], mean observation: -0.050 [-1.852, 1.597], mean_best_reward: --\n",
      " 64796/100000: episode: 1614, duration: 0.019s, episode steps: 40, steps per second: 2140, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.074 [-0.990, 0.521], mean_best_reward: --\n",
      " 64837/100000: episode: 1615, duration: 0.019s, episode steps: 41, steps per second: 2115, episode reward: 41.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.585 [0.000, 1.000], mean observation: -0.009 [-2.197, 1.412], mean_best_reward: --\n",
      " 64910/100000: episode: 1616, duration: 0.031s, episode steps: 73, steps per second: 2377, episode reward: 73.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.397 [0.000, 1.000], mean observation: -0.365 [-3.033, 2.295], mean_best_reward: --\n",
      " 64992/100000: episode: 1617, duration: 0.037s, episode steps: 82, steps per second: 2216, episode reward: 82.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.463 [0.000, 1.000], mean observation: -0.345 [-1.689, 0.504], mean_best_reward: --\n",
      " 65103/100000: episode: 1618, duration: 0.065s, episode steps: 111, steps per second: 1710, episode reward: 111.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.568 [0.000, 1.000], mean observation: 0.134 [-2.816, 2.881], mean_best_reward: --\n",
      " 65132/100000: episode: 1619, duration: 0.014s, episode steps: 29, steps per second: 2049, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.517 [0.000, 1.000], mean observation: 0.051 [-0.824, 1.156], mean_best_reward: --\n",
      " 65180/100000: episode: 1620, duration: 0.026s, episode steps: 48, steps per second: 1872, episode reward: 48.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.479 [0.000, 1.000], mean observation: -0.066 [-1.158, 0.795], mean_best_reward: --\n",
      " 65290/100000: episode: 1621, duration: 0.057s, episode steps: 110, steps per second: 1926, episode reward: 110.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.473 [0.000, 1.000], mean observation: -0.354 [-2.254, 1.147], mean_best_reward: --\n",
      " 65409/100000: episode: 1622, duration: 0.056s, episode steps: 119, steps per second: 2108, episode reward: 119.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.454 [0.000, 1.000], mean observation: -0.217 [-2.207, 1.337], mean_best_reward: --\n",
      " 65523/100000: episode: 1623, duration: 0.052s, episode steps: 114, steps per second: 2212, episode reward: 114.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.526 [0.000, 1.000], mean observation: -0.257 [-2.212, 1.138], mean_best_reward: --\n",
      " 65558/100000: episode: 1624, duration: 0.017s, episode steps: 35, steps per second: 2115, episode reward: 35.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: 0.090 [-0.765, 1.613], mean_best_reward: --\n",
      " 65568/100000: episode: 1625, duration: 0.006s, episode steps: 10, steps per second: 1702, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.300 [0.000, 1.000], mean observation: 0.123 [-0.983, 1.613], mean_best_reward: --\n",
      " 65626/100000: episode: 1626, duration: 0.034s, episode steps: 58, steps per second: 1730, episode reward: 58.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.517 [0.000, 1.000], mean observation: 0.089 [-0.665, 0.987], mean_best_reward: --\n",
      " 65642/100000: episode: 1627, duration: 0.011s, episode steps: 16, steps per second: 1421, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.066 [-1.692, 1.198], mean_best_reward: --\n",
      " 65667/100000: episode: 1628, duration: 0.018s, episode steps: 25, steps per second: 1423, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: 0.045 [-0.931, 1.371], mean_best_reward: --\n",
      " 65706/100000: episode: 1629, duration: 0.020s, episode steps: 39, steps per second: 1993, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.487 [0.000, 1.000], mean observation: 0.025 [-0.929, 1.063], mean_best_reward: --\n",
      " 65752/100000: episode: 1630, duration: 0.022s, episode steps: 46, steps per second: 2053, episode reward: 46.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: -0.068 [-1.171, 0.781], mean_best_reward: --\n",
      " 65764/100000: episode: 1631, duration: 0.007s, episode steps: 12, steps per second: 1654, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.583 [0.000, 1.000], mean observation: -0.120 [-1.263, 0.759], mean_best_reward: --\n",
      " 65778/100000: episode: 1632, duration: 0.009s, episode steps: 14, steps per second: 1569, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.714 [0.000, 1.000], mean observation: -0.105 [-2.123, 1.145], mean_best_reward: --\n",
      " 65806/100000: episode: 1633, duration: 0.015s, episode steps: 28, steps per second: 1917, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.464 [0.000, 1.000], mean observation: -0.096 [-1.032, 0.428], mean_best_reward: --\n",
      " 65838/100000: episode: 1634, duration: 0.015s, episode steps: 32, steps per second: 2119, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.059 [-1.331, 0.604], mean_best_reward: --\n",
      " 65863/100000: episode: 1635, duration: 0.013s, episode steps: 25, steps per second: 1896, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.440 [0.000, 1.000], mean observation: 0.061 [-0.826, 1.600], mean_best_reward: --\n",
      " 65892/100000: episode: 1636, duration: 0.015s, episode steps: 29, steps per second: 1880, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.552 [0.000, 1.000], mean observation: 0.079 [-0.628, 1.005], mean_best_reward: --\n",
      " 65970/100000: episode: 1637, duration: 0.037s, episode steps: 78, steps per second: 2128, episode reward: 78.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: -0.251 [-1.339, 0.604], mean_best_reward: --\n",
      " 66107/100000: episode: 1638, duration: 0.075s, episode steps: 137, steps per second: 1830, episode reward: 137.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.482 [0.000, 1.000], mean observation: -0.098 [-1.287, 2.076], mean_best_reward: --\n",
      " 66207/100000: episode: 1639, duration: 0.047s, episode steps: 100, steps per second: 2137, episode reward: 100.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.550 [0.000, 1.000], mean observation: 0.094 [-2.086, 1.898], mean_best_reward: --\n",
      " 66274/100000: episode: 1640, duration: 0.032s, episode steps: 67, steps per second: 2072, episode reward: 67.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.448 [0.000, 1.000], mean observation: -0.209 [-1.671, 1.117], mean_best_reward: --\n",
      " 66290/100000: episode: 1641, duration: 0.009s, episode steps: 16, steps per second: 1846, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.688 [0.000, 1.000], mean observation: -0.087 [-2.102, 1.192], mean_best_reward: --\n",
      " 66338/100000: episode: 1642, duration: 0.023s, episode steps: 48, steps per second: 2090, episode reward: 48.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.542 [0.000, 1.000], mean observation: 0.202 [-0.934, 1.496], mean_best_reward: --\n",
      " 66397/100000: episode: 1643, duration: 0.028s, episode steps: 59, steps per second: 2105, episode reward: 59.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.610 [0.000, 1.000], mean observation: 0.086 [-2.831, 2.535], mean_best_reward: --\n",
      " 66426/100000: episode: 1644, duration: 0.014s, episode steps: 29, steps per second: 2027, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.586 [0.000, 1.000], mean observation: -0.030 [-2.052, 1.385], mean_best_reward: --\n",
      " 66513/100000: episode: 1645, duration: 0.040s, episode steps: 87, steps per second: 2179, episode reward: 87.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.552 [0.000, 1.000], mean observation: 0.251 [-1.456, 2.086], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66579/100000: episode: 1646, duration: 0.037s, episode steps: 66, steps per second: 1780, episode reward: 66.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.020 [-0.869, 0.737], mean_best_reward: --\n",
      " 66603/100000: episode: 1647, duration: 0.016s, episode steps: 24, steps per second: 1547, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.064 [-0.590, 1.112], mean_best_reward: --\n",
      " 66803/100000: episode: 1648, duration: 0.091s, episode steps: 200, steps per second: 2198, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.525 [0.000, 1.000], mean observation: -0.137 [-1.362, 2.009], mean_best_reward: --\n",
      " 66816/100000: episode: 1649, duration: 0.007s, episode steps: 13, steps per second: 1737, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.692 [0.000, 1.000], mean observation: -0.128 [-1.910, 0.943], mean_best_reward: --\n",
      " 66908/100000: episode: 1650, duration: 0.039s, episode steps: 92, steps per second: 2375, episode reward: 92.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.457 [0.000, 1.000], mean observation: -0.069 [-1.770, 2.010], mean_best_reward: --\n",
      " 66920/100000: episode: 1651, duration: 0.007s, episode steps: 12, steps per second: 1670, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.583 [0.000, 1.000], mean observation: -0.120 [-1.614, 0.995], mean_best_reward: 153.500000\n",
      " 66945/100000: episode: 1652, duration: 0.012s, episode steps: 25, steps per second: 2083, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.018 [-1.871, 1.216], mean_best_reward: --\n",
      " 67061/100000: episode: 1653, duration: 0.059s, episode steps: 116, steps per second: 1963, episode reward: 116.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.457 [0.000, 1.000], mean observation: -0.449 [-2.405, 0.876], mean_best_reward: --\n",
      " 67104/100000: episode: 1654, duration: 0.020s, episode steps: 43, steps per second: 2203, episode reward: 43.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.512 [0.000, 1.000], mean observation: -0.062 [-1.375, 0.742], mean_best_reward: --\n",
      " 67219/100000: episode: 1655, duration: 0.050s, episode steps: 115, steps per second: 2280, episode reward: 115.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: -0.277 [-1.722, 1.066], mean_best_reward: --\n",
      " 67246/100000: episode: 1656, duration: 0.013s, episode steps: 27, steps per second: 2025, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.556 [0.000, 1.000], mean observation: -0.049 [-1.484, 0.769], mean_best_reward: --\n",
      " 67315/100000: episode: 1657, duration: 0.032s, episode steps: 69, steps per second: 2182, episode reward: 69.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.507 [0.000, 1.000], mean observation: -0.052 [-1.586, 0.957], mean_best_reward: --\n",
      " 67409/100000: episode: 1658, duration: 0.045s, episode steps: 94, steps per second: 2096, episode reward: 94.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.436 [0.000, 1.000], mean observation: -0.277 [-2.163, 0.827], mean_best_reward: --\n",
      " 67425/100000: episode: 1659, duration: 0.010s, episode steps: 16, steps per second: 1535, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.625 [0.000, 1.000], mean observation: -0.113 [-1.608, 0.758], mean_best_reward: --\n",
      " 67548/100000: episode: 1660, duration: 0.066s, episode steps: 123, steps per second: 1874, episode reward: 123.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.512 [0.000, 1.000], mean observation: 0.128 [-0.849, 1.133], mean_best_reward: --\n",
      " 67588/100000: episode: 1661, duration: 0.018s, episode steps: 40, steps per second: 2174, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.157 [-1.289, 0.550], mean_best_reward: --\n",
      " 67719/100000: episode: 1662, duration: 0.056s, episode steps: 131, steps per second: 2326, episode reward: 131.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.458 [0.000, 1.000], mean observation: -0.481 [-2.437, 0.794], mean_best_reward: --\n",
      " 67797/100000: episode: 1663, duration: 0.032s, episode steps: 78, steps per second: 2410, episode reward: 78.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.513 [0.000, 1.000], mean observation: 0.006 [-1.562, 1.008], mean_best_reward: --\n",
      " 67816/100000: episode: 1664, duration: 0.009s, episode steps: 19, steps per second: 2103, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.579 [0.000, 1.000], mean observation: -0.107 [-1.576, 0.626], mean_best_reward: --\n",
      " 67851/100000: episode: 1665, duration: 0.017s, episode steps: 35, steps per second: 2090, episode reward: 35.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.486 [0.000, 1.000], mean observation: -0.051 [-1.222, 0.742], mean_best_reward: --\n",
      " 67878/100000: episode: 1666, duration: 0.013s, episode steps: 27, steps per second: 2037, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.407 [0.000, 1.000], mean observation: 0.053 [-1.196, 1.989], mean_best_reward: --\n",
      " 68004/100000: episode: 1667, duration: 0.125s, episode steps: 126, steps per second: 1009, episode reward: 126.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.556 [0.000, 1.000], mean observation: 0.161 [-2.151, 2.661], mean_best_reward: --\n",
      " 68039/100000: episode: 1668, duration: 0.032s, episode steps: 35, steps per second: 1104, episode reward: 35.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.486 [0.000, 1.000], mean observation: -0.101 [-1.131, 0.576], mean_best_reward: --\n",
      " 68133/100000: episode: 1669, duration: 0.096s, episode steps: 94, steps per second: 978, episode reward: 94.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.489 [0.000, 1.000], mean observation: -0.045 [-1.144, 0.820], mean_best_reward: --\n",
      " 68247/100000: episode: 1670, duration: 0.105s, episode steps: 114, steps per second: 1082, episode reward: 114.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.518 [0.000, 1.000], mean observation: 0.077 [-0.611, 1.222], mean_best_reward: --\n",
      " 68295/100000: episode: 1671, duration: 0.032s, episode steps: 48, steps per second: 1478, episode reward: 48.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.521 [0.000, 1.000], mean observation: -0.123 [-2.014, 0.623], mean_best_reward: --\n",
      " 68362/100000: episode: 1672, duration: 0.035s, episode steps: 67, steps per second: 1926, episode reward: 67.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.507 [0.000, 1.000], mean observation: 0.069 [-0.938, 1.153], mean_best_reward: --\n",
      " 68460/100000: episode: 1673, duration: 0.052s, episode steps: 98, steps per second: 1890, episode reward: 98.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.105 [-0.985, 1.088], mean_best_reward: --\n",
      " 68585/100000: episode: 1674, duration: 0.051s, episode steps: 125, steps per second: 2436, episode reward: 125.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: -0.049 [-1.171, 0.936], mean_best_reward: --\n",
      " 68741/100000: episode: 1675, duration: 0.075s, episode steps: 156, steps per second: 2092, episode reward: 156.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.125 [-1.330, 1.470], mean_best_reward: --\n",
      " 68757/100000: episode: 1676, duration: 0.008s, episode steps: 16, steps per second: 1957, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.088 [-1.172, 0.804], mean_best_reward: --\n",
      " 68814/100000: episode: 1677, duration: 0.025s, episode steps: 57, steps per second: 2307, episode reward: 57.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.456 [0.000, 1.000], mean observation: -0.137 [-1.070, 0.526], mean_best_reward: --\n",
      " 68903/100000: episode: 1678, duration: 0.041s, episode steps: 89, steps per second: 2193, episode reward: 89.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.483 [0.000, 1.000], mean observation: -0.092 [-1.393, 0.813], mean_best_reward: --\n",
      " 68930/100000: episode: 1679, duration: 0.014s, episode steps: 27, steps per second: 1864, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.519 [0.000, 1.000], mean observation: -0.102 [-1.162, 0.438], mean_best_reward: --\n",
      " 69040/100000: episode: 1680, duration: 0.052s, episode steps: 110, steps per second: 2106, episode reward: 110.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.509 [0.000, 1.000], mean observation: 0.056 [-1.209, 1.015], mean_best_reward: --\n",
      " 69084/100000: episode: 1681, duration: 0.021s, episode steps: 44, steps per second: 2140, episode reward: 44.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.078 [-1.248, 0.725], mean_best_reward: --\n",
      " 69128/100000: episode: 1682, duration: 0.022s, episode steps: 44, steps per second: 2028, episode reward: 44.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.523 [0.000, 1.000], mean observation: 0.112 [-0.831, 1.032], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 69164/100000: episode: 1683, duration: 0.020s, episode steps: 36, steps per second: 1773, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.528 [0.000, 1.000], mean observation: -0.074 [-1.546, 0.660], mean_best_reward: --\n",
      " 69249/100000: episode: 1684, duration: 0.047s, episode steps: 85, steps per second: 1804, episode reward: 85.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.250 [-1.604, 0.814], mean_best_reward: --\n",
      " 69265/100000: episode: 1685, duration: 0.009s, episode steps: 16, steps per second: 1800, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.625 [0.000, 1.000], mean observation: -0.075 [-1.700, 1.166], mean_best_reward: --\n",
      " 69288/100000: episode: 1686, duration: 0.011s, episode steps: 23, steps per second: 2011, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: -0.082 [-1.295, 0.633], mean_best_reward: --\n",
      " 69330/100000: episode: 1687, duration: 0.023s, episode steps: 42, steps per second: 1860, episode reward: 42.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.524 [0.000, 1.000], mean observation: 0.136 [-0.902, 1.360], mean_best_reward: --\n",
      " 69386/100000: episode: 1688, duration: 0.028s, episode steps: 56, steps per second: 2029, episode reward: 56.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.536 [0.000, 1.000], mean observation: 0.104 [-0.584, 0.913], mean_best_reward: --\n",
      " 69466/100000: episode: 1689, duration: 0.038s, episode steps: 80, steps per second: 2119, episode reward: 80.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.525 [0.000, 1.000], mean observation: 0.040 [-1.901, 0.950], mean_best_reward: --\n",
      " 69526/100000: episode: 1690, duration: 0.026s, episode steps: 60, steps per second: 2287, episode reward: 60.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.617 [0.000, 1.000], mean observation: 0.168 [-2.917, 2.691], mean_best_reward: --\n",
      " 69604/100000: episode: 1691, duration: 0.039s, episode steps: 78, steps per second: 2008, episode reward: 78.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.487 [0.000, 1.000], mean observation: 0.021 [-1.132, 0.995], mean_best_reward: --\n",
      " 69686/100000: episode: 1692, duration: 0.043s, episode steps: 82, steps per second: 1895, episode reward: 82.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.107 [-1.447, 0.598], mean_best_reward: --\n",
      " 69790/100000: episode: 1693, duration: 0.044s, episode steps: 104, steps per second: 2347, episode reward: 104.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.170 [-0.862, 1.085], mean_best_reward: --\n",
      " 69887/100000: episode: 1694, duration: 0.040s, episode steps: 97, steps per second: 2410, episode reward: 97.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.015 [-1.152, 0.919], mean_best_reward: --\n",
      " 70026/100000: episode: 1695, duration: 0.060s, episode steps: 139, steps per second: 2327, episode reward: 139.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.453 [0.000, 1.000], mean observation: -0.425 [-2.810, 0.785], mean_best_reward: --\n",
      " 70180/100000: episode: 1696, duration: 0.182s, episode steps: 154, steps per second: 848, episode reward: 154.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.494 [0.000, 1.000], mean observation: 0.208 [-0.881, 1.275], mean_best_reward: --\n",
      " 70240/100000: episode: 1697, duration: 0.083s, episode steps: 60, steps per second: 724, episode reward: 60.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.178 [-1.305, 0.567], mean_best_reward: --\n",
      " 70272/100000: episode: 1698, duration: 0.032s, episode steps: 32, steps per second: 999, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.149 [-1.234, 0.369], mean_best_reward: --\n",
      " 70353/100000: episode: 1699, duration: 0.064s, episode steps: 81, steps per second: 1271, episode reward: 81.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.531 [0.000, 1.000], mean observation: 0.062 [-0.580, 0.976], mean_best_reward: --\n",
      " 70465/100000: episode: 1700, duration: 0.097s, episode steps: 112, steps per second: 1154, episode reward: 112.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.527 [0.000, 1.000], mean observation: 0.162 [-1.386, 1.344], mean_best_reward: --\n",
      " 70520/100000: episode: 1701, duration: 0.057s, episode steps: 55, steps per second: 962, episode reward: 55.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: -0.129 [-1.429, 0.967], mean_best_reward: 189.000000\n",
      " 70594/100000: episode: 1702, duration: 0.035s, episode steps: 74, steps per second: 2096, episode reward: 74.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.459 [0.000, 1.000], mean observation: -0.101 [-1.502, 0.747], mean_best_reward: --\n",
      " 70678/100000: episode: 1703, duration: 0.034s, episode steps: 84, steps per second: 2445, episode reward: 84.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.452 [0.000, 1.000], mean observation: -0.004 [-1.866, 2.069], mean_best_reward: --\n",
      " 70767/100000: episode: 1704, duration: 0.036s, episode steps: 89, steps per second: 2441, episode reward: 89.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.494 [0.000, 1.000], mean observation: -0.046 [-1.112, 1.340], mean_best_reward: --\n",
      " 70876/100000: episode: 1705, duration: 0.047s, episode steps: 109, steps per second: 2303, episode reward: 109.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.486 [0.000, 1.000], mean observation: -0.138 [-1.250, 0.904], mean_best_reward: --\n",
      " 70901/100000: episode: 1706, duration: 0.018s, episode steps: 25, steps per second: 1398, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.078 [-2.045, 1.035], mean_best_reward: --\n",
      " 70947/100000: episode: 1707, duration: 0.020s, episode steps: 46, steps per second: 2276, episode reward: 46.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.435 [0.000, 1.000], mean observation: -0.134 [-1.046, 0.351], mean_best_reward: --\n",
      " 70965/100000: episode: 1708, duration: 0.009s, episode steps: 18, steps per second: 1989, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.071 [-1.275, 0.809], mean_best_reward: --\n",
      " 71051/100000: episode: 1709, duration: 0.036s, episode steps: 86, steps per second: 2373, episode reward: 86.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.477 [0.000, 1.000], mean observation: -0.276 [-1.536, 0.486], mean_best_reward: --\n",
      " 71128/100000: episode: 1710, duration: 0.035s, episode steps: 77, steps per second: 2215, episode reward: 77.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.468 [0.000, 1.000], mean observation: -0.154 [-1.125, 0.698], mean_best_reward: --\n",
      " 71173/100000: episode: 1711, duration: 0.021s, episode steps: 45, steps per second: 2132, episode reward: 45.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.489 [0.000, 1.000], mean observation: -0.078 [-0.847, 0.581], mean_best_reward: --\n",
      " 71212/100000: episode: 1712, duration: 0.018s, episode steps: 39, steps per second: 2128, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.487 [0.000, 1.000], mean observation: -0.043 [-1.039, 0.606], mean_best_reward: --\n",
      " 71285/100000: episode: 1713, duration: 0.031s, episode steps: 73, steps per second: 2327, episode reward: 73.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.507 [0.000, 1.000], mean observation: 0.073 [-0.446, 0.903], mean_best_reward: --\n",
      " 71388/100000: episode: 1714, duration: 0.054s, episode steps: 103, steps per second: 1891, episode reward: 103.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.456 [0.000, 1.000], mean observation: -0.325 [-1.906, 1.431], mean_best_reward: --\n",
      " 71420/100000: episode: 1715, duration: 0.016s, episode steps: 32, steps per second: 1994, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: -0.066 [-0.973, 0.458], mean_best_reward: --\n",
      " 71528/100000: episode: 1716, duration: 0.044s, episode steps: 108, steps per second: 2459, episode reward: 108.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.509 [0.000, 1.000], mean observation: 0.087 [-1.041, 0.899], mean_best_reward: --\n",
      " 71559/100000: episode: 1717, duration: 0.016s, episode steps: 31, steps per second: 1970, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.484 [0.000, 1.000], mean observation: -0.140 [-1.105, 0.604], mean_best_reward: --\n",
      " 71571/100000: episode: 1718, duration: 0.007s, episode steps: 12, steps per second: 1713, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.121 [-2.002, 1.148], mean_best_reward: --\n",
      " 71660/100000: episode: 1719, duration: 0.037s, episode steps: 89, steps per second: 2389, episode reward: 89.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.528 [0.000, 1.000], mean observation: 0.214 [-0.685, 1.424], mean_best_reward: --\n",
      " 71679/100000: episode: 1720, duration: 0.010s, episode steps: 19, steps per second: 1860, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: -0.085 [-1.085, 0.596], mean_best_reward: --\n",
      " 71730/100000: episode: 1721, duration: 0.026s, episode steps: 51, steps per second: 1967, episode reward: 51.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.451 [0.000, 1.000], mean observation: -0.169 [-0.931, 0.337], mean_best_reward: --\n",
      " 71815/100000: episode: 1722, duration: 0.039s, episode steps: 85, steps per second: 2196, episode reward: 85.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.518 [0.000, 1.000], mean observation: 0.024 [-0.782, 0.880], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 71929/100000: episode: 1723, duration: 0.065s, episode steps: 114, steps per second: 1765, episode reward: 114.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.439 [0.000, 1.000], mean observation: -0.436 [-2.514, 0.646], mean_best_reward: --\n",
      " 72073/100000: episode: 1724, duration: 0.061s, episode steps: 144, steps per second: 2361, episode reward: 144.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.493 [0.000, 1.000], mean observation: -0.254 [-1.322, 0.950], mean_best_reward: --\n",
      " 72094/100000: episode: 1725, duration: 0.010s, episode steps: 21, steps per second: 2086, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.619 [0.000, 1.000], mean observation: -0.056 [-1.904, 1.186], mean_best_reward: --\n",
      " 72137/100000: episode: 1726, duration: 0.022s, episode steps: 43, steps per second: 1928, episode reward: 43.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.442 [0.000, 1.000], mean observation: -0.022 [-1.137, 1.480], mean_best_reward: --\n",
      " 72279/100000: episode: 1727, duration: 0.062s, episode steps: 142, steps per second: 2300, episode reward: 142.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.507 [0.000, 1.000], mean observation: -0.257 [-1.511, 0.787], mean_best_reward: --\n",
      " 72342/100000: episode: 1728, duration: 0.029s, episode steps: 63, steps per second: 2158, episode reward: 63.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.444 [0.000, 1.000], mean observation: -0.244 [-1.443, 0.427], mean_best_reward: --\n",
      " 72358/100000: episode: 1729, duration: 0.008s, episode steps: 16, steps per second: 1949, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.438 [0.000, 1.000], mean observation: 0.080 [-0.813, 1.405], mean_best_reward: --\n",
      " 72520/100000: episode: 1730, duration: 0.081s, episode steps: 162, steps per second: 1996, episode reward: 162.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.101 [-1.893, 1.196], mean_best_reward: --\n",
      " 72547/100000: episode: 1731, duration: 0.014s, episode steps: 27, steps per second: 1987, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.444 [0.000, 1.000], mean observation: -0.088 [-1.075, 0.595], mean_best_reward: --\n",
      " 72663/100000: episode: 1732, duration: 0.050s, episode steps: 116, steps per second: 2334, episode reward: 116.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.266 [-2.079, 1.309], mean_best_reward: --\n",
      " 72731/100000: episode: 1733, duration: 0.029s, episode steps: 68, steps per second: 2324, episode reward: 68.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.456 [0.000, 1.000], mean observation: -0.106 [-1.262, 0.609], mean_best_reward: --\n",
      " 72756/100000: episode: 1734, duration: 0.012s, episode steps: 25, steps per second: 2153, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.047 [-1.259, 0.835], mean_best_reward: --\n",
      " 72814/100000: episode: 1735, duration: 0.026s, episode steps: 58, steps per second: 2198, episode reward: 58.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.534 [0.000, 1.000], mean observation: 0.045 [-1.577, 0.973], mean_best_reward: --\n",
      " 72882/100000: episode: 1736, duration: 0.031s, episode steps: 68, steps per second: 2176, episode reward: 68.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.029 [-0.915, 0.427], mean_best_reward: --\n",
      " 72939/100000: episode: 1737, duration: 0.027s, episode steps: 57, steps per second: 2144, episode reward: 57.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.456 [0.000, 1.000], mean observation: -0.172 [-1.319, 0.867], mean_best_reward: --\n",
      " 73000/100000: episode: 1738, duration: 0.037s, episode steps: 61, steps per second: 1656, episode reward: 61.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.508 [0.000, 1.000], mean observation: 0.122 [-0.835, 1.470], mean_best_reward: --\n",
      " 73093/100000: episode: 1739, duration: 0.041s, episode steps: 93, steps per second: 2242, episode reward: 93.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.570 [0.000, 1.000], mean observation: 0.257 [-2.441, 2.422], mean_best_reward: --\n",
      " 73151/100000: episode: 1740, duration: 0.024s, episode steps: 58, steps per second: 2393, episode reward: 58.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.483 [0.000, 1.000], mean observation: -0.121 [-1.342, 0.617], mean_best_reward: --\n",
      " 73169/100000: episode: 1741, duration: 0.009s, episode steps: 18, steps per second: 2010, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.088 [-0.767, 1.417], mean_best_reward: --\n",
      " 73189/100000: episode: 1742, duration: 0.009s, episode steps: 20, steps per second: 2150, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.124 [-1.356, 0.772], mean_best_reward: --\n",
      " 73237/100000: episode: 1743, duration: 0.021s, episode steps: 48, steps per second: 2332, episode reward: 48.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.154 [-1.539, 0.408], mean_best_reward: --\n",
      " 73327/100000: episode: 1744, duration: 0.038s, episode steps: 90, steps per second: 2364, episode reward: 90.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.522 [0.000, 1.000], mean observation: 0.142 [-1.083, 1.317], mean_best_reward: --\n",
      " 73360/100000: episode: 1745, duration: 0.016s, episode steps: 33, steps per second: 2104, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: -0.033 [-1.127, 0.748], mean_best_reward: --\n",
      " 73385/100000: episode: 1746, duration: 0.011s, episode steps: 25, steps per second: 2205, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: 0.072 [-0.942, 1.550], mean_best_reward: --\n",
      " 73415/100000: episode: 1747, duration: 0.014s, episode steps: 30, steps per second: 2219, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.433 [0.000, 1.000], mean observation: -0.150 [-1.302, 0.772], mean_best_reward: --\n",
      " 73533/100000: episode: 1748, duration: 0.063s, episode steps: 118, steps per second: 1865, episode reward: 118.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.585 [0.000, 1.000], mean observation: 0.445 [-1.898, 3.709], mean_best_reward: --\n",
      " 73561/100000: episode: 1749, duration: 0.015s, episode steps: 28, steps per second: 1888, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.607 [0.000, 1.000], mean observation: -0.049 [-2.186, 1.232], mean_best_reward: --\n",
      " 73588/100000: episode: 1750, duration: 0.015s, episode steps: 27, steps per second: 1823, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.519 [0.000, 1.000], mean observation: -0.106 [-1.280, 0.585], mean_best_reward: --\n",
      " 73597/100000: episode: 1751, duration: 0.007s, episode steps: 9, steps per second: 1228, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.778 [0.000, 1.000], mean observation: -0.147 [-1.981, 1.194], mean_best_reward: 164.500000\n",
      " 73779/100000: episode: 1752, duration: 0.082s, episode steps: 182, steps per second: 2226, episode reward: 182.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.489 [0.000, 1.000], mean observation: -0.271 [-1.857, 1.418], mean_best_reward: --\n",
      " 73792/100000: episode: 1753, duration: 0.008s, episode steps: 13, steps per second: 1668, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: -0.132 [-1.405, 0.741], mean_best_reward: --\n",
      " 73814/100000: episode: 1754, duration: 0.012s, episode steps: 22, steps per second: 1851, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: -0.105 [-1.013, 0.609], mean_best_reward: --\n",
      " 73856/100000: episode: 1755, duration: 0.019s, episode steps: 42, steps per second: 2173, episode reward: 42.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.524 [0.000, 1.000], mean observation: -0.026 [-1.548, 0.820], mean_best_reward: --\n",
      " 73901/100000: episode: 1756, duration: 0.021s, episode steps: 45, steps per second: 2107, episode reward: 45.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.511 [0.000, 1.000], mean observation: 0.141 [-0.473, 1.142], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 74044/100000: episode: 1757, duration: 0.079s, episode steps: 143, steps per second: 1799, episode reward: 143.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.357 [-2.413, 0.929], mean_best_reward: --\n",
      " 74064/100000: episode: 1758, duration: 0.011s, episode steps: 20, steps per second: 1835, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.080 [-0.817, 1.446], mean_best_reward: --\n",
      " 74194/100000: episode: 1759, duration: 0.061s, episode steps: 130, steps per second: 2133, episode reward: 130.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.454 [0.000, 1.000], mean observation: -0.289 [-2.587, 1.870], mean_best_reward: --\n",
      " 74231/100000: episode: 1760, duration: 0.019s, episode steps: 37, steps per second: 1921, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.459 [0.000, 1.000], mean observation: -0.124 [-1.155, 0.468], mean_best_reward: --\n",
      " 74344/100000: episode: 1761, duration: 0.048s, episode steps: 113, steps per second: 2344, episode reward: 113.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.558 [0.000, 1.000], mean observation: 0.302 [-1.975, 2.664], mean_best_reward: --\n",
      " 74369/100000: episode: 1762, duration: 0.012s, episode steps: 25, steps per second: 2097, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: -0.104 [-1.183, 0.384], mean_best_reward: --\n",
      " 74423/100000: episode: 1763, duration: 0.024s, episode steps: 54, steps per second: 2247, episode reward: 54.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.556 [0.000, 1.000], mean observation: 0.213 [-0.469, 1.257], mean_best_reward: --\n",
      " 74544/100000: episode: 1764, duration: 0.057s, episode steps: 121, steps per second: 2112, episode reward: 121.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.479 [0.000, 1.000], mean observation: -0.163 [-1.721, 1.315], mean_best_reward: --\n",
      " 74572/100000: episode: 1765, duration: 0.017s, episode steps: 28, steps per second: 1644, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.536 [0.000, 1.000], mean observation: 0.102 [-0.434, 1.009], mean_best_reward: --\n",
      " 74583/100000: episode: 1766, duration: 0.007s, episode steps: 11, steps per second: 1606, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.727 [0.000, 1.000], mean observation: -0.109 [-2.148, 1.386], mean_best_reward: --\n",
      " 74619/100000: episode: 1767, duration: 0.018s, episode steps: 36, steps per second: 2011, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.472 [0.000, 1.000], mean observation: -0.116 [-0.944, 0.390], mean_best_reward: --\n",
      " 74680/100000: episode: 1768, duration: 0.026s, episode steps: 61, steps per second: 2356, episode reward: 61.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.508 [0.000, 1.000], mean observation: -0.007 [-1.127, 1.357], mean_best_reward: --\n",
      " 74781/100000: episode: 1769, duration: 0.044s, episode steps: 101, steps per second: 2277, episode reward: 101.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.465 [0.000, 1.000], mean observation: -0.265 [-1.646, 1.272], mean_best_reward: --\n",
      " 74962/100000: episode: 1770, duration: 0.075s, episode steps: 181, steps per second: 2406, episode reward: 181.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.492 [0.000, 1.000], mean observation: -0.191 [-1.193, 1.356], mean_best_reward: --\n",
      " 75044/100000: episode: 1771, duration: 0.049s, episode steps: 82, steps per second: 1661, episode reward: 82.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.463 [0.000, 1.000], mean observation: -0.214 [-1.730, 1.175], mean_best_reward: --\n",
      " 75102/100000: episode: 1772, duration: 0.027s, episode steps: 58, steps per second: 2117, episode reward: 58.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.483 [0.000, 1.000], mean observation: -0.047 [-0.924, 0.612], mean_best_reward: --\n",
      " 75209/100000: episode: 1773, duration: 0.046s, episode steps: 107, steps per second: 2340, episode reward: 107.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.477 [0.000, 1.000], mean observation: -0.226 [-1.543, 1.136], mean_best_reward: --\n",
      " 75275/100000: episode: 1774, duration: 0.029s, episode steps: 66, steps per second: 2248, episode reward: 66.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.005 [-0.879, 0.611], mean_best_reward: --\n",
      " 75308/100000: episode: 1775, duration: 0.015s, episode steps: 33, steps per second: 2192, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: -0.044 [-1.494, 0.654], mean_best_reward: --\n",
      " 75347/100000: episode: 1776, duration: 0.018s, episode steps: 39, steps per second: 2173, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.113 [-0.961, 0.375], mean_best_reward: --\n",
      " 75448/100000: episode: 1777, duration: 0.044s, episode steps: 101, steps per second: 2304, episode reward: 101.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.436 [0.000, 1.000], mean observation: -0.324 [-2.460, 1.721], mean_best_reward: --\n",
      " 75491/100000: episode: 1778, duration: 0.019s, episode steps: 43, steps per second: 2277, episode reward: 43.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.512 [0.000, 1.000], mean observation: 0.006 [-1.689, 1.338], mean_best_reward: --\n",
      " 75588/100000: episode: 1779, duration: 0.056s, episode steps: 97, steps per second: 1735, episode reward: 97.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.526 [0.000, 1.000], mean observation: 0.091 [-0.543, 1.118], mean_best_reward: --\n",
      " 75667/100000: episode: 1780, duration: 0.035s, episode steps: 79, steps per second: 2258, episode reward: 79.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.532 [0.000, 1.000], mean observation: 0.212 [-0.512, 1.144], mean_best_reward: --\n",
      " 75779/100000: episode: 1781, duration: 0.046s, episode steps: 112, steps per second: 2434, episode reward: 112.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: -0.441 [-2.406, 1.092], mean_best_reward: --\n",
      " 75836/100000: episode: 1782, duration: 0.025s, episode steps: 57, steps per second: 2325, episode reward: 57.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.544 [0.000, 1.000], mean observation: -0.012 [-1.780, 0.954], mean_best_reward: --\n",
      " 75881/100000: episode: 1783, duration: 0.021s, episode steps: 45, steps per second: 2171, episode reward: 45.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.511 [0.000, 1.000], mean observation: 0.037 [-1.416, 1.024], mean_best_reward: --\n",
      " 75922/100000: episode: 1784, duration: 0.018s, episode steps: 41, steps per second: 2271, episode reward: 41.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.439 [0.000, 1.000], mean observation: -0.139 [-0.914, 0.583], mean_best_reward: --\n",
      " 75955/100000: episode: 1785, duration: 0.019s, episode steps: 33, steps per second: 1760, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: -0.053 [-1.347, 0.623], mean_best_reward: --\n",
      " 75990/100000: episode: 1786, duration: 0.018s, episode steps: 35, steps per second: 1958, episode reward: 35.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.543 [0.000, 1.000], mean observation: 0.124 [-0.542, 0.944], mean_best_reward: --\n",
      " 76017/100000: episode: 1787, duration: 0.014s, episode steps: 27, steps per second: 1983, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.481 [0.000, 1.000], mean observation: -0.104 [-1.070, 0.415], mean_best_reward: --\n",
      " 76066/100000: episode: 1788, duration: 0.038s, episode steps: 49, steps per second: 1296, episode reward: 49.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: -0.160 [-1.115, 0.388], mean_best_reward: --\n",
      " 76142/100000: episode: 1789, duration: 0.034s, episode steps: 76, steps per second: 2267, episode reward: 76.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.461 [0.000, 1.000], mean observation: -0.241 [-1.785, 0.541], mean_best_reward: --\n",
      " 76174/100000: episode: 1790, duration: 0.015s, episode steps: 32, steps per second: 2097, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.531 [0.000, 1.000], mean observation: -0.044 [-1.189, 0.647], mean_best_reward: --\n",
      " 76215/100000: episode: 1791, duration: 0.018s, episode steps: 41, steps per second: 2217, episode reward: 41.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.512 [0.000, 1.000], mean observation: -0.083 [-1.325, 0.826], mean_best_reward: --\n",
      " 76362/100000: episode: 1792, duration: 0.063s, episode steps: 147, steps per second: 2322, episode reward: 147.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.497 [0.000, 1.000], mean observation: -0.220 [-1.453, 0.829], mean_best_reward: --\n",
      " 76459/100000: episode: 1793, duration: 0.047s, episode steps: 97, steps per second: 2065, episode reward: 97.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.443 [0.000, 1.000], mean observation: -0.344 [-2.029, 0.749], mean_best_reward: --\n",
      " 76479/100000: episode: 1794, duration: 0.010s, episode steps: 20, steps per second: 1921, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.053 [-1.253, 0.797], mean_best_reward: --\n",
      " 76493/100000: episode: 1795, duration: 0.008s, episode steps: 14, steps per second: 1678, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: 0.105 [-0.765, 1.426], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 76571/100000: episode: 1796, duration: 0.049s, episode steps: 78, steps per second: 1596, episode reward: 78.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: 0.067 [-1.443, 1.558], mean_best_reward: --\n",
      " 76648/100000: episode: 1797, duration: 0.034s, episode steps: 77, steps per second: 2271, episode reward: 77.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: -0.193 [-1.424, 0.452], mean_best_reward: --\n",
      " 76684/100000: episode: 1798, duration: 0.016s, episode steps: 36, steps per second: 2196, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.058 [-1.113, 0.786], mean_best_reward: --\n",
      " 76723/100000: episode: 1799, duration: 0.017s, episode steps: 39, steps per second: 2253, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.513 [0.000, 1.000], mean observation: -0.051 [-1.132, 0.592], mean_best_reward: --\n",
      " 76827/100000: episode: 1800, duration: 0.042s, episode steps: 104, steps per second: 2473, episode reward: 104.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.328 [-2.089, 1.337], mean_best_reward: --\n",
      " 76888/100000: episode: 1801, duration: 0.027s, episode steps: 61, steps per second: 2284, episode reward: 61.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.091 [-1.510, 1.614], mean_best_reward: 141.000000\n",
      " 76931/100000: episode: 1802, duration: 0.020s, episode steps: 43, steps per second: 2201, episode reward: 43.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.512 [0.000, 1.000], mean observation: -0.052 [-1.253, 0.646], mean_best_reward: --\n",
      " 76949/100000: episode: 1803, duration: 0.009s, episode steps: 18, steps per second: 2086, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.611 [0.000, 1.000], mean observation: -0.066 [-1.446, 0.986], mean_best_reward: --\n",
      " 77076/100000: episode: 1804, duration: 0.070s, episode steps: 127, steps per second: 1803, episode reward: 127.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: -0.248 [-1.460, 1.049], mean_best_reward: --\n",
      " 77206/100000: episode: 1805, duration: 0.058s, episode steps: 130, steps per second: 2254, episode reward: 130.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.007 [-0.817, 1.196], mean_best_reward: --\n",
      " 77337/100000: episode: 1806, duration: 0.055s, episode steps: 131, steps per second: 2383, episode reward: 131.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.565 [0.000, 1.000], mean observation: 0.079 [-2.737, 3.171], mean_best_reward: --\n",
      " 77426/100000: episode: 1807, duration: 0.038s, episode steps: 89, steps per second: 2370, episode reward: 89.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.551 [0.000, 1.000], mean observation: 0.177 [-1.296, 1.922], mean_best_reward: --\n",
      " 77469/100000: episode: 1808, duration: 0.019s, episode steps: 43, steps per second: 2259, episode reward: 43.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.442 [0.000, 1.000], mean observation: -0.161 [-0.909, 0.641], mean_best_reward: --\n",
      " 77669/100000: episode: 1809, duration: 0.102s, episode steps: 200, steps per second: 1964, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.079 [-0.903, 1.089], mean_best_reward: --\n",
      " 77719/100000: episode: 1810, duration: 0.023s, episode steps: 50, steps per second: 2164, episode reward: 50.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: -0.105 [-1.842, 0.628], mean_best_reward: --\n",
      " 77733/100000: episode: 1811, duration: 0.014s, episode steps: 14, steps per second: 990, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.121 [-0.567, 0.965], mean_best_reward: --\n",
      " 77853/100000: episode: 1812, duration: 0.056s, episode steps: 120, steps per second: 2137, episode reward: 120.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.525 [0.000, 1.000], mean observation: 0.037 [-1.016, 1.337], mean_best_reward: --\n",
      " 77937/100000: episode: 1813, duration: 0.036s, episode steps: 84, steps per second: 2358, episode reward: 84.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.157 [-1.976, 0.981], mean_best_reward: --\n",
      " 77993/100000: episode: 1814, duration: 0.024s, episode steps: 56, steps per second: 2286, episode reward: 56.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.051 [-1.389, 0.608], mean_best_reward: --\n",
      " 78009/100000: episode: 1815, duration: 0.008s, episode steps: 16, steps per second: 1985, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.312 [0.000, 1.000], mean observation: 0.063 [-1.602, 2.336], mean_best_reward: --\n",
      " 78117/100000: episode: 1816, duration: 0.048s, episode steps: 108, steps per second: 2243, episode reward: 108.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.491 [0.000, 1.000], mean observation: 0.024 [-1.195, 1.140], mean_best_reward: --\n",
      " 78220/100000: episode: 1817, duration: 0.058s, episode steps: 103, steps per second: 1771, episode reward: 103.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.253 [-2.057, 1.405], mean_best_reward: --\n",
      " 78298/100000: episode: 1818, duration: 0.034s, episode steps: 78, steps per second: 2268, episode reward: 78.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.043 [-0.576, 1.456], mean_best_reward: --\n",
      " 78370/100000: episode: 1819, duration: 0.032s, episode steps: 72, steps per second: 2275, episode reward: 72.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.083 [-0.784, 1.292], mean_best_reward: --\n",
      " 78427/100000: episode: 1820, duration: 0.025s, episode steps: 57, steps per second: 2296, episode reward: 57.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.491 [0.000, 1.000], mean observation: -0.134 [-1.096, 0.531], mean_best_reward: --\n",
      " 78579/100000: episode: 1821, duration: 0.073s, episode steps: 152, steps per second: 2083, episode reward: 152.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.493 [0.000, 1.000], mean observation: -0.297 [-1.826, 1.160], mean_best_reward: --\n",
      " 78682/100000: episode: 1822, duration: 0.050s, episode steps: 103, steps per second: 2041, episode reward: 103.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.524 [0.000, 1.000], mean observation: 0.052 [-0.707, 1.110], mean_best_reward: --\n",
      " 78788/100000: episode: 1823, duration: 0.047s, episode steps: 106, steps per second: 2261, episode reward: 106.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.491 [0.000, 1.000], mean observation: 0.042 [-1.127, 1.118], mean_best_reward: --\n",
      " 78839/100000: episode: 1824, duration: 0.023s, episode steps: 51, steps per second: 2198, episode reward: 51.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.451 [0.000, 1.000], mean observation: -0.136 [-0.968, 0.444], mean_best_reward: --\n",
      " 78888/100000: episode: 1825, duration: 0.021s, episode steps: 49, steps per second: 2302, episode reward: 49.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.044 [-1.111, 0.625], mean_best_reward: --\n",
      " 78986/100000: episode: 1826, duration: 0.041s, episode steps: 98, steps per second: 2373, episode reward: 98.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.052 [-1.270, 0.926], mean_best_reward: --\n",
      " 79150/100000: episode: 1827, duration: 0.088s, episode steps: 164, steps per second: 1870, episode reward: 164.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: 0.002 [-0.816, 0.768], mean_best_reward: --\n",
      " 79170/100000: episode: 1828, duration: 0.011s, episode steps: 20, steps per second: 1835, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.084 [-1.890, 1.142], mean_best_reward: --\n",
      " 79284/100000: episode: 1829, duration: 0.051s, episode steps: 114, steps per second: 2255, episode reward: 114.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.482 [0.000, 1.000], mean observation: 0.016 [-1.327, 1.103], mean_best_reward: --\n",
      " 79448/100000: episode: 1830, duration: 0.067s, episode steps: 164, steps per second: 2442, episode reward: 164.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.494 [0.000, 1.000], mean observation: -0.091 [-1.370, 0.959], mean_best_reward: --\n",
      " 79514/100000: episode: 1831, duration: 0.028s, episode steps: 66, steps per second: 2334, episode reward: 66.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: -0.106 [-1.768, 0.918], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 79629/100000: episode: 1832, duration: 0.051s, episode steps: 115, steps per second: 2252, episode reward: 115.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.548 [0.000, 1.000], mean observation: 0.233 [-1.404, 2.023], mean_best_reward: --\n",
      " 79715/100000: episode: 1833, duration: 0.046s, episode steps: 86, steps per second: 1870, episode reward: 86.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.029 [-0.737, 1.110], mean_best_reward: --\n",
      " 79803/100000: episode: 1834, duration: 0.038s, episode steps: 88, steps per second: 2312, episode reward: 88.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.534 [0.000, 1.000], mean observation: 0.272 [-1.339, 1.878], mean_best_reward: --\n",
      " 79962/100000: episode: 1835, duration: 0.068s, episode steps: 159, steps per second: 2345, episode reward: 159.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.497 [0.000, 1.000], mean observation: -0.334 [-1.759, 0.833], mean_best_reward: --\n",
      " 80138/100000: episode: 1836, duration: 0.086s, episode steps: 176, steps per second: 2045, episode reward: 176.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.477 [0.000, 1.000], mean observation: -0.379 [-2.286, 1.097], mean_best_reward: --\n",
      " 80183/100000: episode: 1837, duration: 0.021s, episode steps: 45, steps per second: 2168, episode reward: 45.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.489 [0.000, 1.000], mean observation: 0.039 [-0.763, 1.440], mean_best_reward: --\n",
      " 80213/100000: episode: 1838, duration: 0.015s, episode steps: 30, steps per second: 2060, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.095 [-1.090, 0.389], mean_best_reward: --\n",
      " 80247/100000: episode: 1839, duration: 0.017s, episode steps: 34, steps per second: 1995, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.529 [0.000, 1.000], mean observation: 0.047 [-0.767, 1.281], mean_best_reward: --\n",
      " 80311/100000: episode: 1840, duration: 0.031s, episode steps: 64, steps per second: 2045, episode reward: 64.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: -0.120 [-1.316, 0.575], mean_best_reward: --\n",
      " 80448/100000: episode: 1841, duration: 0.060s, episode steps: 137, steps per second: 2269, episode reward: 137.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.460 [0.000, 1.000], mean observation: -0.252 [-2.025, 0.823], mean_best_reward: --\n",
      " 80495/100000: episode: 1842, duration: 0.021s, episode steps: 47, steps per second: 2261, episode reward: 47.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.489 [0.000, 1.000], mean observation: 0.077 [-0.802, 1.476], mean_best_reward: --\n",
      " 80541/100000: episode: 1843, duration: 0.021s, episode steps: 46, steps per second: 2225, episode reward: 46.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.543 [0.000, 1.000], mean observation: 0.049 [-1.696, 1.337], mean_best_reward: --\n",
      " 80556/100000: episode: 1844, duration: 0.008s, episode steps: 15, steps per second: 1777, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.089 [-1.513, 0.932], mean_best_reward: --\n",
      " 80623/100000: episode: 1845, duration: 0.039s, episode steps: 67, steps per second: 1703, episode reward: 67.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.463 [0.000, 1.000], mean observation: -0.095 [-0.964, 0.929], mean_best_reward: --\n",
      " 80780/100000: episode: 1846, duration: 0.066s, episode steps: 157, steps per second: 2383, episode reward: 157.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: 0.058 [-1.258, 0.833], mean_best_reward: --\n",
      " 80849/100000: episode: 1847, duration: 0.031s, episode steps: 69, steps per second: 2259, episode reward: 69.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: 0.000 [-1.221, 1.826], mean_best_reward: --\n",
      " 80876/100000: episode: 1848, duration: 0.014s, episode steps: 27, steps per second: 1966, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.556 [0.000, 1.000], mean observation: -0.100 [-1.512, 0.602], mean_best_reward: --\n",
      " 80998/100000: episode: 1849, duration: 0.051s, episode steps: 122, steps per second: 2384, episode reward: 122.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.541 [0.000, 1.000], mean observation: 0.159 [-1.932, 2.454], mean_best_reward: --\n",
      " 81090/100000: episode: 1850, duration: 0.037s, episode steps: 92, steps per second: 2455, episode reward: 92.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: -0.103 [-1.194, 0.937], mean_best_reward: --\n",
      " 81142/100000: episode: 1851, duration: 0.033s, episode steps: 52, steps per second: 1572, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.084 [-1.370, 0.599], mean_best_reward: 183.000000\n",
      " 81179/100000: episode: 1852, duration: 0.018s, episode steps: 37, steps per second: 2074, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.486 [0.000, 1.000], mean observation: -0.001 [-1.011, 1.564], mean_best_reward: --\n",
      " 81254/100000: episode: 1853, duration: 0.033s, episode steps: 75, steps per second: 2266, episode reward: 75.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.440 [0.000, 1.000], mean observation: -0.280 [-1.840, 1.505], mean_best_reward: --\n",
      " 81347/100000: episode: 1854, duration: 0.040s, episode steps: 93, steps per second: 2345, episode reward: 93.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.527 [0.000, 1.000], mean observation: 0.147 [-1.125, 1.650], mean_best_reward: --\n",
      " 81462/100000: episode: 1855, duration: 0.049s, episode steps: 115, steps per second: 2351, episode reward: 115.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.539 [0.000, 1.000], mean observation: -0.045 [-1.764, 1.728], mean_best_reward: --\n",
      " 81515/100000: episode: 1856, duration: 0.037s, episode steps: 53, steps per second: 1441, episode reward: 53.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.472 [0.000, 1.000], mean observation: -0.055 [-1.103, 1.090], mean_best_reward: --\n",
      " 81600/100000: episode: 1857, duration: 0.072s, episode steps: 85, steps per second: 1182, episode reward: 85.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.494 [0.000, 1.000], mean observation: -0.099 [-1.351, 1.307], mean_best_reward: --\n",
      " 81680/100000: episode: 1858, duration: 0.063s, episode steps: 80, steps per second: 1268, episode reward: 80.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.192 [-1.548, 1.090], mean_best_reward: --\n",
      " 81796/100000: episode: 1859, duration: 0.118s, episode steps: 116, steps per second: 982, episode reward: 116.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.543 [0.000, 1.000], mean observation: 0.052 [-2.169, 2.121], mean_best_reward: --\n",
      " 81808/100000: episode: 1860, duration: 0.008s, episode steps: 12, steps per second: 1428, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.417 [0.000, 1.000], mean observation: 0.115 [-0.574, 1.053], mean_best_reward: --\n",
      " 81874/100000: episode: 1861, duration: 0.068s, episode steps: 66, steps per second: 966, episode reward: 66.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.606 [0.000, 1.000], mean observation: 0.036 [-3.466, 2.724], mean_best_reward: --\n",
      " 81984/100000: episode: 1862, duration: 0.062s, episode steps: 110, steps per second: 1762, episode reward: 110.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.564 [0.000, 1.000], mean observation: 0.472 [-0.855, 2.745], mean_best_reward: --\n",
      " 81999/100000: episode: 1863, duration: 0.011s, episode steps: 15, steps per second: 1313, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: 0.051 [-1.200, 1.726], mean_best_reward: --\n",
      " 82131/100000: episode: 1864, duration: 0.073s, episode steps: 132, steps per second: 1809, episode reward: 132.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.508 [0.000, 1.000], mean observation: 0.084 [-1.272, 1.141], mean_best_reward: --\n",
      " 82245/100000: episode: 1865, duration: 0.055s, episode steps: 114, steps per second: 2085, episode reward: 114.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.456 [0.000, 1.000], mean observation: -0.188 [-2.040, 1.665], mean_best_reward: --\n",
      " 82287/100000: episode: 1866, duration: 0.021s, episode steps: 42, steps per second: 2045, episode reward: 42.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: 0.142 [-2.879, 2.715], mean_best_reward: --\n",
      " 82355/100000: episode: 1867, duration: 0.030s, episode steps: 68, steps per second: 2282, episode reward: 68.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.544 [0.000, 1.000], mean observation: 0.089 [-1.507, 1.183], mean_best_reward: --\n",
      " 82367/100000: episode: 1868, duration: 0.007s, episode steps: 12, steps per second: 1799, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.833 [0.000, 1.000], mean observation: -0.113 [-2.501, 1.567], mean_best_reward: --\n",
      " 82445/100000: episode: 1869, duration: 0.034s, episode steps: 78, steps per second: 2276, episode reward: 78.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: 0.143 [-1.396, 1.889], mean_best_reward: --\n",
      " 82519/100000: episode: 1870, duration: 0.031s, episode steps: 74, steps per second: 2378, episode reward: 74.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.527 [0.000, 1.000], mean observation: -0.140 [-2.232, 0.778], mean_best_reward: --\n",
      " 82554/100000: episode: 1871, duration: 0.019s, episode steps: 35, steps per second: 1843, episode reward: 35.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: 0.139 [-0.401, 0.955], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 82582/100000: episode: 1872, duration: 0.020s, episode steps: 28, steps per second: 1435, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.536 [0.000, 1.000], mean observation: 0.082 [-0.735, 1.155], mean_best_reward: --\n",
      " 82654/100000: episode: 1873, duration: 0.051s, episode steps: 72, steps per second: 1411, episode reward: 72.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.458 [0.000, 1.000], mean observation: -0.215 [-1.885, 1.141], mean_best_reward: --\n",
      " 82721/100000: episode: 1874, duration: 0.043s, episode steps: 67, steps per second: 1546, episode reward: 67.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.493 [0.000, 1.000], mean observation: 0.113 [-0.657, 1.407], mean_best_reward: --\n",
      " 82739/100000: episode: 1875, duration: 0.010s, episode steps: 18, steps per second: 1716, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.444 [0.000, 1.000], mean observation: 0.096 [-0.772, 1.499], mean_best_reward: --\n",
      " 82796/100000: episode: 1876, duration: 0.024s, episode steps: 57, steps per second: 2330, episode reward: 57.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.439 [0.000, 1.000], mean observation: 0.002 [-1.551, 2.489], mean_best_reward: --\n",
      " 82872/100000: episode: 1877, duration: 0.034s, episode steps: 76, steps per second: 2217, episode reward: 76.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.526 [0.000, 1.000], mean observation: 0.006 [-2.050, 0.833], mean_best_reward: --\n",
      " 82889/100000: episode: 1878, duration: 0.009s, episode steps: 17, steps per second: 1939, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.647 [0.000, 1.000], mean observation: -0.069 [-1.749, 1.015], mean_best_reward: --\n",
      " 83025/100000: episode: 1879, duration: 0.066s, episode steps: 136, steps per second: 2060, episode reward: 136.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.537 [0.000, 1.000], mean observation: -0.111 [-1.869, 1.898], mean_best_reward: --\n",
      " 83105/100000: episode: 1880, duration: 0.035s, episode steps: 80, steps per second: 2311, episode reward: 80.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.525 [0.000, 1.000], mean observation: 0.057 [-1.219, 1.090], mean_best_reward: --\n",
      " 83184/100000: episode: 1881, duration: 0.033s, episode steps: 79, steps per second: 2359, episode reward: 79.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.456 [0.000, 1.000], mean observation: -0.212 [-1.356, 1.372], mean_best_reward: --\n",
      " 83285/100000: episode: 1882, duration: 0.042s, episode steps: 101, steps per second: 2400, episode reward: 101.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.092 [-1.165, 1.340], mean_best_reward: --\n",
      " 83367/100000: episode: 1883, duration: 0.036s, episode steps: 82, steps per second: 2260, episode reward: 82.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.001 [-1.136, 1.225], mean_best_reward: --\n",
      " 83447/100000: episode: 1884, duration: 0.034s, episode steps: 80, steps per second: 2333, episode reward: 80.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.450 [0.000, 1.000], mean observation: -0.179 [-1.847, 1.168], mean_best_reward: --\n",
      " 83607/100000: episode: 1885, duration: 0.080s, episode steps: 160, steps per second: 2003, episode reward: 160.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.525 [0.000, 1.000], mean observation: -0.162 [-2.448, 1.545], mean_best_reward: --\n",
      " 83677/100000: episode: 1886, duration: 0.030s, episode steps: 70, steps per second: 2341, episode reward: 70.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: -0.026 [-1.301, 1.051], mean_best_reward: --\n",
      " 83785/100000: episode: 1887, duration: 0.057s, episode steps: 108, steps per second: 1902, episode reward: 108.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.565 [0.000, 1.000], mean observation: -0.144 [-3.457, 2.703], mean_best_reward: --\n",
      " 83852/100000: episode: 1888, duration: 0.063s, episode steps: 67, steps per second: 1068, episode reward: 67.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.507 [0.000, 1.000], mean observation: 0.099 [-0.664, 1.250], mean_best_reward: --\n",
      " 83907/100000: episode: 1889, duration: 0.046s, episode steps: 55, steps per second: 1200, episode reward: 55.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: 0.113 [-2.416, 2.517], mean_best_reward: --\n",
      " 84059/100000: episode: 1890, duration: 0.132s, episode steps: 152, steps per second: 1152, episode reward: 152.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.493 [0.000, 1.000], mean observation: -0.032 [-1.109, 1.357], mean_best_reward: --\n",
      " 84137/100000: episode: 1891, duration: 0.050s, episode steps: 78, steps per second: 1553, episode reward: 78.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: 0.008 [-1.383, 1.352], mean_best_reward: --\n",
      " 84271/100000: episode: 1892, duration: 0.063s, episode steps: 134, steps per second: 2127, episode reward: 134.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.130 [-1.016, 1.127], mean_best_reward: --\n",
      " 84280/100000: episode: 1893, duration: 0.006s, episode steps: 9, steps per second: 1398, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.889 [0.000, 1.000], mean observation: -0.135 [-2.262, 1.347], mean_best_reward: --\n",
      " 84298/100000: episode: 1894, duration: 0.010s, episode steps: 18, steps per second: 1740, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.061 [-2.051, 1.229], mean_best_reward: --\n",
      " 84337/100000: episode: 1895, duration: 0.019s, episode steps: 39, steps per second: 2009, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.564 [0.000, 1.000], mean observation: 0.142 [-0.405, 0.895], mean_best_reward: --\n",
      " 84495/100000: episode: 1896, duration: 0.076s, episode steps: 158, steps per second: 2074, episode reward: 158.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.062 [-1.728, 1.632], mean_best_reward: --\n",
      " 84564/100000: episode: 1897, duration: 0.031s, episode steps: 69, steps per second: 2229, episode reward: 69.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.449 [0.000, 1.000], mean observation: -0.228 [-1.664, 1.116], mean_best_reward: --\n",
      " 84694/100000: episode: 1898, duration: 0.053s, episode steps: 130, steps per second: 2434, episode reward: 130.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.036 [-1.446, 0.975], mean_best_reward: --\n",
      " 84728/100000: episode: 1899, duration: 0.015s, episode steps: 34, steps per second: 2244, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.559 [0.000, 1.000], mean observation: -0.086 [-1.897, 0.953], mean_best_reward: --\n",
      " 84799/100000: episode: 1900, duration: 0.030s, episode steps: 71, steps per second: 2353, episode reward: 71.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.521 [0.000, 1.000], mean observation: 0.088 [-1.104, 1.309], mean_best_reward: --\n",
      " 84999/100000: episode: 1901, duration: 0.114s, episode steps: 200, steps per second: 1755, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: -0.090 [-1.188, 0.822], mean_best_reward: 178.000000\n",
      " 85091/100000: episode: 1902, duration: 0.040s, episode steps: 92, steps per second: 2293, episode reward: 92.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.565 [0.000, 1.000], mean observation: 0.147 [-2.472, 2.478], mean_best_reward: --\n",
      " 85190/100000: episode: 1903, duration: 0.042s, episode steps: 99, steps per second: 2338, episode reward: 99.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.596 [0.000, 1.000], mean observation: 0.339 [-2.729, 3.530], mean_best_reward: --\n",
      " 85283/100000: episode: 1904, duration: 0.039s, episode steps: 93, steps per second: 2371, episode reward: 93.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.591 [0.000, 1.000], mean observation: 0.117 [-3.655, 3.299], mean_best_reward: --\n",
      " 85324/100000: episode: 1905, duration: 0.019s, episode steps: 41, steps per second: 2155, episode reward: 41.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.512 [0.000, 1.000], mean observation: 0.024 [-0.778, 1.330], mean_best_reward: --\n",
      " 85401/100000: episode: 1906, duration: 0.033s, episode steps: 77, steps per second: 2359, episode reward: 77.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.481 [0.000, 1.000], mean observation: -0.094 [-0.918, 0.573], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 85484/100000: episode: 1907, duration: 0.042s, episode steps: 83, steps per second: 1981, episode reward: 83.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.506 [0.000, 1.000], mean observation: 0.057 [-0.566, 1.203], mean_best_reward: --\n",
      " 85525/100000: episode: 1908, duration: 0.027s, episode steps: 41, steps per second: 1539, episode reward: 41.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.512 [0.000, 1.000], mean observation: 0.072 [-0.591, 1.261], mean_best_reward: --\n",
      " 85584/100000: episode: 1909, duration: 0.027s, episode steps: 59, steps per second: 2173, episode reward: 59.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.542 [0.000, 1.000], mean observation: 0.206 [-0.388, 1.103], mean_best_reward: --\n",
      " 85622/100000: episode: 1910, duration: 0.018s, episode steps: 38, steps per second: 2125, episode reward: 38.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.526 [0.000, 1.000], mean observation: 0.079 [-0.963, 1.437], mean_best_reward: --\n",
      " 85673/100000: episode: 1911, duration: 0.022s, episode steps: 51, steps per second: 2345, episode reward: 51.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: 0.029 [-0.819, 1.429], mean_best_reward: --\n",
      " 85756/100000: episode: 1912, duration: 0.035s, episode steps: 83, steps per second: 2344, episode reward: 83.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.590 [0.000, 1.000], mean observation: 0.232 [-2.267, 2.846], mean_best_reward: --\n",
      " 85840/100000: episode: 1913, duration: 0.039s, episode steps: 84, steps per second: 2167, episode reward: 84.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: -0.240 [-1.475, 0.840], mean_best_reward: --\n",
      " 85922/100000: episode: 1914, duration: 0.041s, episode steps: 82, steps per second: 2007, episode reward: 82.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.451 [0.000, 1.000], mean observation: -0.308 [-2.416, 1.458], mean_best_reward: --\n",
      " 86017/100000: episode: 1915, duration: 0.049s, episode steps: 95, steps per second: 1933, episode reward: 95.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.568 [0.000, 1.000], mean observation: 0.239 [-2.145, 2.441], mean_best_reward: --\n",
      " 86203/100000: episode: 1916, duration: 0.078s, episode steps: 186, steps per second: 2373, episode reward: 186.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.489 [0.000, 1.000], mean observation: -0.193 [-1.490, 1.107], mean_best_reward: --\n",
      " 86234/100000: episode: 1917, duration: 0.015s, episode steps: 31, steps per second: 2078, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.516 [0.000, 1.000], mean observation: 0.023 [-0.799, 1.021], mean_best_reward: --\n",
      " 86298/100000: episode: 1918, duration: 0.027s, episode steps: 64, steps per second: 2389, episode reward: 64.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.516 [0.000, 1.000], mean observation: 0.077 [-0.514, 1.036], mean_best_reward: --\n",
      " 86348/100000: episode: 1919, duration: 0.021s, episode steps: 50, steps per second: 2363, episode reward: 50.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.069 [-1.073, 0.437], mean_best_reward: --\n",
      " 86526/100000: episode: 1920, duration: 0.090s, episode steps: 178, steps per second: 1976, episode reward: 178.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.528 [0.000, 1.000], mean observation: -0.028 [-2.431, 1.975], mean_best_reward: --\n",
      " 86688/100000: episode: 1921, duration: 0.069s, episode steps: 162, steps per second: 2360, episode reward: 162.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: -0.117 [-1.659, 0.696], mean_best_reward: --\n",
      " 86769/100000: episode: 1922, duration: 0.033s, episode steps: 81, steps per second: 2441, episode reward: 81.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.494 [0.000, 1.000], mean observation: -0.105 [-1.342, 1.232], mean_best_reward: --\n",
      " 86838/100000: episode: 1923, duration: 0.029s, episode steps: 69, steps per second: 2402, episode reward: 69.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.522 [0.000, 1.000], mean observation: 0.017 [-1.494, 0.737], mean_best_reward: --\n",
      " 86943/100000: episode: 1924, duration: 0.043s, episode steps: 105, steps per second: 2419, episode reward: 105.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.077 [-0.870, 1.165], mean_best_reward: --\n",
      " 87013/100000: episode: 1925, duration: 0.033s, episode steps: 70, steps per second: 2137, episode reward: 70.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: -0.009 [-1.689, 1.144], mean_best_reward: --\n",
      " 87107/100000: episode: 1926, duration: 0.050s, episode steps: 94, steps per second: 1867, episode reward: 94.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.543 [0.000, 1.000], mean observation: 0.169 [-1.014, 1.692], mean_best_reward: --\n",
      " 87123/100000: episode: 1927, duration: 0.009s, episode steps: 16, steps per second: 1766, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.075 [-0.821, 1.395], mean_best_reward: --\n",
      " 87154/100000: episode: 1928, duration: 0.015s, episode steps: 31, steps per second: 2053, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.613 [0.000, 1.000], mean observation: -0.000 [-2.109, 1.372], mean_best_reward: --\n",
      " 87307/100000: episode: 1929, duration: 0.064s, episode steps: 153, steps per second: 2403, episode reward: 153.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.477 [0.000, 1.000], mean observation: -0.112 [-1.523, 2.043], mean_best_reward: --\n",
      " 87330/100000: episode: 1930, duration: 0.011s, episode steps: 23, steps per second: 2101, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: 0.059 [-0.604, 0.977], mean_best_reward: --\n",
      " 87469/100000: episode: 1931, duration: 0.059s, episode steps: 139, steps per second: 2353, episode reward: 139.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.391 [-2.141, 0.856], mean_best_reward: --\n",
      " 87581/100000: episode: 1932, duration: 0.057s, episode steps: 112, steps per second: 1968, episode reward: 112.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: 0.220 [-1.723, 2.056], mean_best_reward: --\n",
      " 87612/100000: episode: 1933, duration: 0.014s, episode steps: 31, steps per second: 2207, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.452 [0.000, 1.000], mean observation: 0.022 [-1.033, 1.691], mean_best_reward: --\n",
      " 87704/100000: episode: 1934, duration: 0.038s, episode steps: 92, steps per second: 2443, episode reward: 92.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.511 [0.000, 1.000], mean observation: -0.011 [-1.633, 0.574], mean_best_reward: --\n",
      " 87773/100000: episode: 1935, duration: 0.029s, episode steps: 69, steps per second: 2418, episode reward: 69.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.522 [0.000, 1.000], mean observation: 0.073 [-0.866, 0.826], mean_best_reward: --\n",
      " 87904/100000: episode: 1936, duration: 0.054s, episode steps: 131, steps per second: 2414, episode reward: 131.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.511 [0.000, 1.000], mean observation: 0.054 [-1.303, 0.781], mean_best_reward: --\n",
      " 87994/100000: episode: 1937, duration: 0.049s, episode steps: 90, steps per second: 1844, episode reward: 90.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.533 [0.000, 1.000], mean observation: 0.157 [-0.632, 1.059], mean_best_reward: --\n",
      " 88139/100000: episode: 1938, duration: 0.068s, episode steps: 145, steps per second: 2147, episode reward: 145.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.531 [0.000, 1.000], mean observation: 0.105 [-2.846, 1.754], mean_best_reward: --\n",
      " 88176/100000: episode: 1939, duration: 0.018s, episode steps: 37, steps per second: 2073, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.595 [0.000, 1.000], mean observation: -0.038 [-2.418, 1.417], mean_best_reward: --\n",
      " 88239/100000: episode: 1940, duration: 0.029s, episode steps: 63, steps per second: 2210, episode reward: 63.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.444 [0.000, 1.000], mean observation: -0.129 [-1.515, 1.488], mean_best_reward: --\n",
      " 88289/100000: episode: 1941, duration: 0.022s, episode steps: 50, steps per second: 2295, episode reward: 50.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.580 [0.000, 1.000], mean observation: 0.055 [-2.050, 1.538], mean_best_reward: --\n",
      " 88343/100000: episode: 1942, duration: 0.024s, episode steps: 54, steps per second: 2280, episode reward: 54.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.046 [-1.359, 1.715], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88503/100000: episode: 1943, duration: 0.080s, episode steps: 160, steps per second: 1991, episode reward: 160.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.487 [0.000, 1.000], mean observation: 0.027 [-1.131, 1.412], mean_best_reward: --\n",
      " 88615/100000: episode: 1944, duration: 0.048s, episode steps: 112, steps per second: 2326, episode reward: 112.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.482 [0.000, 1.000], mean observation: -0.069 [-1.160, 1.359], mean_best_reward: --\n",
      " 88665/100000: episode: 1945, duration: 0.021s, episode steps: 50, steps per second: 2364, episode reward: 50.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: 0.137 [-0.580, 0.928], mean_best_reward: --\n",
      " 88716/100000: episode: 1946, duration: 0.022s, episode steps: 51, steps per second: 2360, episode reward: 51.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.549 [0.000, 1.000], mean observation: 0.183 [-0.688, 1.319], mean_best_reward: --\n",
      " 88781/100000: episode: 1947, duration: 0.028s, episode steps: 65, steps per second: 2302, episode reward: 65.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: 0.158 [-0.503, 0.939], mean_best_reward: --\n",
      " 88861/100000: episode: 1948, duration: 0.033s, episode steps: 80, steps per second: 2409, episode reward: 80.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.575 [0.000, 1.000], mean observation: 0.254 [-1.784, 2.240], mean_best_reward: --\n",
      " 88920/100000: episode: 1949, duration: 0.025s, episode steps: 59, steps per second: 2350, episode reward: 59.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.508 [0.000, 1.000], mean observation: 0.060 [-0.621, 1.068], mean_best_reward: --\n",
      " 88983/100000: episode: 1950, duration: 0.034s, episode steps: 63, steps per second: 1874, episode reward: 63.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: -0.227 [-2.492, 2.014], mean_best_reward: --\n",
      " 89118/100000: episode: 1951, duration: 0.062s, episode steps: 135, steps per second: 2193, episode reward: 135.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.526 [0.000, 1.000], mean observation: -0.127 [-1.900, 1.396], mean_best_reward: 191.000000\n",
      " 89162/100000: episode: 1952, duration: 0.019s, episode steps: 44, steps per second: 2338, episode reward: 44.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.523 [0.000, 1.000], mean observation: -0.034 [-1.544, 1.002], mean_best_reward: --\n",
      " 89196/100000: episode: 1953, duration: 0.016s, episode steps: 34, steps per second: 2092, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.057 [-0.851, 0.560], mean_best_reward: --\n",
      " 89233/100000: episode: 1954, duration: 0.016s, episode steps: 37, steps per second: 2256, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.459 [0.000, 1.000], mean observation: 0.068 [-0.823, 1.889], mean_best_reward: --\n",
      " 89263/100000: episode: 1955, duration: 0.015s, episode steps: 30, steps per second: 2052, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.098 [-0.819, 1.391], mean_best_reward: --\n",
      " 89276/100000: episode: 1956, duration: 0.008s, episode steps: 13, steps per second: 1718, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.615 [0.000, 1.000], mean observation: -0.093 [-1.870, 1.194], mean_best_reward: --\n",
      " 89390/100000: episode: 1957, duration: 0.049s, episode steps: 114, steps per second: 2326, episode reward: 114.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.518 [0.000, 1.000], mean observation: 0.258 [-1.118, 1.469], mean_best_reward: --\n",
      " 89483/100000: episode: 1958, duration: 0.052s, episode steps: 93, steps per second: 1781, episode reward: 93.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.516 [0.000, 1.000], mean observation: 0.219 [-0.722, 1.209], mean_best_reward: --\n",
      " 89525/100000: episode: 1959, duration: 0.019s, episode steps: 42, steps per second: 2157, episode reward: 42.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: 0.066 [-0.754, 1.574], mean_best_reward: --\n",
      " 89607/100000: episode: 1960, duration: 0.035s, episode steps: 82, steps per second: 2343, episode reward: 82.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: -0.133 [-1.942, 1.741], mean_best_reward: --\n",
      " 89768/100000: episode: 1961, duration: 0.067s, episode steps: 161, steps per second: 2400, episode reward: 161.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.491 [0.000, 1.000], mean observation: 0.107 [-1.418, 0.823], mean_best_reward: --\n",
      " 89851/100000: episode: 1962, duration: 0.035s, episode steps: 83, steps per second: 2406, episode reward: 83.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.494 [0.000, 1.000], mean observation: -0.075 [-1.358, 1.618], mean_best_reward: --\n",
      " 89869/100000: episode: 1963, duration: 0.009s, episode steps: 18, steps per second: 1932, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.444 [0.000, 1.000], mean observation: 0.076 [-0.802, 1.244], mean_best_reward: --\n",
      " 89990/100000: episode: 1964, duration: 0.060s, episode steps: 121, steps per second: 2023, episode reward: 121.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.479 [0.000, 1.000], mean observation: -0.192 [-1.527, 1.471], mean_best_reward: --\n",
      " 90027/100000: episode: 1965, duration: 0.020s, episode steps: 37, steps per second: 1816, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.541 [0.000, 1.000], mean observation: 0.132 [-0.570, 1.065], mean_best_reward: --\n",
      " 90117/100000: episode: 1966, duration: 0.038s, episode steps: 90, steps per second: 2368, episode reward: 90.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.203 [-1.886, 1.252], mean_best_reward: --\n",
      " 90161/100000: episode: 1967, duration: 0.020s, episode steps: 44, steps per second: 2211, episode reward: 44.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.009 [-1.019, 1.387], mean_best_reward: --\n",
      " 90208/100000: episode: 1968, duration: 0.022s, episode steps: 47, steps per second: 2133, episode reward: 47.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.511 [0.000, 1.000], mean observation: -0.019 [-1.101, 0.808], mean_best_reward: --\n",
      " 90350/100000: episode: 1969, duration: 0.059s, episode steps: 142, steps per second: 2408, episode reward: 142.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.486 [0.000, 1.000], mean observation: -0.400 [-2.282, 1.263], mean_best_reward: --\n",
      " 90375/100000: episode: 1970, duration: 0.012s, episode steps: 25, steps per second: 2048, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.046 [-1.905, 1.181], mean_best_reward: --\n",
      " 90414/100000: episode: 1971, duration: 0.018s, episode steps: 39, steps per second: 2136, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: 0.021 [-1.028, 1.615], mean_best_reward: --\n",
      " 90440/100000: episode: 1972, duration: 0.014s, episode steps: 26, steps per second: 1851, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: -0.066 [-1.159, 0.593], mean_best_reward: --\n",
      " 90465/100000: episode: 1973, duration: 0.020s, episode steps: 25, steps per second: 1271, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: 0.091 [-0.579, 1.205], mean_best_reward: --\n",
      " 90499/100000: episode: 1974, duration: 0.016s, episode steps: 34, steps per second: 2115, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.031 [-1.181, 0.739], mean_best_reward: --\n",
      " 90623/100000: episode: 1975, duration: 0.054s, episode steps: 124, steps per second: 2312, episode reward: 124.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.524 [0.000, 1.000], mean observation: -0.081 [-0.991, 1.247], mean_best_reward: --\n",
      " 90643/100000: episode: 1976, duration: 0.011s, episode steps: 20, steps per second: 1866, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.650 [0.000, 1.000], mean observation: -0.077 [-1.999, 1.170], mean_best_reward: --\n",
      " 90726/100000: episode: 1977, duration: 0.035s, episode steps: 83, steps per second: 2404, episode reward: 83.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.518 [0.000, 1.000], mean observation: 0.105 [-0.855, 1.060], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90883/100000: episode: 1978, duration: 0.063s, episode steps: 157, steps per second: 2484, episode reward: 157.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: -0.149 [-1.532, 1.157], mean_best_reward: --\n",
      " 90897/100000: episode: 1979, duration: 0.012s, episode steps: 14, steps per second: 1131, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.643 [0.000, 1.000], mean observation: -0.104 [-1.498, 0.970], mean_best_reward: --\n",
      " 90933/100000: episode: 1980, duration: 0.025s, episode steps: 36, steps per second: 1419, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.472 [0.000, 1.000], mean observation: -0.108 [-0.897, 0.447], mean_best_reward: --\n",
      " 91052/100000: episode: 1981, duration: 0.051s, episode steps: 119, steps per second: 2350, episode reward: 119.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.454 [0.000, 1.000], mean observation: -0.312 [-2.593, 1.277], mean_best_reward: --\n",
      " 91131/100000: episode: 1982, duration: 0.033s, episode steps: 79, steps per second: 2401, episode reward: 79.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.532 [0.000, 1.000], mean observation: 0.188 [-0.627, 1.126], mean_best_reward: --\n",
      " 91235/100000: episode: 1983, duration: 0.042s, episode steps: 104, steps per second: 2477, episode reward: 104.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.519 [0.000, 1.000], mean observation: 0.104 [-0.585, 0.992], mean_best_reward: --\n",
      " 91327/100000: episode: 1984, duration: 0.039s, episode steps: 92, steps per second: 2372, episode reward: 92.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.533 [0.000, 1.000], mean observation: 0.136 [-0.675, 1.111], mean_best_reward: --\n",
      " 91428/100000: episode: 1985, duration: 0.064s, episode steps: 101, steps per second: 1588, episode reward: 101.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.535 [0.000, 1.000], mean observation: 0.189 [-0.571, 1.503], mean_best_reward: --\n",
      " 91507/100000: episode: 1986, duration: 0.035s, episode steps: 79, steps per second: 2249, episode reward: 79.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.481 [0.000, 1.000], mean observation: -0.060 [-1.387, 1.793], mean_best_reward: --\n",
      " 91570/100000: episode: 1987, duration: 0.028s, episode steps: 63, steps per second: 2235, episode reward: 63.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: 0.026 [-0.975, 1.290], mean_best_reward: --\n",
      " 91612/100000: episode: 1988, duration: 0.019s, episode steps: 42, steps per second: 2216, episode reward: 42.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.524 [0.000, 1.000], mean observation: 0.087 [-0.579, 1.180], mean_best_reward: --\n",
      " 91663/100000: episode: 1989, duration: 0.022s, episode steps: 51, steps per second: 2328, episode reward: 51.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.110 [-1.258, 0.440], mean_best_reward: --\n",
      " 91723/100000: episode: 1990, duration: 0.027s, episode steps: 60, steps per second: 2242, episode reward: 60.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.075 [-1.484, 0.597], mean_best_reward: --\n",
      " 91856/100000: episode: 1991, duration: 0.065s, episode steps: 133, steps per second: 2037, episode reward: 133.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.526 [0.000, 1.000], mean observation: 0.286 [-0.788, 1.647], mean_best_reward: --\n",
      " 91906/100000: episode: 1992, duration: 0.022s, episode steps: 50, steps per second: 2229, episode reward: 50.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: 0.042 [-0.830, 1.314], mean_best_reward: --\n",
      " 91927/100000: episode: 1993, duration: 0.010s, episode steps: 21, steps per second: 2118, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.571 [0.000, 1.000], mean observation: -0.062 [-1.513, 0.834], mean_best_reward: --\n",
      " 91967/100000: episode: 1994, duration: 0.018s, episode steps: 40, steps per second: 2260, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.525 [0.000, 1.000], mean observation: 0.021 [-0.821, 1.016], mean_best_reward: --\n",
      " 92003/100000: episode: 1995, duration: 0.016s, episode steps: 36, steps per second: 2260, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.472 [0.000, 1.000], mean observation: -0.051 [-1.101, 0.792], mean_best_reward: --\n",
      " 92099/100000: episode: 1996, duration: 0.041s, episode steps: 96, steps per second: 2355, episode reward: 96.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.479 [0.000, 1.000], mean observation: -0.169 [-1.098, 0.535], mean_best_reward: --\n",
      " 92184/100000: episode: 1997, duration: 0.035s, episode steps: 85, steps per second: 2453, episode reward: 85.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.435 [0.000, 1.000], mean observation: -0.259 [-2.070, 1.645], mean_best_reward: --\n",
      " 92247/100000: episode: 1998, duration: 0.026s, episode steps: 63, steps per second: 2393, episode reward: 63.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.524 [0.000, 1.000], mean observation: 0.088 [-0.984, 1.257], mean_best_reward: --\n",
      " 92329/100000: episode: 1999, duration: 0.036s, episode steps: 82, steps per second: 2279, episode reward: 82.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.524 [0.000, 1.000], mean observation: 0.026 [-1.558, 1.019], mean_best_reward: --\n",
      " 92353/100000: episode: 2000, duration: 0.025s, episode steps: 24, steps per second: 972, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.043 [-1.511, 0.992], mean_best_reward: --\n",
      " 92444/100000: episode: 2001, duration: 0.039s, episode steps: 91, steps per second: 2315, episode reward: 91.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.068 [-1.196, 1.197], mean_best_reward: 139.000000\n",
      " 92531/100000: episode: 2002, duration: 0.036s, episode steps: 87, steps per second: 2391, episode reward: 87.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.460 [0.000, 1.000], mean observation: -0.242 [-2.071, 1.394], mean_best_reward: --\n",
      " 92608/100000: episode: 2003, duration: 0.033s, episode steps: 77, steps per second: 2314, episode reward: 77.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.532 [0.000, 1.000], mean observation: 0.042 [-1.154, 1.457], mean_best_reward: --\n",
      " 92635/100000: episode: 2004, duration: 0.014s, episode steps: 27, steps per second: 1982, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.593 [0.000, 1.000], mean observation: -0.074 [-1.881, 0.990], mean_best_reward: --\n",
      " 92668/100000: episode: 2005, duration: 0.015s, episode steps: 33, steps per second: 2235, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.576 [0.000, 1.000], mean observation: -0.051 [-1.882, 1.031], mean_best_reward: --\n",
      " 92758/100000: episode: 2006, duration: 0.038s, episode steps: 90, steps per second: 2398, episode reward: 90.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.533 [0.000, 1.000], mean observation: 0.206 [-1.337, 1.545], mean_best_reward: --\n",
      " 92812/100000: episode: 2007, duration: 0.030s, episode steps: 54, steps per second: 1817, episode reward: 54.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.101 [-0.778, 1.197], mean_best_reward: --\n",
      " 92919/100000: episode: 2008, duration: 0.050s, episode steps: 107, steps per second: 2154, episode reward: 107.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.449 [0.000, 1.000], mean observation: -0.475 [-2.597, 1.259], mean_best_reward: --\n",
      " 93003/100000: episode: 2009, duration: 0.036s, episode steps: 84, steps per second: 2323, episode reward: 84.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.452 [0.000, 1.000], mean observation: -0.149 [-2.274, 1.711], mean_best_reward: --\n",
      " 93040/100000: episode: 2010, duration: 0.019s, episode steps: 37, steps per second: 1907, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: -0.092 [-1.527, 0.604], mean_best_reward: --\n",
      " 93104/100000: episode: 2011, duration: 0.027s, episode steps: 64, steps per second: 2376, episode reward: 64.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.453 [0.000, 1.000], mean observation: -0.248 [-1.312, 0.798], mean_best_reward: --\n",
      " 93165/100000: episode: 2012, duration: 0.025s, episode steps: 61, steps per second: 2399, episode reward: 61.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.525 [0.000, 1.000], mean observation: 0.157 [-0.605, 0.970], mean_best_reward: --\n",
      " 93178/100000: episode: 2013, duration: 0.007s, episode steps: 13, steps per second: 1819, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.385 [0.000, 1.000], mean observation: 0.107 [-0.826, 1.507], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93203/100000: episode: 2014, duration: 0.014s, episode steps: 25, steps per second: 1815, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.640 [0.000, 1.000], mean observation: -0.003 [-2.261, 1.581], mean_best_reward: --\n",
      " 93225/100000: episode: 2015, duration: 0.015s, episode steps: 22, steps per second: 1507, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: -0.100 [-1.216, 0.740], mean_best_reward: --\n",
      " 93309/100000: episode: 2016, duration: 0.040s, episode steps: 84, steps per second: 2089, episode reward: 84.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.536 [0.000, 1.000], mean observation: 0.199 [-0.528, 1.309], mean_best_reward: --\n",
      " 93379/100000: episode: 2017, duration: 0.029s, episode steps: 70, steps per second: 2374, episode reward: 70.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: -0.242 [-2.421, 0.783], mean_best_reward: --\n",
      " 93400/100000: episode: 2018, duration: 0.010s, episode steps: 21, steps per second: 2077, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.619 [0.000, 1.000], mean observation: -0.076 [-1.786, 0.944], mean_best_reward: --\n",
      " 93413/100000: episode: 2019, duration: 0.007s, episode steps: 13, steps per second: 1828, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: -0.110 [-1.300, 0.758], mean_best_reward: --\n",
      " 93489/100000: episode: 2020, duration: 0.032s, episode steps: 76, steps per second: 2377, episode reward: 76.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.447 [0.000, 1.000], mean observation: -0.106 [-2.106, 1.958], mean_best_reward: --\n",
      " 93518/100000: episode: 2021, duration: 0.013s, episode steps: 29, steps per second: 2179, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.483 [0.000, 1.000], mean observation: 0.053 [-0.981, 1.595], mean_best_reward: --\n",
      " 93541/100000: episode: 2022, duration: 0.011s, episode steps: 23, steps per second: 2135, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: 0.083 [-0.578, 1.199], mean_best_reward: --\n",
      " 93573/100000: episode: 2023, duration: 0.015s, episode steps: 32, steps per second: 2172, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.531 [0.000, 1.000], mean observation: -0.100 [-1.604, 0.749], mean_best_reward: --\n",
      " 93595/100000: episode: 2024, duration: 0.011s, episode steps: 22, steps per second: 2012, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.364 [0.000, 1.000], mean observation: 0.053 [-1.214, 2.047], mean_best_reward: --\n",
      " 93661/100000: episode: 2025, duration: 0.037s, episode steps: 66, steps per second: 1761, episode reward: 66.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: 0.164 [-0.802, 1.334], mean_best_reward: --\n",
      " 93759/100000: episode: 2026, duration: 0.043s, episode steps: 98, steps per second: 2291, episode reward: 98.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.054 [-1.120, 0.979], mean_best_reward: --\n",
      " 93852/100000: episode: 2027, duration: 0.039s, episode steps: 93, steps per second: 2396, episode reward: 93.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.516 [0.000, 1.000], mean observation: 0.134 [-0.729, 1.278], mean_best_reward: --\n",
      " 93918/100000: episode: 2028, duration: 0.028s, episode steps: 66, steps per second: 2328, episode reward: 66.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.530 [0.000, 1.000], mean observation: -0.060 [-1.940, 0.842], mean_best_reward: --\n",
      " 93944/100000: episode: 2029, duration: 0.012s, episode steps: 26, steps per second: 2185, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: -0.072 [-1.162, 0.593], mean_best_reward: --\n",
      " 94006/100000: episode: 2030, duration: 0.026s, episode steps: 62, steps per second: 2343, episode reward: 62.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.548 [0.000, 1.000], mean observation: 0.043 [-1.801, 1.121], mean_best_reward: --\n",
      " 94094/100000: episode: 2031, duration: 0.039s, episode steps: 88, steps per second: 2270, episode reward: 88.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.523 [0.000, 1.000], mean observation: 0.119 [-0.757, 1.153], mean_best_reward: --\n",
      " 94166/100000: episode: 2032, duration: 0.044s, episode steps: 72, steps per second: 1629, episode reward: 72.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.486 [0.000, 1.000], mean observation: -0.022 [-0.856, 0.769], mean_best_reward: --\n",
      " 94272/100000: episode: 2033, duration: 0.048s, episode steps: 106, steps per second: 2187, episode reward: 106.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.566 [0.000, 1.000], mean observation: 0.373 [-1.871, 2.670], mean_best_reward: --\n",
      " 94304/100000: episode: 2034, duration: 0.015s, episode steps: 32, steps per second: 2201, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.060 [-1.444, 0.659], mean_best_reward: --\n",
      " 94337/100000: episode: 2035, duration: 0.015s, episode steps: 33, steps per second: 2220, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: 0.075 [-0.661, 1.697], mean_best_reward: --\n",
      " 94380/100000: episode: 2036, duration: 0.020s, episode steps: 43, steps per second: 2202, episode reward: 43.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.465 [0.000, 1.000], mean observation: -0.117 [-0.922, 0.587], mean_best_reward: --\n",
      " 94403/100000: episode: 2037, duration: 0.011s, episode steps: 23, steps per second: 2112, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: -0.077 [-0.807, 0.401], mean_best_reward: --\n",
      " 94429/100000: episode: 2038, duration: 0.013s, episode steps: 26, steps per second: 2047, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: -0.100 [-1.449, 0.617], mean_best_reward: --\n",
      " 94490/100000: episode: 2039, duration: 0.028s, episode steps: 61, steps per second: 2218, episode reward: 61.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.508 [0.000, 1.000], mean observation: -0.010 [-1.221, 0.825], mean_best_reward: --\n",
      " 94546/100000: episode: 2040, duration: 0.023s, episode steps: 56, steps per second: 2391, episode reward: 56.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.536 [0.000, 1.000], mean observation: 0.204 [-0.473, 1.305], mean_best_reward: --\n",
      " 94676/100000: episode: 2041, duration: 0.064s, episode steps: 130, steps per second: 2018, episode reward: 130.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.531 [0.000, 1.000], mean observation: -0.220 [-2.663, 1.755], mean_best_reward: --\n",
      " 94746/100000: episode: 2042, duration: 0.032s, episode steps: 70, steps per second: 2220, episode reward: 70.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.529 [0.000, 1.000], mean observation: -0.027 [-2.186, 0.817], mean_best_reward: --\n",
      " 94787/100000: episode: 2043, duration: 0.020s, episode steps: 41, steps per second: 2027, episode reward: 41.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.537 [0.000, 1.000], mean observation: -0.063 [-1.525, 0.582], mean_best_reward: --\n",
      " 94926/100000: episode: 2044, duration: 0.056s, episode steps: 139, steps per second: 2463, episode reward: 139.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.489 [0.000, 1.000], mean observation: -0.234 [-1.545, 1.159], mean_best_reward: --\n",
      " 95011/100000: episode: 2045, duration: 0.036s, episode steps: 85, steps per second: 2385, episode reward: 85.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.482 [0.000, 1.000], mean observation: 0.093 [-0.743, 1.946], mean_best_reward: --\n",
      " 95053/100000: episode: 2046, duration: 0.018s, episode steps: 42, steps per second: 2331, episode reward: 42.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.452 [0.000, 1.000], mean observation: -0.098 [-0.861, 0.588], mean_best_reward: --\n",
      " 95102/100000: episode: 2047, duration: 0.021s, episode steps: 49, steps per second: 2348, episode reward: 49.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: -0.029 [-1.478, 0.936], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95145/100000: episode: 2048, duration: 0.019s, episode steps: 43, steps per second: 2251, episode reward: 43.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.512 [0.000, 1.000], mean observation: 0.108 [-0.557, 0.904], mean_best_reward: --\n",
      " 95327/100000: episode: 2049, duration: 0.090s, episode steps: 182, steps per second: 2023, episode reward: 182.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.270 [-2.254, 1.657], mean_best_reward: --\n",
      " 95433/100000: episode: 2050, duration: 0.045s, episode steps: 106, steps per second: 2342, episode reward: 106.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.472 [0.000, 1.000], mean observation: -0.116 [-1.119, 0.651], mean_best_reward: --\n",
      " 95464/100000: episode: 2051, duration: 0.014s, episode steps: 31, steps per second: 2141, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.548 [0.000, 1.000], mean observation: 0.109 [-0.372, 0.751], mean_best_reward: 152.000000\n",
      " 95546/100000: episode: 2052, duration: 0.034s, episode steps: 82, steps per second: 2425, episode reward: 82.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: -0.119 [-1.334, 0.980], mean_best_reward: --\n",
      " 95675/100000: episode: 2053, duration: 0.066s, episode steps: 129, steps per second: 1961, episode reward: 129.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: -0.145 [-1.534, 1.325], mean_best_reward: --\n",
      " 95802/100000: episode: 2054, duration: 0.054s, episode steps: 127, steps per second: 2357, episode reward: 127.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.472 [0.000, 1.000], mean observation: -0.084 [-1.988, 1.178], mean_best_reward: --\n",
      " 95904/100000: episode: 2055, duration: 0.042s, episode steps: 102, steps per second: 2423, episode reward: 102.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.115 [-1.351, 1.135], mean_best_reward: --\n",
      " 95940/100000: episode: 2056, duration: 0.018s, episode steps: 36, steps per second: 2041, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.528 [0.000, 1.000], mean observation: -0.092 [-1.505, 0.579], mean_best_reward: --\n",
      " 96041/100000: episode: 2057, duration: 0.043s, episode steps: 101, steps per second: 2371, episode reward: 101.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.564 [0.000, 1.000], mean observation: 0.262 [-2.133, 2.617], mean_best_reward: --\n",
      " 96060/100000: episode: 2058, duration: 0.010s, episode steps: 19, steps per second: 1922, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.632 [0.000, 1.000], mean observation: -0.058 [-1.796, 1.015], mean_best_reward: --\n",
      " 96176/100000: episode: 2059, duration: 0.055s, episode steps: 116, steps per second: 2114, episode reward: 116.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.517 [0.000, 1.000], mean observation: 0.157 [-1.399, 1.746], mean_best_reward: --\n",
      " 96299/100000: episode: 2060, duration: 0.055s, episode steps: 123, steps per second: 2228, episode reward: 123.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: 0.102 [-1.123, 0.947], mean_best_reward: --\n",
      " 96429/100000: episode: 2061, duration: 0.053s, episode steps: 130, steps per second: 2460, episode reward: 130.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.042 [-0.897, 1.276], mean_best_reward: --\n",
      " 96518/100000: episode: 2062, duration: 0.037s, episode steps: 89, steps per second: 2430, episode reward: 89.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.494 [0.000, 1.000], mean observation: -0.132 [-1.094, 0.976], mean_best_reward: --\n",
      " 96659/100000: episode: 2063, duration: 0.059s, episode steps: 141, steps per second: 2387, episode reward: 141.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.496 [0.000, 1.000], mean observation: -0.078 [-0.924, 1.078], mean_best_reward: --\n",
      " 96728/100000: episode: 2064, duration: 0.038s, episode steps: 69, steps per second: 1799, episode reward: 69.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.464 [0.000, 1.000], mean observation: -0.140 [-1.663, 1.273], mean_best_reward: --\n",
      " 96755/100000: episode: 2065, duration: 0.014s, episode steps: 27, steps per second: 1971, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.444 [0.000, 1.000], mean observation: 0.037 [-1.125, 1.664], mean_best_reward: --\n",
      " 96934/100000: episode: 2066, duration: 0.074s, episode steps: 179, steps per second: 2433, episode reward: 179.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.492 [0.000, 1.000], mean observation: -0.066 [-1.121, 0.926], mean_best_reward: --\n",
      " 96986/100000: episode: 2067, duration: 0.023s, episode steps: 52, steps per second: 2303, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.519 [0.000, 1.000], mean observation: -0.093 [-1.812, 0.614], mean_best_reward: --\n",
      " 97053/100000: episode: 2068, duration: 0.028s, episode steps: 67, steps per second: 2362, episode reward: 67.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.463 [0.000, 1.000], mean observation: -0.257 [-1.491, 0.472], mean_best_reward: --\n",
      " 97096/100000: episode: 2069, duration: 0.020s, episode steps: 43, steps per second: 2104, episode reward: 43.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.535 [0.000, 1.000], mean observation: -0.144 [-2.063, 0.635], mean_best_reward: --\n",
      " 97143/100000: episode: 2070, duration: 0.034s, episode steps: 47, steps per second: 1383, episode reward: 47.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.532 [0.000, 1.000], mean observation: 0.074 [-1.472, 1.500], mean_best_reward: --\n",
      " 97254/100000: episode: 2071, duration: 0.053s, episode steps: 111, steps per second: 2084, episode reward: 111.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.477 [0.000, 1.000], mean observation: -0.079 [-1.169, 0.958], mean_best_reward: --\n",
      " 97357/100000: episode: 2072, duration: 0.047s, episode steps: 103, steps per second: 2185, episode reward: 103.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.466 [0.000, 1.000], mean observation: -0.341 [-2.007, 0.896], mean_best_reward: --\n",
      " 97546/100000: episode: 2073, duration: 0.077s, episode steps: 189, steps per second: 2450, episode reward: 189.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.519 [0.000, 1.000], mean observation: 0.022 [-1.066, 1.853], mean_best_reward: --\n",
      " 97557/100000: episode: 2074, duration: 0.006s, episode steps: 11, steps per second: 1782, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.909 [0.000, 1.000], mean observation: -0.133 [-2.896, 1.783], mean_best_reward: --\n",
      " 97633/100000: episode: 2075, duration: 0.048s, episode steps: 76, steps per second: 1569, episode reward: 76.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.487 [0.000, 1.000], mean observation: 0.063 [-0.779, 0.812], mean_best_reward: --\n",
      " 97658/100000: episode: 2076, duration: 0.012s, episode steps: 25, steps per second: 2009, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: -0.079 [-1.027, 0.542], mean_best_reward: --\n",
      " 97714/100000: episode: 2077, duration: 0.024s, episode steps: 56, steps per second: 2296, episode reward: 56.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.482 [0.000, 1.000], mean observation: -0.055 [-0.978, 0.614], mean_best_reward: --\n",
      " 97876/100000: episode: 2078, duration: 0.066s, episode steps: 162, steps per second: 2443, episode reward: 162.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.494 [0.000, 1.000], mean observation: 0.075 [-0.869, 1.993], mean_best_reward: --\n",
      " 97932/100000: episode: 2079, duration: 0.028s, episode steps: 56, steps per second: 1984, episode reward: 56.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.482 [0.000, 1.000], mean observation: -0.095 [-1.026, 0.520], mean_best_reward: --\n",
      " 98038/100000: episode: 2080, duration: 0.047s, episode steps: 106, steps per second: 2261, episode reward: 106.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.112 [-1.334, 1.132], mean_best_reward: --\n",
      " 98080/100000: episode: 2081, duration: 0.020s, episode steps: 42, steps per second: 2111, episode reward: 42.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.452 [0.000, 1.000], mean observation: -0.143 [-0.870, 0.439], mean_best_reward: --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 98248/100000: episode: 2082, duration: 0.088s, episode steps: 168, steps per second: 1914, episode reward: 168.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.494 [0.000, 1.000], mean observation: 0.143 [-0.884, 1.105], mean_best_reward: --\n",
      " 98322/100000: episode: 2083, duration: 0.031s, episode steps: 74, steps per second: 2398, episode reward: 74.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.459 [0.000, 1.000], mean observation: -0.176 [-1.061, 0.723], mean_best_reward: --\n",
      " 98435/100000: episode: 2084, duration: 0.046s, episode steps: 113, steps per second: 2481, episode reward: 113.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: 0.005 [-1.535, 1.628], mean_best_reward: --\n",
      " 98603/100000: episode: 2085, duration: 0.068s, episode steps: 168, steps per second: 2474, episode reward: 168.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.554 [0.000, 1.000], mean observation: 0.102 [-3.013, 3.387], mean_best_reward: --\n",
      " 98622/100000: episode: 2086, duration: 0.010s, episode steps: 19, steps per second: 1951, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: -0.084 [-1.031, 0.566], mean_best_reward: --\n",
      " 98815/100000: episode: 2087, duration: 0.094s, episode steps: 193, steps per second: 2060, episode reward: 193.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.508 [0.000, 1.000], mean observation: -0.029 [-1.173, 1.458], mean_best_reward: --\n",
      " 98852/100000: episode: 2088, duration: 0.019s, episode steps: 37, steps per second: 1904, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.432 [0.000, 1.000], mean observation: -0.209 [-1.138, 0.555], mean_best_reward: --\n",
      " 98958/100000: episode: 2089, duration: 0.043s, episode steps: 106, steps per second: 2437, episode reward: 106.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.491 [0.000, 1.000], mean observation: -0.109 [-1.181, 1.189], mean_best_reward: --\n",
      " 99108/100000: episode: 2090, duration: 0.060s, episode steps: 150, steps per second: 2497, episode reward: 150.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.513 [0.000, 1.000], mean observation: -0.152 [-1.525, 1.309], mean_best_reward: --\n",
      " 99220/100000: episode: 2091, duration: 0.045s, episode steps: 112, steps per second: 2480, episode reward: 112.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.509 [0.000, 1.000], mean observation: 0.098 [-1.400, 1.158], mean_best_reward: --\n",
      " 99389/100000: episode: 2092, duration: 0.088s, episode steps: 169, steps per second: 1924, episode reward: 169.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.491 [0.000, 1.000], mean observation: -0.236 [-1.424, 0.957], mean_best_reward: --\n",
      " 99519/100000: episode: 2093, duration: 0.054s, episode steps: 130, steps per second: 2394, episode reward: 130.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.023 [-1.623, 1.031], mean_best_reward: --\n",
      " 99628/100000: episode: 2094, duration: 0.047s, episode steps: 109, steps per second: 2339, episode reward: 109.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.459 [0.000, 1.000], mean observation: -0.138 [-1.916, 1.297], mean_best_reward: --\n",
      " 99800/100000: episode: 2095, duration: 0.069s, episode steps: 172, steps per second: 2500, episode reward: 172.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.477 [0.000, 1.000], mean observation: -0.253 [-1.666, 0.868], mean_best_reward: --\n",
      " 99880/100000: episode: 2096, duration: 0.038s, episode steps: 80, steps per second: 2107, episode reward: 80.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.425 [0.000, 1.000], mean observation: -0.158 [-2.346, 2.597], mean_best_reward: --\n",
      " 99909/100000: episode: 2097, duration: 0.023s, episode steps: 29, steps per second: 1258, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.586 [0.000, 1.000], mean observation: -0.075 [-2.099, 1.044], mean_best_reward: --\n",
      " 99962/100000: episode: 2098, duration: 0.023s, episode steps: 53, steps per second: 2277, episode reward: 53.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.509 [0.000, 1.000], mean observation: -0.109 [-1.704, 0.776], mean_best_reward: --\n",
      "done, took 52.471 seconds\n",
      "Testing for 5 episodes ...\n",
      "Episode 1: reward: 172.000, steps: 172\n",
      "Episode 2: reward: 143.000, steps: 143\n",
      "Episode 3: reward: 181.000, steps: 181\n",
      "Episode 4: reward: 200.000, steps: 200\n",
      "Episode 5: reward: 200.000, steps: 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f22bef896d8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.cem import CEMAgent\n",
    "from rl.memory import EpisodeParameterMemory\n",
    "\n",
    "ENV_NAME = 'CartPole-v0'\n",
    "\n",
    "\n",
    "# Get the environment and extract the number of actions.\n",
    "env = gym.make(ENV_NAME)\n",
    "np.random.seed(123)\n",
    "env.seed(123)\n",
    "\n",
    "nb_actions = env.action_space.n\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "\n",
    "# Option 1 : Simple model\n",
    "# model = Sequential()\n",
    "# model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "# model.add(Dense(nb_actions))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "# Option 2: deep network\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
    "# even the metrics!\n",
    "memory = EpisodeParameterMemory(limit=1000, window_length=1)\n",
    "\n",
    "cem = CEMAgent(model=model, nb_actions=nb_actions, memory=memory,\n",
    "               batch_size=50, nb_steps_warmup=2000, train_interval=50, elite_frac=0.05)\n",
    "cem.compile()\n",
    "\n",
    "# Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# Ctrl + C.\n",
    "cem.fit(env, nb_steps=100000, visualize=False, verbose=2)\n",
    "\n",
    "# After training is done, we save the best weights.\n",
    "cem.save_weights('./modelos_Q5/cem_{}_params.h5f'.format(ENV_NAME), overwrite=True)\n",
    "\n",
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "cem.test(env, nb_episodes=5, visualize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodo 2: Deep Q Learning\n",
    "\n",
    "### Desempenho\n",
    "\n",
    "* Para uma medida mais justa, o treinamento desta rede foi encerrado proximo do decorrer de 52 segundos \n",
    "    * Tempo de treinamento: 54.599 seconds\n",
    "    * Recompensas:\n",
    "\n",
    "        * Episode 1: reward: 200.000, steps: 200\n",
    "        * Episode 2: reward: 200.000, steps: 200\n",
    "        * Episode 3: reward: 177.000, steps: 177\n",
    "        * Episode 4: reward: 200.000, steps: 200\n",
    "        * Episode 5: reward: 200.000, steps: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 658\n",
      "Trainable params: 658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training for 50000 steps ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pupio/anaconda3/lib/python3.7/site-packages/rl/memory.py:39: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
      "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    31/50000: episode: 1, duration: 1.225s, episode steps: 31, steps per second: 25, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.419 [0.000, 1.000], mean observation: 0.013 [-1.185, 1.776], loss: 0.461355, mean_absolute_error: 0.519542, mean_q: 0.094742\n",
      "    44/50000: episode: 2, duration: 0.036s, episode steps: 13, steps per second: 365, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.692 [0.000, 1.000], mean observation: -0.069 [-1.867, 1.224], loss: 0.353852, mean_absolute_error: 0.544188, mean_q: 0.290045\n",
      "    64/50000: episode: 3, duration: 0.053s, episode steps: 20, steps per second: 378, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.550 [0.000, 1.000], mean observation: -0.070 [-1.375, 0.833], loss: 0.228019, mean_absolute_error: 0.555019, mean_q: 0.492115\n",
      "    83/50000: episode: 4, duration: 0.050s, episode steps: 19, steps per second: 377, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.421 [0.000, 1.000], mean observation: 0.074 [-0.817, 1.505], loss: 0.117900, mean_absolute_error: 0.608295, mean_q: 0.826718\n",
      "    98/50000: episode: 5, duration: 0.043s, episode steps: 15, steps per second: 347, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.090 [-1.368, 0.825], loss: 0.061369, mean_absolute_error: 0.672499, mean_q: 1.141347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pupio/anaconda3/lib/python3.7/site-packages/rl/memory.py:39: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
      "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   114/50000: episode: 6, duration: 0.059s, episode steps: 16, steps per second: 270, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.069 [-2.711, 1.766], loss: 0.035653, mean_absolute_error: 0.724693, mean_q: 1.317960\n",
      "   128/50000: episode: 7, duration: 0.039s, episode steps: 14, steps per second: 362, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: 0.111 [-0.934, 1.483], loss: 0.033730, mean_absolute_error: 0.757089, mean_q: 1.419276\n",
      "   151/50000: episode: 8, duration: 0.061s, episode steps: 23, steps per second: 375, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.304 [0.000, 1.000], mean observation: 0.050 [-1.760, 2.679], loss: 0.020377, mean_absolute_error: 0.805427, mean_q: 1.601638\n",
      "   162/50000: episode: 9, duration: 0.030s, episode steps: 11, steps per second: 365, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.273 [0.000, 1.000], mean observation: 0.133 [-1.133, 1.962], loss: 0.041706, mean_absolute_error: 0.891977, mean_q: 1.767968\n",
      "   175/50000: episode: 10, duration: 0.036s, episode steps: 13, steps per second: 365, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.769 [0.000, 1.000], mean observation: -0.118 [-2.439, 1.549], loss: 0.032130, mean_absolute_error: 0.928541, mean_q: 1.847007\n",
      "   208/50000: episode: 11, duration: 0.098s, episode steps: 33, steps per second: 337, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.394 [0.000, 1.000], mean observation: 0.009 [-1.580, 2.195], loss: 0.045879, mean_absolute_error: 1.005387, mean_q: 2.020157\n",
      "   223/50000: episode: 12, duration: 0.042s, episode steps: 15, steps per second: 360, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.096 [-1.845, 1.032], loss: 0.039296, mean_absolute_error: 1.114288, mean_q: 2.262856\n",
      "   235/50000: episode: 13, duration: 0.032s, episode steps: 12, steps per second: 375, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.250 [0.000, 1.000], mean observation: 0.124 [-1.329, 2.154], loss: 0.063442, mean_absolute_error: 1.169860, mean_q: 2.330529\n",
      "   249/50000: episode: 14, duration: 0.038s, episode steps: 14, steps per second: 372, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.357 [0.000, 1.000], mean observation: 0.103 [-0.965, 1.601], loss: 0.052925, mean_absolute_error: 1.219966, mean_q: 2.478961\n",
      "   264/50000: episode: 15, duration: 0.040s, episode steps: 15, steps per second: 373, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.086 [-1.187, 2.013], loss: 0.052247, mean_absolute_error: 1.269652, mean_q: 2.584885\n",
      "   289/50000: episode: 16, duration: 0.083s, episode steps: 25, steps per second: 302, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.360 [0.000, 1.000], mean observation: 0.054 [-1.365, 2.263], loss: 0.090199, mean_absolute_error: 1.371153, mean_q: 2.739742\n",
      "   314/50000: episode: 17, duration: 0.067s, episode steps: 25, steps per second: 373, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.360 [0.000, 1.000], mean observation: 0.019 [-1.350, 2.101], loss: 0.134530, mean_absolute_error: 1.496010, mean_q: 2.962636\n",
      "   335/50000: episode: 18, duration: 0.057s, episode steps: 21, steps per second: 369, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: 0.057 [-0.984, 1.414], loss: 0.099708, mean_absolute_error: 1.618882, mean_q: 3.227309\n",
      "   350/50000: episode: 19, duration: 0.042s, episode steps: 15, steps per second: 361, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.064 [-1.407, 0.815], loss: 0.098449, mean_absolute_error: 1.676065, mean_q: 3.340661\n",
      "   371/50000: episode: 20, duration: 0.064s, episode steps: 21, steps per second: 328, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: 0.087 [-0.788, 1.469], loss: 0.134796, mean_absolute_error: 1.756067, mean_q: 3.455331\n",
      "   385/50000: episode: 21, duration: 0.042s, episode steps: 14, steps per second: 336, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.357 [0.000, 1.000], mean observation: 0.131 [-0.967, 1.801], loss: 0.118585, mean_absolute_error: 1.840794, mean_q: 3.635452\n",
      "   400/50000: episode: 22, duration: 0.041s, episode steps: 15, steps per second: 363, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.733 [0.000, 1.000], mean observation: -0.085 [-2.227, 1.361], loss: 0.179658, mean_absolute_error: 1.909586, mean_q: 3.703051\n",
      "   415/50000: episode: 23, duration: 0.040s, episode steps: 15, steps per second: 373, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.400 [0.000, 1.000], mean observation: 0.105 [-0.949, 1.714], loss: 0.164580, mean_absolute_error: 1.962535, mean_q: 3.816557\n",
      "   427/50000: episode: 24, duration: 0.032s, episode steps: 12, steps per second: 374, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.167 [0.000, 1.000], mean observation: 0.135 [-1.555, 2.601], loss: 0.189227, mean_absolute_error: 2.000431, mean_q: 3.903291\n",
      "   439/50000: episode: 25, duration: 0.032s, episode steps: 12, steps per second: 374, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.125 [-2.249, 1.358], loss: 0.211446, mean_absolute_error: 2.111784, mean_q: 4.144042\n",
      "   451/50000: episode: 26, duration: 0.054s, episode steps: 12, steps per second: 223, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.417 [0.000, 1.000], mean observation: 0.098 [-0.773, 1.402], loss: 0.176919, mean_absolute_error: 2.131103, mean_q: 4.032674\n",
      "   466/50000: episode: 27, duration: 0.048s, episode steps: 15, steps per second: 311, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.074 [-0.997, 1.708], loss: 0.247464, mean_absolute_error: 2.207115, mean_q: 4.220091\n",
      "   485/50000: episode: 28, duration: 0.098s, episode steps: 19, steps per second: 194, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.421 [0.000, 1.000], mean observation: 0.069 [-0.653, 1.389], loss: 0.306607, mean_absolute_error: 2.262642, mean_q: 4.306255\n",
      "   495/50000: episode: 29, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.900 [0.000, 1.000], mean observation: -0.112 [-2.543, 1.614], loss: 0.254404, mean_absolute_error: 2.322938, mean_q: 4.392073\n",
      "   508/50000: episode: 30, duration: 0.054s, episode steps: 13, steps per second: 242, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.231 [0.000, 1.000], mean observation: 0.119 [-1.333, 2.349], loss: 0.259908, mean_absolute_error: 2.384567, mean_q: 4.491700\n",
      "   516/50000: episode: 31, duration: 0.025s, episode steps: 8, steps per second: 320, episode reward: 8.000, mean reward: 1.000 [1.000, 1.000], mean action: 1.000 [1.000, 1.000], mean observation: -0.147 [-2.506, 1.535], loss: 0.236296, mean_absolute_error: 2.379931, mean_q: 4.549714\n",
      "   541/50000: episode: 32, duration: 0.072s, episode steps: 25, steps per second: 347, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.440 [0.000, 1.000], mean observation: 0.034 [-1.026, 1.636], loss: 0.215561, mean_absolute_error: 2.479553, mean_q: 4.785542\n",
      "   550/50000: episode: 33, duration: 0.025s, episode steps: 9, steps per second: 361, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.111 [0.000, 1.000], mean observation: 0.140 [-1.541, 2.425], loss: 0.330172, mean_absolute_error: 2.517942, mean_q: 4.760935\n",
      "   561/50000: episode: 34, duration: 0.031s, episode steps: 11, steps per second: 358, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.273 [0.000, 1.000], mean observation: 0.128 [-0.937, 1.766], loss: 0.233457, mean_absolute_error: 2.595241, mean_q: 4.945133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   589/50000: episode: 35, duration: 0.087s, episode steps: 28, steps per second: 321, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.571 [0.000, 1.000], mean observation: -0.043 [-1.673, 0.963], loss: 0.241473, mean_absolute_error: 2.648523, mean_q: 5.084620\n",
      "   601/50000: episode: 36, duration: 0.036s, episode steps: 12, steps per second: 332, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.124 [-2.069, 1.161], loss: 0.202372, mean_absolute_error: 2.699294, mean_q: 5.216860\n",
      "   622/50000: episode: 37, duration: 0.057s, episode steps: 21, steps per second: 367, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.056 [-1.355, 2.195], loss: 0.271322, mean_absolute_error: 2.802674, mean_q: 5.372855\n",
      "   650/50000: episode: 38, duration: 0.076s, episode steps: 28, steps per second: 371, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.464 [0.000, 1.000], mean observation: 0.062 [-0.772, 1.454], loss: 0.334265, mean_absolute_error: 2.871283, mean_q: 5.423715\n",
      "   660/50000: episode: 39, duration: 0.029s, episode steps: 10, steps per second: 349, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.100 [0.000, 1.000], mean observation: 0.127 [-1.568, 2.471], loss: 0.282534, mean_absolute_error: 2.983600, mean_q: 5.707385\n",
      "   675/50000: episode: 40, duration: 0.050s, episode steps: 15, steps per second: 297, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.089 [-1.001, 1.802], loss: 0.289325, mean_absolute_error: 2.994577, mean_q: 5.673856\n",
      "   690/50000: episode: 41, duration: 0.041s, episode steps: 15, steps per second: 363, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: 0.118 [-0.785, 1.381], loss: 0.339835, mean_absolute_error: 2.987542, mean_q: 5.578089\n",
      "   701/50000: episode: 42, duration: 0.031s, episode steps: 11, steps per second: 350, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.364 [0.000, 1.000], mean observation: 0.103 [-1.025, 1.496], loss: 0.261863, mean_absolute_error: 3.052586, mean_q: 5.779012\n",
      "   734/50000: episode: 43, duration: 0.087s, episode steps: 33, steps per second: 378, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.040 [-1.028, 0.632], loss: 0.321903, mean_absolute_error: 3.128393, mean_q: 5.895103\n",
      "   746/50000: episode: 44, duration: 0.033s, episode steps: 12, steps per second: 359, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.250 [0.000, 1.000], mean observation: 0.126 [-1.332, 2.188], loss: 0.341389, mean_absolute_error: 3.241286, mean_q: 6.156520\n",
      "   789/50000: episode: 45, duration: 0.127s, episode steps: 43, steps per second: 339, episode reward: 43.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: 0.075 [-0.564, 1.203], loss: 0.271791, mean_absolute_error: 3.270320, mean_q: 6.269864\n",
      "   814/50000: episode: 46, duration: 0.113s, episode steps: 25, steps per second: 221, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.640 [0.000, 1.000], mean observation: -0.016 [-2.419, 1.600], loss: 0.261353, mean_absolute_error: 3.423017, mean_q: 6.619359\n",
      "   824/50000: episode: 47, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.100 [0.000, 1.000], mean observation: 0.163 [-1.528, 2.555], loss: 0.284775, mean_absolute_error: 3.433893, mean_q: 6.625168\n",
      "   855/50000: episode: 48, duration: 0.104s, episode steps: 31, steps per second: 299, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.516 [0.000, 1.000], mean observation: -0.099 [-1.274, 0.388], loss: 0.240884, mean_absolute_error: 3.576533, mean_q: 6.964962\n",
      "   888/50000: episode: 49, duration: 0.087s, episode steps: 33, steps per second: 380, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: 0.069 [-0.615, 1.388], loss: 0.323315, mean_absolute_error: 3.679342, mean_q: 7.148987\n",
      "   911/50000: episode: 50, duration: 0.061s, episode steps: 23, steps per second: 374, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: -0.109 [-0.992, 0.386], loss: 0.235447, mean_absolute_error: 3.790928, mean_q: 7.405158\n",
      "   922/50000: episode: 51, duration: 0.030s, episode steps: 11, steps per second: 364, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.364 [0.000, 1.000], mean observation: 0.109 [-1.140, 1.829], loss: 0.507742, mean_absolute_error: 3.873657, mean_q: 7.510399\n",
      "   952/50000: episode: 52, duration: 0.093s, episode steps: 30, steps per second: 324, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.400 [0.000, 1.000], mean observation: -0.015 [-1.391, 1.883], loss: 0.316103, mean_absolute_error: 3.912264, mean_q: 7.619272\n",
      "   970/50000: episode: 53, duration: 0.056s, episode steps: 18, steps per second: 320, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.389 [0.000, 1.000], mean observation: 0.063 [-1.215, 1.828], loss: 0.303306, mean_absolute_error: 4.029776, mean_q: 7.891305\n",
      "   992/50000: episode: 54, duration: 0.096s, episode steps: 22, steps per second: 229, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: -0.082 [-1.327, 0.600], loss: 0.455836, mean_absolute_error: 4.092151, mean_q: 7.956999\n",
      "  1020/50000: episode: 55, duration: 0.111s, episode steps: 28, steps per second: 252, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: 0.083 [-0.791, 1.866], loss: 0.356097, mean_absolute_error: 4.181555, mean_q: 8.186027\n",
      "  1045/50000: episode: 56, duration: 0.094s, episode steps: 25, steps per second: 265, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: -0.096 [-1.222, 0.571], loss: 0.288878, mean_absolute_error: 4.282566, mean_q: 8.464334\n",
      "  1081/50000: episode: 57, duration: 0.115s, episode steps: 36, steps per second: 314, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.528 [0.000, 1.000], mean observation: 0.096 [-0.789, 1.077], loss: 0.307346, mean_absolute_error: 4.459482, mean_q: 8.838861\n",
      "  1166/50000: episode: 58, duration: 0.239s, episode steps: 85, steps per second: 355, episode reward: 85.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.482 [0.000, 1.000], mean observation: -0.150 [-1.077, 0.627], loss: 0.476878, mean_absolute_error: 4.679001, mean_q: 9.249437\n",
      "  1201/50000: episode: 59, duration: 0.102s, episode steps: 35, steps per second: 342, episode reward: 35.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.457 [0.000, 1.000], mean observation: -0.079 [-1.126, 0.742], loss: 0.610124, mean_absolute_error: 4.942023, mean_q: 9.790334\n",
      "  1261/50000: episode: 60, duration: 0.177s, episode steps: 60, steps per second: 340, episode reward: 60.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.533 [0.000, 1.000], mean observation: 0.121 [-0.701, 0.864], loss: 0.396858, mean_absolute_error: 5.170728, mean_q: 10.327708\n",
      "  1273/50000: episode: 61, duration: 0.034s, episode steps: 12, steps per second: 353, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.112 [-2.107, 1.355], loss: 0.718999, mean_absolute_error: 5.292295, mean_q: 10.561114\n",
      "  1329/50000: episode: 62, duration: 0.160s, episode steps: 56, steps per second: 350, episode reward: 56.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.482 [0.000, 1.000], mean observation: -0.175 [-1.044, 0.874], loss: 0.377284, mean_absolute_error: 5.424198, mean_q: 10.828726\n",
      "  1406/50000: episode: 63, duration: 0.214s, episode steps: 77, steps per second: 359, episode reward: 77.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.468 [0.000, 1.000], mean observation: -0.216 [-1.282, 1.043], loss: 0.562398, mean_absolute_error: 5.714887, mean_q: 11.387120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1495/50000: episode: 64, duration: 0.242s, episode steps: 89, steps per second: 367, episode reward: 89.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.483 [0.000, 1.000], mean observation: 0.089 [-0.836, 1.494], loss: 0.414305, mean_absolute_error: 6.014996, mean_q: 12.141092\n",
      "  1584/50000: episode: 65, duration: 0.242s, episode steps: 89, steps per second: 368, episode reward: 89.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.461 [0.000, 1.000], mean observation: -0.219 [-1.666, 0.627], loss: 0.608449, mean_absolute_error: 6.498116, mean_q: 13.026323\n",
      "  1667/50000: episode: 66, duration: 0.228s, episode steps: 83, steps per second: 364, episode reward: 83.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.446 [0.000, 1.000], mean observation: -0.295 [-1.815, 0.652], loss: 0.623735, mean_absolute_error: 6.817114, mean_q: 13.736756\n",
      "  1788/50000: episode: 67, duration: 0.321s, episode steps: 121, steps per second: 377, episode reward: 121.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.496 [0.000, 1.000], mean observation: -0.143 [-1.266, 0.815], loss: 0.549128, mean_absolute_error: 7.267460, mean_q: 14.680163\n",
      "  1937/50000: episode: 68, duration: 0.391s, episode steps: 149, steps per second: 381, episode reward: 149.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.256 [-2.177, 0.858], loss: 0.688132, mean_absolute_error: 7.844137, mean_q: 15.894711\n",
      "  2045/50000: episode: 69, duration: 0.297s, episode steps: 108, steps per second: 364, episode reward: 108.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.463 [0.000, 1.000], mean observation: -0.295 [-1.629, 0.845], loss: 0.673409, mean_absolute_error: 8.438729, mean_q: 17.099531\n",
      "  2185/50000: episode: 70, duration: 0.367s, episode steps: 140, steps per second: 381, episode reward: 140.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.464 [0.000, 1.000], mean observation: -0.283 [-1.808, 1.138], loss: 0.773433, mean_absolute_error: 9.070422, mean_q: 18.369490\n",
      "  2325/50000: episode: 71, duration: 0.375s, episode steps: 140, steps per second: 373, episode reward: 140.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.479 [0.000, 1.000], mean observation: -0.181 [-1.136, 0.712], loss: 0.728255, mean_absolute_error: 9.564758, mean_q: 19.439516\n",
      "  2514/50000: episode: 72, duration: 0.528s, episode steps: 189, steps per second: 358, episode reward: 189.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: -0.330 [-2.334, 0.796], loss: 0.830591, mean_absolute_error: 10.374153, mean_q: 21.116970\n",
      "  2662/50000: episode: 73, duration: 0.523s, episode steps: 148, steps per second: 283, episode reward: 148.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.466 [0.000, 1.000], mean observation: -0.412 [-2.299, 1.004], loss: 0.802333, mean_absolute_error: 10.998939, mean_q: 22.476866\n",
      "  2862/50000: episode: 74, duration: 0.570s, episode steps: 200, steps per second: 351, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.147 [-1.278, 0.911], loss: 0.882115, mean_absolute_error: 11.818887, mean_q: 24.163305\n",
      "  3033/50000: episode: 75, duration: 0.482s, episode steps: 171, steps per second: 355, episode reward: 171.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.468 [0.000, 1.000], mean observation: -0.374 [-2.442, 0.718], loss: 1.367796, mean_absolute_error: 12.741117, mean_q: 25.870836\n",
      "  3188/50000: episode: 76, duration: 0.448s, episode steps: 155, steps per second: 346, episode reward: 155.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.458 [0.000, 1.000], mean observation: -0.403 [-2.514, 0.993], loss: 1.163329, mean_absolute_error: 13.346174, mean_q: 27.213266\n",
      "  3332/50000: episode: 77, duration: 0.404s, episode steps: 144, steps per second: 356, episode reward: 144.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.451 [0.000, 1.000], mean observation: -0.417 [-2.535, 0.704], loss: 1.254380, mean_absolute_error: 14.045183, mean_q: 28.615805\n",
      "  3503/50000: episode: 78, duration: 0.472s, episode steps: 171, steps per second: 363, episode reward: 171.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.352 [-2.517, 0.842], loss: 1.232498, mean_absolute_error: 14.742359, mean_q: 29.958549\n",
      "  3648/50000: episode: 79, duration: 0.399s, episode steps: 145, steps per second: 364, episode reward: 145.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.423 [-2.442, 0.724], loss: 1.451209, mean_absolute_error: 15.245832, mean_q: 31.008099\n",
      "  3796/50000: episode: 80, duration: 0.393s, episode steps: 148, steps per second: 377, episode reward: 148.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.459 [0.000, 1.000], mean observation: -0.420 [-2.433, 0.948], loss: 1.111073, mean_absolute_error: 15.943752, mean_q: 32.403503\n",
      "  3965/50000: episode: 81, duration: 0.438s, episode steps: 169, steps per second: 386, episode reward: 169.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.365 [-2.410, 0.720], loss: 1.456718, mean_absolute_error: 16.454315, mean_q: 33.491421\n",
      "  4111/50000: episode: 82, duration: 0.392s, episode steps: 146, steps per second: 373, episode reward: 146.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.459 [0.000, 1.000], mean observation: -0.414 [-2.408, 0.864], loss: 1.448249, mean_absolute_error: 17.130146, mean_q: 34.821304\n",
      "  4257/50000: episode: 83, duration: 0.385s, episode steps: 146, steps per second: 379, episode reward: 146.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.459 [0.000, 1.000], mean observation: -0.416 [-2.428, 0.776], loss: 1.481768, mean_absolute_error: 17.611713, mean_q: 35.676510\n",
      "  4424/50000: episode: 84, duration: 0.442s, episode steps: 167, steps per second: 378, episode reward: 167.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.461 [0.000, 1.000], mean observation: -0.372 [-2.415, 1.035], loss: 1.579712, mean_absolute_error: 18.234556, mean_q: 37.174210\n",
      "  4624/50000: episode: 85, duration: 0.527s, episode steps: 200, steps per second: 379, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.268 [-2.086, 0.807], loss: 1.459660, mean_absolute_error: 18.997736, mean_q: 38.544380\n",
      "  4789/50000: episode: 86, duration: 0.431s, episode steps: 165, steps per second: 383, episode reward: 165.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.377 [-2.417, 0.840], loss: 1.014396, mean_absolute_error: 19.678368, mean_q: 39.996872\n",
      "  4973/50000: episode: 87, duration: 0.486s, episode steps: 184, steps per second: 379, episode reward: 184.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.473 [0.000, 1.000], mean observation: -0.345 [-2.413, 0.797], loss: 1.700648, mean_absolute_error: 20.203997, mean_q: 40.966660\n",
      "  5135/50000: episode: 88, duration: 0.428s, episode steps: 162, steps per second: 378, episode reward: 162.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.463 [0.000, 1.000], mean observation: -0.387 [-2.411, 0.926], loss: 1.592420, mean_absolute_error: 20.783157, mean_q: 42.141022\n",
      "  5307/50000: episode: 89, duration: 0.448s, episode steps: 172, steps per second: 384, episode reward: 172.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.465 [0.000, 1.000], mean observation: -0.365 [-2.433, 0.810], loss: 1.644437, mean_absolute_error: 21.315998, mean_q: 43.213684\n",
      "  5460/50000: episode: 90, duration: 0.406s, episode steps: 153, steps per second: 377, episode reward: 153.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.458 [0.000, 1.000], mean observation: -0.399 [-2.403, 0.772], loss: 1.376834, mean_absolute_error: 21.886728, mean_q: 44.407448\n",
      "  5635/50000: episode: 91, duration: 0.467s, episode steps: 175, steps per second: 374, episode reward: 175.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: -0.354 [-2.409, 0.878], loss: 1.657690, mean_absolute_error: 22.287886, mean_q: 45.168259\n",
      "  5804/50000: episode: 92, duration: 0.444s, episode steps: 169, steps per second: 380, episode reward: 169.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.361 [-2.406, 0.759], loss: 1.607210, mean_absolute_error: 22.681681, mean_q: 46.017075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5959/50000: episode: 93, duration: 0.403s, episode steps: 155, steps per second: 384, episode reward: 155.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.398 [-2.405, 0.692], loss: 1.816896, mean_absolute_error: 23.265728, mean_q: 47.068893\n",
      "  6131/50000: episode: 94, duration: 0.452s, episode steps: 172, steps per second: 380, episode reward: 172.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.465 [0.000, 1.000], mean observation: -0.372 [-2.413, 0.945], loss: 1.448987, mean_absolute_error: 23.619249, mean_q: 47.811852\n",
      "  6313/50000: episode: 95, duration: 0.475s, episode steps: 182, steps per second: 383, episode reward: 182.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.516 [0.000, 1.000], mean observation: 0.142 [-0.821, 1.128], loss: 1.311942, mean_absolute_error: 24.178026, mean_q: 49.051071\n",
      "  6513/50000: episode: 96, duration: 0.521s, episode steps: 200, steps per second: 384, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.260 [-2.160, 1.095], loss: 2.793397, mean_absolute_error: 24.950834, mean_q: 50.301483\n",
      "  6672/50000: episode: 97, duration: 0.416s, episode steps: 159, steps per second: 382, episode reward: 159.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.465 [0.000, 1.000], mean observation: -0.388 [-2.402, 1.105], loss: 1.780401, mean_absolute_error: 25.266548, mean_q: 51.144051\n",
      "  6872/50000: episode: 98, duration: 0.524s, episode steps: 200, steps per second: 382, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.226 [-1.993, 0.772], loss: 1.724367, mean_absolute_error: 25.870386, mean_q: 52.282284\n",
      "  7049/50000: episode: 99, duration: 0.462s, episode steps: 177, steps per second: 383, episode reward: 177.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.361 [-2.430, 1.149], loss: 1.640354, mean_absolute_error: 26.238279, mean_q: 53.101997\n",
      "  7202/50000: episode: 100, duration: 0.401s, episode steps: 153, steps per second: 382, episode reward: 153.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.412 [-2.426, 0.778], loss: 2.278156, mean_absolute_error: 26.629190, mean_q: 53.793823\n",
      "  7373/50000: episode: 101, duration: 0.452s, episode steps: 171, steps per second: 378, episode reward: 171.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.468 [0.000, 1.000], mean observation: -0.371 [-2.408, 0.767], loss: 2.070708, mean_absolute_error: 26.752678, mean_q: 54.150471\n",
      "  7561/50000: episode: 102, duration: 0.490s, episode steps: 188, steps per second: 384, episode reward: 188.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.473 [0.000, 1.000], mean observation: -0.338 [-2.419, 0.922], loss: 2.259596, mean_absolute_error: 27.360697, mean_q: 55.229439\n",
      "  7761/50000: episode: 103, duration: 0.519s, episode steps: 200, steps per second: 385, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.320 [-2.430, 1.069], loss: 1.159326, mean_absolute_error: 27.518867, mean_q: 55.700897\n",
      "  7961/50000: episode: 104, duration: 0.522s, episode steps: 200, steps per second: 383, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.193 [-1.835, 1.375], loss: 2.061263, mean_absolute_error: 27.985577, mean_q: 56.510986\n",
      "  8161/50000: episode: 105, duration: 0.523s, episode steps: 200, steps per second: 383, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.202 [-2.066, 1.124], loss: 2.153499, mean_absolute_error: 28.390234, mean_q: 57.310963\n",
      "  8326/50000: episode: 106, duration: 0.437s, episode steps: 165, steps per second: 378, episode reward: 165.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.461 [0.000, 1.000], mean observation: -0.379 [-2.421, 1.050], loss: 1.765949, mean_absolute_error: 28.849110, mean_q: 58.152641\n",
      "  8526/50000: episode: 107, duration: 0.522s, episode steps: 200, steps per second: 383, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.095 [-1.283, 1.118], loss: 1.860079, mean_absolute_error: 29.399561, mean_q: 59.418289\n",
      "  8726/50000: episode: 108, duration: 0.526s, episode steps: 200, steps per second: 380, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.172 [-1.618, 0.785], loss: 2.564400, mean_absolute_error: 29.649263, mean_q: 59.864708\n",
      "  8890/50000: episode: 109, duration: 0.429s, episode steps: 164, steps per second: 382, episode reward: 164.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.518 [0.000, 1.000], mean observation: 0.140 [-0.969, 1.130], loss: 1.839275, mean_absolute_error: 30.273130, mean_q: 61.104332\n",
      "  9051/50000: episode: 110, duration: 0.424s, episode steps: 161, steps per second: 380, episode reward: 161.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.460 [0.000, 1.000], mean observation: -0.391 [-2.412, 0.833], loss: 2.248947, mean_absolute_error: 30.510723, mean_q: 61.596420\n",
      "  9230/50000: episode: 111, duration: 0.469s, episode steps: 179, steps per second: 381, episode reward: 179.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: -0.360 [-2.413, 0.846], loss: 2.600549, mean_absolute_error: 30.921755, mean_q: 62.355839\n",
      "  9428/50000: episode: 112, duration: 0.523s, episode steps: 198, steps per second: 379, episode reward: 198.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.318 [-2.424, 1.137], loss: 2.012980, mean_absolute_error: 31.085896, mean_q: 62.668133\n",
      "  9600/50000: episode: 113, duration: 0.453s, episode steps: 172, steps per second: 380, episode reward: 172.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.517 [0.000, 1.000], mean observation: 0.138 [-1.028, 1.120], loss: 1.533207, mean_absolute_error: 31.330969, mean_q: 63.201454\n",
      "  9800/50000: episode: 114, duration: 0.525s, episode steps: 200, steps per second: 381, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.285 [-2.158, 1.181], loss: 1.347993, mean_absolute_error: 31.528027, mean_q: 63.565426\n",
      "  9994/50000: episode: 115, duration: 0.509s, episode steps: 194, steps per second: 381, episode reward: 194.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: -0.314 [-2.427, 1.252], loss: 1.535542, mean_absolute_error: 32.023167, mean_q: 64.519585\n",
      " 10179/50000: episode: 116, duration: 0.479s, episode steps: 185, steps per second: 386, episode reward: 185.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: 0.123 [-1.152, 1.096], loss: 1.695013, mean_absolute_error: 32.550690, mean_q: 65.600807\n",
      " 10346/50000: episode: 117, duration: 0.438s, episode steps: 167, steps per second: 382, episode reward: 167.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.461 [0.000, 1.000], mean observation: -0.361 [-2.767, 1.023], loss: 1.814741, mean_absolute_error: 32.533432, mean_q: 65.396309\n",
      " 10507/50000: episode: 118, duration: 0.428s, episode steps: 161, steps per second: 376, episode reward: 161.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.472 [0.000, 1.000], mean observation: -0.352 [-2.138, 1.440], loss: 1.032100, mean_absolute_error: 32.610020, mean_q: 65.742783\n",
      " 10656/50000: episode: 119, duration: 0.408s, episode steps: 149, steps per second: 365, episode reward: 149.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.450 [0.000, 1.000], mean observation: -0.413 [-2.757, 0.847], loss: 1.849818, mean_absolute_error: 32.694080, mean_q: 65.815521\n",
      " 10816/50000: episode: 120, duration: 0.422s, episode steps: 160, steps per second: 380, episode reward: 160.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.463 [0.000, 1.000], mean observation: -0.390 [-2.413, 1.317], loss: 1.348020, mean_absolute_error: 33.121910, mean_q: 66.734802\n",
      " 10991/50000: episode: 121, duration: 0.458s, episode steps: 175, steps per second: 382, episode reward: 175.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.457 [0.000, 1.000], mean observation: -0.361 [-2.803, 1.276], loss: 1.420502, mean_absolute_error: 32.736740, mean_q: 65.970436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11135/50000: episode: 122, duration: 0.380s, episode steps: 144, steps per second: 379, episode reward: 144.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: 0.158 [-1.001, 1.101], loss: 1.769260, mean_absolute_error: 32.787510, mean_q: 66.061676\n",
      " 11273/50000: episode: 123, duration: 0.366s, episode steps: 138, steps per second: 377, episode reward: 138.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.457 [0.000, 1.000], mean observation: -0.441 [-2.412, 1.074], loss: 1.669131, mean_absolute_error: 33.389572, mean_q: 67.290169\n",
      " 11473/50000: episode: 124, duration: 0.519s, episode steps: 200, steps per second: 385, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.199 [-1.840, 0.949], loss: 1.401440, mean_absolute_error: 33.441612, mean_q: 67.418488\n",
      " 11673/50000: episode: 125, duration: 0.521s, episode steps: 200, steps per second: 384, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.078 [-1.272, 1.333], loss: 1.510226, mean_absolute_error: 33.390659, mean_q: 67.252563\n",
      " 11830/50000: episode: 126, duration: 0.412s, episode steps: 157, steps per second: 381, episode reward: 157.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.446 [0.000, 1.000], mean observation: -0.389 [-3.132, 1.475], loss: 1.330898, mean_absolute_error: 33.675812, mean_q: 67.940170\n",
      " 11997/50000: episode: 127, duration: 0.430s, episode steps: 167, steps per second: 388, episode reward: 167.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.461 [0.000, 1.000], mean observation: -0.386 [-2.435, 1.152], loss: 1.298907, mean_absolute_error: 34.148098, mean_q: 68.858009\n",
      " 12185/50000: episode: 128, duration: 0.489s, episode steps: 188, steps per second: 385, episode reward: 188.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.463 [0.000, 1.000], mean observation: -0.338 [-2.507, 1.550], loss: 1.490616, mean_absolute_error: 34.012299, mean_q: 68.356926\n",
      " 12367/50000: episode: 129, duration: 0.476s, episode steps: 182, steps per second: 382, episode reward: 182.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: -0.277 [-1.872, 1.064], loss: 1.762279, mean_absolute_error: 33.793255, mean_q: 68.032631\n",
      " 12567/50000: episode: 130, duration: 0.526s, episode steps: 200, steps per second: 381, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.057 [-1.291, 1.466], loss: 1.685991, mean_absolute_error: 34.171600, mean_q: 68.817001\n",
      " 12717/50000: episode: 131, duration: 0.393s, episode steps: 150, steps per second: 382, episode reward: 150.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.400 [-2.616, 1.149], loss: 1.593061, mean_absolute_error: 34.644726, mean_q: 69.662262\n",
      " 12917/50000: episode: 132, duration: 0.529s, episode steps: 200, steps per second: 378, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.055 [-1.363, 1.512], loss: 1.465237, mean_absolute_error: 34.390762, mean_q: 69.250595\n",
      " 13117/50000: episode: 133, duration: 0.520s, episode steps: 200, steps per second: 384, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.156 [-1.628, 1.234], loss: 1.286573, mean_absolute_error: 35.150478, mean_q: 70.689354\n",
      " 13286/50000: episode: 134, duration: 0.453s, episode steps: 169, steps per second: 373, episode reward: 169.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.473 [0.000, 1.000], mean observation: -0.359 [-2.582, 1.296], loss: 3.225607, mean_absolute_error: 34.943356, mean_q: 70.279572\n",
      " 13458/50000: episode: 135, duration: 0.453s, episode steps: 172, steps per second: 380, episode reward: 172.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.453 [0.000, 1.000], mean observation: -0.338 [-3.184, 1.684], loss: 3.301520, mean_absolute_error: 34.712704, mean_q: 69.802643\n",
      " 13658/50000: episode: 136, duration: 0.521s, episode steps: 200, steps per second: 384, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.009 [-1.469, 1.150], loss: 1.856339, mean_absolute_error: 35.104916, mean_q: 70.667786\n",
      " 13858/50000: episode: 137, duration: 0.515s, episode steps: 200, steps per second: 388, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.265 [-2.427, 1.435], loss: 3.166619, mean_absolute_error: 34.946407, mean_q: 70.265579\n",
      " 14017/50000: episode: 138, duration: 0.412s, episode steps: 159, steps per second: 386, episode reward: 159.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.465 [0.000, 1.000], mean observation: -0.393 [-2.348, 0.936], loss: 2.054951, mean_absolute_error: 35.241089, mean_q: 70.977249\n",
      " 14200/50000: episode: 139, duration: 0.478s, episode steps: 183, steps per second: 383, episode reward: 183.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.448 [0.000, 1.000], mean observation: -0.316 [-3.605, 2.336], loss: 0.992227, mean_absolute_error: 35.253990, mean_q: 71.003136\n",
      " 14368/50000: episode: 140, duration: 0.446s, episode steps: 168, steps per second: 377, episode reward: 168.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.446 [0.000, 1.000], mean observation: -0.371 [-3.361, 2.013], loss: 3.517556, mean_absolute_error: 35.450497, mean_q: 71.123894\n",
      " 14521/50000: episode: 141, duration: 0.404s, episode steps: 153, steps per second: 378, episode reward: 153.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.431 [0.000, 1.000], mean observation: -0.377 [-3.967, 2.811], loss: 2.095691, mean_absolute_error: 35.573193, mean_q: 71.506691\n",
      " 14701/50000: episode: 142, duration: 0.472s, episode steps: 180, steps per second: 381, episode reward: 180.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.450 [0.000, 1.000], mean observation: -0.339 [-3.353, 1.462], loss: 2.020095, mean_absolute_error: 35.106716, mean_q: 70.656990\n",
      " 14876/50000: episode: 143, duration: 0.461s, episode steps: 175, steps per second: 380, episode reward: 175.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.503 [0.000, 1.000], mean observation: 0.191 [-0.797, 1.553], loss: 1.552748, mean_absolute_error: 35.237438, mean_q: 70.973625\n",
      " 15036/50000: episode: 144, duration: 0.420s, episode steps: 160, steps per second: 381, episode reward: 160.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.463 [0.000, 1.000], mean observation: -0.353 [-2.803, 1.218], loss: 2.497947, mean_absolute_error: 35.565346, mean_q: 71.557739\n",
      " 15236/50000: episode: 145, duration: 0.525s, episode steps: 200, steps per second: 381, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.465 [0.000, 1.000], mean observation: -0.273 [-2.571, 1.507], loss: 3.984827, mean_absolute_error: 35.423866, mean_q: 71.072929\n",
      " 15436/50000: episode: 146, duration: 0.516s, episode steps: 200, steps per second: 388, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.268 [-2.057, 1.543], loss: 2.910950, mean_absolute_error: 35.135300, mean_q: 70.696426\n",
      " 15636/50000: episode: 147, duration: 0.525s, episode steps: 200, steps per second: 381, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.241 [-2.268, 1.134], loss: 3.747260, mean_absolute_error: 35.395359, mean_q: 71.145821\n",
      " 15836/50000: episode: 148, duration: 0.525s, episode steps: 200, steps per second: 381, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.144 [-1.104, 1.258], loss: 2.751670, mean_absolute_error: 35.528934, mean_q: 71.490921\n",
      " 16016/50000: episode: 149, duration: 0.473s, episode steps: 180, steps per second: 380, episode reward: 180.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.456 [0.000, 1.000], mean observation: -0.338 [-2.969, 1.382], loss: 2.307724, mean_absolute_error: 35.497570, mean_q: 71.484535\n",
      " 16175/50000: episode: 150, duration: 0.417s, episode steps: 159, steps per second: 381, episode reward: 159.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.447 [0.000, 1.000], mean observation: -0.368 [-3.190, 1.940], loss: 1.620282, mean_absolute_error: 35.371731, mean_q: 71.249557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16346/50000: episode: 151, duration: 0.461s, episode steps: 171, steps per second: 371, episode reward: 171.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.468 [0.000, 1.000], mean observation: -0.338 [-2.590, 1.580], loss: 2.436723, mean_absolute_error: 35.689648, mean_q: 71.894363\n",
      " 16546/50000: episode: 152, duration: 0.631s, episode steps: 200, steps per second: 317, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.178 [-1.709, 1.369], loss: 2.820718, mean_absolute_error: 35.351917, mean_q: 71.137619\n",
      " 16746/50000: episode: 153, duration: 0.525s, episode steps: 200, steps per second: 381, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.119 [-1.302, 1.266], loss: 2.367017, mean_absolute_error: 35.633690, mean_q: 71.727875\n",
      " 16946/50000: episode: 154, duration: 0.522s, episode steps: 200, steps per second: 383, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.151 [-1.589, 1.608], loss: 1.659327, mean_absolute_error: 35.908020, mean_q: 72.219894\n",
      " 17125/50000: episode: 155, duration: 0.474s, episode steps: 179, steps per second: 378, episode reward: 179.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.458 [0.000, 1.000], mean observation: -0.353 [-2.770, 1.224], loss: 1.962268, mean_absolute_error: 35.781517, mean_q: 72.011246\n",
      " 17325/50000: episode: 156, duration: 0.555s, episode steps: 200, steps per second: 361, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.233 [-2.250, 1.705], loss: 3.346658, mean_absolute_error: 35.822250, mean_q: 72.054779\n",
      " 17525/50000: episode: 157, duration: 0.521s, episode steps: 200, steps per second: 384, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.168 [-1.377, 1.249], loss: 2.797546, mean_absolute_error: 35.916214, mean_q: 72.301208\n",
      " 17725/50000: episode: 158, duration: 0.519s, episode steps: 200, steps per second: 385, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: 0.009 [-1.437, 1.320], loss: 1.964789, mean_absolute_error: 35.997940, mean_q: 72.380783\n",
      " 17925/50000: episode: 159, duration: 0.522s, episode steps: 200, steps per second: 383, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.185 [-1.441, 1.534], loss: 3.560954, mean_absolute_error: 36.669628, mean_q: 73.719971\n",
      " 18125/50000: episode: 160, duration: 0.527s, episode steps: 200, steps per second: 380, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.140 [-1.631, 1.696], loss: 1.889668, mean_absolute_error: 36.420181, mean_q: 73.270149\n",
      " 18279/50000: episode: 161, duration: 0.407s, episode steps: 154, steps per second: 378, episode reward: 154.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.506 [0.000, 1.000], mean observation: 0.239 [-0.993, 1.202], loss: 1.684678, mean_absolute_error: 36.287361, mean_q: 73.029144\n",
      " 18451/50000: episode: 162, duration: 0.448s, episode steps: 172, steps per second: 384, episode reward: 172.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.261 [-1.136, 1.849], loss: 2.171662, mean_absolute_error: 36.122269, mean_q: 72.700783\n",
      " 18651/50000: episode: 163, duration: 0.533s, episode steps: 200, steps per second: 376, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.169 [-1.516, 1.336], loss: 2.195615, mean_absolute_error: 36.532711, mean_q: 73.578430\n",
      " 18851/50000: episode: 164, duration: 0.517s, episode steps: 200, steps per second: 387, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.215 [-1.412, 1.337], loss: 1.615481, mean_absolute_error: 36.570412, mean_q: 73.686806\n",
      " 19051/50000: episode: 165, duration: 0.523s, episode steps: 200, steps per second: 382, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.102 [-1.351, 1.410], loss: 1.416345, mean_absolute_error: 37.045929, mean_q: 74.560509\n",
      " 19251/50000: episode: 166, duration: 0.516s, episode steps: 200, steps per second: 387, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.201 [-1.515, 1.293], loss: 2.769193, mean_absolute_error: 37.113846, mean_q: 74.579216\n",
      " 19451/50000: episode: 167, duration: 0.523s, episode steps: 200, steps per second: 382, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.175 [-0.925, 1.188], loss: 1.461856, mean_absolute_error: 37.534611, mean_q: 75.516350\n",
      " 19651/50000: episode: 168, duration: 0.524s, episode steps: 200, steps per second: 382, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.230 [-0.992, 1.607], loss: 3.800377, mean_absolute_error: 37.680161, mean_q: 75.660118\n",
      " 19851/50000: episode: 169, duration: 0.525s, episode steps: 200, steps per second: 381, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.098 [-1.221, 1.370], loss: 3.430013, mean_absolute_error: 37.744938, mean_q: 75.765266\n",
      "done, took 54.599 seconds\n",
      "Testing for 5 episodes ...\n",
      "Episode 1: reward: 200.000, steps: 200\n",
      "Episode 2: reward: 200.000, steps: 200\n",
      "Episode 3: reward: 177.000, steps: 177\n",
      "Episode 4: reward: 200.000, steps: 200\n",
      "Episode 5: reward: 200.000, steps: 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4c79e5df98>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "\n",
    "\n",
    "ENV_NAME = 'CartPole-v0'\n",
    "\n",
    "\n",
    "# Get the environment and extract the number of actions.\n",
    "env = gym.make(ENV_NAME)\n",
    "np.random.seed(123)\n",
    "env.seed(123)\n",
    "nb_actions = env.action_space.n\n",
    "\n",
    "# Next, we build a very simple model.\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))\n",
    "print(model.summary())\n",
    "\n",
    "# Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
    "# even the metrics!\n",
    "memory = SequentialMemory(limit=50000, window_length=1)\n",
    "policy = BoltzmannQPolicy()\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=10,\n",
    "               target_model_update=1e-2, policy=policy)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
    "\n",
    "# Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# Ctrl + C.\n",
    "dqn.fit(env, nb_steps=50000, visualize=False, verbose=2)\n",
    "\n",
    "# After training is done, we save the final weights.\n",
    "dqn.save_weights('./modelos_Q5/dqn_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\n",
    "\n",
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "dqn.test(env, nb_episodes=5, visualize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodo 3: Duel DQN\n",
    "\n",
    "### Desempenho\n",
    "\n",
    "* Para uma medida mais justa, o treinamento desta rede foi encerrado proximo do decorrer de 52 segundos \n",
    "    * Tempo de treinamento: 54.371 seconds\n",
    "    * Recompensas:\n",
    "\n",
    "        * Episode 1: reward: 200.000, steps: 200\n",
    "        * Episode 2: reward: 176.000, steps: 176\n",
    "        * Episode 3: reward: 200.000, steps: 200\n",
    "        * Episode 4: reward: 200.000, steps: 200\n",
    "        * Episode 5: reward: 200.000, steps: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pupio/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 658\n",
      "Trainable params: 658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training for 50000 steps ...\n",
      "WARNING:tensorflow:From /home/pupio/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pupio/anaconda3/lib/python3.7/site-packages/rl/memory.py:39: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
      "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    20/50000: episode: 1, duration: 0.843s, episode steps: 20, steps per second: 24, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.400 [0.000, 1.000], mean observation: 0.059 [-0.998, 1.652], loss: 0.468742, mean_absolute_error: 0.515729, mean_q: -0.061790\n",
      "    73/50000: episode: 2, duration: 0.128s, episode steps: 53, steps per second: 413, episode reward: 53.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.566 [0.000, 1.000], mean observation: 0.218 [-1.248, 1.743], loss: 0.340944, mean_absolute_error: 0.469579, mean_q: 0.127797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pupio/anaconda3/lib/python3.7/site-packages/rl/memory.py:39: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
      "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   106/50000: episode: 3, duration: 0.086s, episode steps: 33, steps per second: 386, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: -0.029 [-1.201, 0.833], loss: 0.132459, mean_absolute_error: 0.512152, mean_q: 0.560287\n",
      "   116/50000: episode: 4, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.900 [0.000, 1.000], mean observation: -0.152 [-2.770, 1.738], loss: 0.042505, mean_absolute_error: 0.594300, mean_q: 0.941608\n",
      "   139/50000: episode: 5, duration: 0.109s, episode steps: 23, steps per second: 211, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.565 [0.000, 1.000], mean observation: -0.042 [-1.852, 1.210], loss: 0.019774, mean_absolute_error: 0.633045, mean_q: 1.129749\n",
      "   198/50000: episode: 6, duration: 0.172s, episode steps: 59, steps per second: 343, episode reward: 59.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.492 [0.000, 1.000], mean observation: 0.033 [-1.335, 1.555], loss: 0.006824, mean_absolute_error: 0.735753, mean_q: 1.422631\n",
      "   225/50000: episode: 7, duration: 0.066s, episode steps: 27, steps per second: 410, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.593 [0.000, 1.000], mean observation: -0.054 [-1.836, 1.034], loss: 0.005350, mean_absolute_error: 0.869824, mean_q: 1.706409\n",
      "   237/50000: episode: 8, duration: 0.031s, episode steps: 12, steps per second: 387, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.113 [-1.946, 1.174], loss: 0.013299, mean_absolute_error: 0.940420, mean_q: 1.833516\n",
      "   286/50000: episode: 9, duration: 0.126s, episode steps: 49, steps per second: 389, episode reward: 49.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.531 [0.000, 1.000], mean observation: 0.109 [-0.551, 1.143], loss: 0.015937, mean_absolute_error: 1.048868, mean_q: 2.034321\n",
      "   339/50000: episode: 10, duration: 0.134s, episode steps: 53, steps per second: 395, episode reward: 53.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.491 [0.000, 1.000], mean observation: 0.085 [-1.006, 1.486], loss: 0.019203, mean_absolute_error: 1.239186, mean_q: 2.417059\n",
      "   373/50000: episode: 11, duration: 0.098s, episode steps: 34, steps per second: 347, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.588 [0.000, 1.000], mean observation: -0.010 [-1.968, 1.334], loss: 0.034881, mean_absolute_error: 1.415414, mean_q: 2.743021\n",
      "   391/50000: episode: 12, duration: 0.047s, episode steps: 18, steps per second: 384, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.556 [0.000, 1.000], mean observation: -0.069 [-1.275, 0.826], loss: 0.031009, mean_absolute_error: 1.512592, mean_q: 2.948528\n",
      "   410/50000: episode: 13, duration: 0.054s, episode steps: 19, steps per second: 351, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.684 [0.000, 1.000], mean observation: -0.062 [-2.334, 1.416], loss: 0.040170, mean_absolute_error: 1.606688, mean_q: 3.125263\n",
      "   432/50000: episode: 14, duration: 0.110s, episode steps: 22, steps per second: 200, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.409 [0.000, 1.000], mean observation: 0.080 [-0.782, 1.597], loss: 0.037858, mean_absolute_error: 1.688091, mean_q: 3.306534\n",
      "   499/50000: episode: 15, duration: 0.193s, episode steps: 67, steps per second: 347, episode reward: 67.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.612 [0.000, 1.000], mean observation: 0.301 [-2.147, 3.000], loss: 0.053546, mean_absolute_error: 1.870406, mean_q: 3.651776\n",
      "   514/50000: episode: 16, duration: 0.051s, episode steps: 15, steps per second: 292, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.082 [-1.764, 1.180], loss: 0.083326, mean_absolute_error: 2.045357, mean_q: 3.953731\n",
      "   538/50000: episode: 17, duration: 0.060s, episode steps: 24, steps per second: 403, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.070 [-2.554, 1.585], loss: 0.060970, mean_absolute_error: 2.109902, mean_q: 4.138905\n",
      "   563/50000: episode: 18, duration: 0.073s, episode steps: 25, steps per second: 341, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.400 [0.000, 1.000], mean observation: 0.063 [-1.005, 1.914], loss: 0.068314, mean_absolute_error: 2.224521, mean_q: 4.368474\n",
      "   603/50000: episode: 19, duration: 0.111s, episode steps: 40, steps per second: 359, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.575 [0.000, 1.000], mean observation: 0.022 [-1.724, 1.192], loss: 0.085274, mean_absolute_error: 2.369807, mean_q: 4.637378\n",
      "   644/50000: episode: 20, duration: 0.141s, episode steps: 41, steps per second: 291, episode reward: 41.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.463 [0.000, 1.000], mean observation: -0.054 [-1.060, 0.781], loss: 0.084627, mean_absolute_error: 2.539900, mean_q: 4.992455\n",
      "   676/50000: episode: 21, duration: 0.153s, episode steps: 32, steps per second: 209, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: 0.120 [-0.423, 1.370], loss: 0.127297, mean_absolute_error: 2.691547, mean_q: 5.287164\n",
      "   713/50000: episode: 22, duration: 0.180s, episode steps: 37, steps per second: 205, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: 0.122 [-0.600, 1.048], loss: 0.148643, mean_absolute_error: 2.834997, mean_q: 5.545885\n",
      "   736/50000: episode: 23, duration: 0.099s, episode steps: 23, steps per second: 233, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.522 [0.000, 1.000], mean observation: -0.018 [-1.332, 1.007], loss: 0.134143, mean_absolute_error: 2.943794, mean_q: 5.805759\n",
      "   763/50000: episode: 24, duration: 0.075s, episode steps: 27, steps per second: 358, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.407 [0.000, 1.000], mean observation: 0.090 [-0.980, 1.931], loss: 0.125323, mean_absolute_error: 3.067328, mean_q: 6.075258\n",
      "   831/50000: episode: 25, duration: 0.167s, episode steps: 68, steps per second: 407, episode reward: 68.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.220 [-1.862, 1.174], loss: 0.178607, mean_absolute_error: 3.271721, mean_q: 6.441289\n",
      "   879/50000: episode: 26, duration: 0.115s, episode steps: 48, steps per second: 416, episode reward: 48.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.583 [0.000, 1.000], mean observation: 0.085 [-1.845, 1.554], loss: 0.189201, mean_absolute_error: 3.528534, mean_q: 6.987765\n",
      "   908/50000: episode: 27, duration: 0.072s, episode steps: 29, steps per second: 403, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.552 [0.000, 1.000], mean observation: 0.075 [-0.601, 0.959], loss: 0.186420, mean_absolute_error: 3.687447, mean_q: 7.307168\n",
      "   930/50000: episode: 28, duration: 0.066s, episode steps: 22, steps per second: 335, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.104 [-1.111, 0.732], loss: 0.185720, mean_absolute_error: 3.829323, mean_q: 7.613835\n",
      "   942/50000: episode: 29, duration: 0.049s, episode steps: 12, steps per second: 247, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.120 [-1.129, 1.851], loss: 0.193973, mean_absolute_error: 3.876111, mean_q: 7.732339\n",
      "   981/50000: episode: 30, duration: 0.205s, episode steps: 39, steps per second: 191, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.436 [0.000, 1.000], mean observation: -0.038 [-1.487, 1.681], loss: 0.272650, mean_absolute_error: 3.987183, mean_q: 7.955768\n",
      "  1022/50000: episode: 31, duration: 0.182s, episode steps: 41, steps per second: 225, episode reward: 41.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.585 [0.000, 1.000], mean observation: 0.069 [-1.595, 1.677], loss: 0.282349, mean_absolute_error: 4.193867, mean_q: 8.310091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1074/50000: episode: 32, duration: 0.141s, episode steps: 52, steps per second: 368, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.519 [0.000, 1.000], mean observation: 0.045 [-1.330, 1.290], loss: 0.284635, mean_absolute_error: 4.363553, mean_q: 8.687899\n",
      "  1157/50000: episode: 33, duration: 0.216s, episode steps: 83, steps per second: 384, episode reward: 83.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.506 [0.000, 1.000], mean observation: -0.122 [-1.293, 0.947], loss: 0.254637, mean_absolute_error: 4.677570, mean_q: 9.390153\n",
      "  1196/50000: episode: 34, duration: 0.165s, episode steps: 39, steps per second: 236, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.487 [0.000, 1.000], mean observation: 0.008 [-0.877, 0.913], loss: 0.272334, mean_absolute_error: 4.986375, mean_q: 10.015983\n",
      "  1236/50000: episode: 35, duration: 0.126s, episode steps: 40, steps per second: 319, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.024 [-1.524, 1.321], loss: 0.380700, mean_absolute_error: 5.152470, mean_q: 10.335829\n",
      "  1303/50000: episode: 36, duration: 0.159s, episode steps: 67, steps per second: 422, episode reward: 67.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.522 [0.000, 1.000], mean observation: -0.050 [-1.750, 1.330], loss: 0.377002, mean_absolute_error: 5.378456, mean_q: 10.827748\n",
      "  1331/50000: episode: 37, duration: 0.097s, episode steps: 28, steps per second: 290, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.536 [0.000, 1.000], mean observation: 0.051 [-0.769, 1.257], loss: 0.329828, mean_absolute_error: 5.592205, mean_q: 11.298701\n",
      "  1366/50000: episode: 38, duration: 0.172s, episode steps: 35, steps per second: 203, episode reward: 35.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: -0.001 [-1.133, 0.799], loss: 0.243595, mean_absolute_error: 5.761612, mean_q: 11.716571\n",
      "  1479/50000: episode: 39, duration: 0.297s, episode steps: 113, steps per second: 380, episode reward: 113.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.504 [0.000, 1.000], mean observation: 0.139 [-0.912, 1.230], loss: 0.465155, mean_absolute_error: 6.074986, mean_q: 12.281614\n",
      "  1517/50000: episode: 40, duration: 0.092s, episode steps: 38, steps per second: 415, episode reward: 38.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.447 [0.000, 1.000], mean observation: 0.018 [-0.993, 1.600], loss: 0.662464, mean_absolute_error: 6.414924, mean_q: 12.975797\n",
      "  1606/50000: episode: 41, duration: 0.227s, episode steps: 89, steps per second: 391, episode reward: 89.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.506 [0.000, 1.000], mean observation: 0.236 [-1.100, 1.509], loss: 0.585091, mean_absolute_error: 6.723284, mean_q: 13.608188\n",
      "  1685/50000: episode: 42, duration: 0.206s, episode steps: 79, steps per second: 384, episode reward: 79.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.506 [0.000, 1.000], mean observation: -0.014 [-1.380, 1.106], loss: 0.700121, mean_absolute_error: 7.099713, mean_q: 14.404404\n",
      "  1827/50000: episode: 43, duration: 0.418s, episode steps: 142, steps per second: 339, episode reward: 142.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: 0.442 [-1.552, 2.231], loss: 0.966979, mean_absolute_error: 7.636630, mean_q: 15.417442\n",
      "  1993/50000: episode: 44, duration: 0.414s, episode steps: 166, steps per second: 401, episode reward: 166.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.506 [0.000, 1.000], mean observation: 0.028 [-1.369, 1.374], loss: 0.826595, mean_absolute_error: 8.331853, mean_q: 17.028837\n",
      "  2164/50000: episode: 45, duration: 0.509s, episode steps: 171, steps per second: 336, episode reward: 171.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.509 [0.000, 1.000], mean observation: 0.127 [-1.458, 1.744], loss: 1.000093, mean_absolute_error: 9.172462, mean_q: 18.727917\n",
      "  2346/50000: episode: 46, duration: 0.557s, episode steps: 182, steps per second: 327, episode reward: 182.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.527 [0.000, 1.000], mean observation: 0.371 [-1.188, 2.401], loss: 1.187674, mean_absolute_error: 10.026723, mean_q: 20.471523\n",
      "  2486/50000: episode: 47, duration: 0.635s, episode steps: 140, steps per second: 220, episode reward: 140.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.521 [0.000, 1.000], mean observation: 0.297 [-0.887, 1.534], loss: 1.400958, mean_absolute_error: 10.846354, mean_q: 22.070005\n",
      "  2686/50000: episode: 48, duration: 0.572s, episode steps: 200, steps per second: 350, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.128 [-1.413, 1.654], loss: 1.330480, mean_absolute_error: 11.663235, mean_q: 23.809111\n",
      "  2848/50000: episode: 49, duration: 0.409s, episode steps: 162, steps per second: 396, episode reward: 162.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.512 [0.000, 1.000], mean observation: 0.146 [-1.427, 1.330], loss: 2.199214, mean_absolute_error: 12.654383, mean_q: 25.689156\n",
      "  3021/50000: episode: 50, duration: 0.490s, episode steps: 173, steps per second: 353, episode reward: 173.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.468 [0.000, 1.000], mean observation: -0.246 [-2.030, 1.003], loss: 2.033370, mean_absolute_error: 13.448107, mean_q: 27.301617\n",
      "  3185/50000: episode: 51, duration: 0.430s, episode steps: 164, steps per second: 381, episode reward: 164.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.271 [-1.821, 0.992], loss: 2.286665, mean_absolute_error: 14.329515, mean_q: 29.178699\n",
      "  3385/50000: episode: 52, duration: 0.503s, episode steps: 200, steps per second: 397, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.170 [-1.490, 1.153], loss: 2.989100, mean_absolute_error: 15.365242, mean_q: 31.147781\n",
      "  3585/50000: episode: 53, duration: 0.539s, episode steps: 200, steps per second: 371, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.051 [-1.008, 1.135], loss: 2.671391, mean_absolute_error: 16.349524, mean_q: 33.233238\n",
      "  3785/50000: episode: 54, duration: 0.498s, episode steps: 200, steps per second: 402, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: 0.038 [-0.915, 0.840], loss: 2.746304, mean_absolute_error: 17.325439, mean_q: 35.221436\n",
      "  3985/50000: episode: 55, duration: 0.495s, episode steps: 200, steps per second: 404, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.232 [-1.159, 1.700], loss: 2.969489, mean_absolute_error: 18.205717, mean_q: 37.006607\n",
      "  4147/50000: episode: 56, duration: 0.403s, episode steps: 162, steps per second: 402, episode reward: 162.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: -0.304 [-1.859, 0.815], loss: 2.938672, mean_absolute_error: 19.075495, mean_q: 38.794060\n",
      "  4347/50000: episode: 57, duration: 0.528s, episode steps: 200, steps per second: 379, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.065 [-1.094, 1.099], loss: 2.906296, mean_absolute_error: 19.931686, mean_q: 40.541245\n",
      "  4547/50000: episode: 58, duration: 0.502s, episode steps: 200, steps per second: 398, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.074 [-0.907, 0.697], loss: 4.341877, mean_absolute_error: 20.947718, mean_q: 42.462570\n",
      "  4747/50000: episode: 59, duration: 0.504s, episode steps: 200, steps per second: 397, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.117 [-1.059, 1.239], loss: 4.452936, mean_absolute_error: 21.788923, mean_q: 44.064804\n",
      "  4947/50000: episode: 60, duration: 0.524s, episode steps: 200, steps per second: 382, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.149 [-1.339, 0.852], loss: 4.371033, mean_absolute_error: 22.660561, mean_q: 45.959522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5147/50000: episode: 61, duration: 0.557s, episode steps: 200, steps per second: 359, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.154 [-1.480, 1.132], loss: 4.025436, mean_absolute_error: 23.533737, mean_q: 47.733185\n",
      "  5298/50000: episode: 62, duration: 0.388s, episode steps: 151, steps per second: 390, episode reward: 151.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.457 [0.000, 1.000], mean observation: -0.403 [-2.750, 0.797], loss: 4.281644, mean_absolute_error: 24.320381, mean_q: 49.322815\n",
      "  5495/50000: episode: 63, duration: 0.533s, episode steps: 197, steps per second: 370, episode reward: 197.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.314 [-2.731, 0.923], loss: 4.303280, mean_absolute_error: 25.006836, mean_q: 50.713688\n",
      "  5695/50000: episode: 64, duration: 0.525s, episode steps: 200, steps per second: 381, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.248 [-2.160, 0.889], loss: 5.100449, mean_absolute_error: 25.869019, mean_q: 52.463486\n",
      "  5831/50000: episode: 65, duration: 0.342s, episode steps: 136, steps per second: 398, episode reward: 136.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.463 [0.000, 1.000], mean observation: -0.297 [-1.838, 0.918], loss: 5.416938, mean_absolute_error: 26.384195, mean_q: 53.496586\n",
      "  6010/50000: episode: 66, duration: 0.450s, episode steps: 179, steps per second: 398, episode reward: 179.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.464 [0.000, 1.000], mean observation: -0.348 [-2.737, 0.771], loss: 5.391509, mean_absolute_error: 27.206409, mean_q: 55.027416\n",
      "  6205/50000: episode: 67, duration: 0.483s, episode steps: 195, steps per second: 403, episode reward: 195.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.477 [0.000, 1.000], mean observation: -0.315 [-2.781, 1.081], loss: 4.753190, mean_absolute_error: 27.749146, mean_q: 56.109100\n",
      "  6405/50000: episode: 68, duration: 0.492s, episode steps: 200, steps per second: 406, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.140 [-1.259, 0.866], loss: 5.713156, mean_absolute_error: 28.440151, mean_q: 57.513527\n",
      "  6588/50000: episode: 69, duration: 0.452s, episode steps: 183, steps per second: 405, episode reward: 183.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.333 [-2.574, 0.915], loss: 4.720982, mean_absolute_error: 29.162024, mean_q: 59.049862\n",
      "  6788/50000: episode: 70, duration: 0.491s, episode steps: 200, steps per second: 407, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: 0.043 [-0.858, 1.086], loss: 5.780572, mean_absolute_error: 29.882313, mean_q: 60.454346\n",
      "  6988/50000: episode: 71, duration: 0.492s, episode steps: 200, steps per second: 406, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.154 [-1.074, 1.278], loss: 5.388245, mean_absolute_error: 30.535063, mean_q: 61.755596\n",
      "  7188/50000: episode: 72, duration: 0.492s, episode steps: 200, steps per second: 407, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.201 [-0.734, 1.435], loss: 4.803557, mean_absolute_error: 31.250530, mean_q: 63.298340\n",
      "  7373/50000: episode: 73, duration: 0.456s, episode steps: 185, steps per second: 406, episode reward: 185.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.333 [-2.630, 0.902], loss: 5.556588, mean_absolute_error: 31.912178, mean_q: 64.586548\n",
      "  7573/50000: episode: 74, duration: 0.488s, episode steps: 200, steps per second: 409, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: 0.244 [-0.660, 1.759], loss: 4.994914, mean_absolute_error: 32.646530, mean_q: 66.000145\n",
      "  7773/50000: episode: 75, duration: 0.521s, episode steps: 200, steps per second: 384, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.084 [-0.962, 1.155], loss: 6.463215, mean_absolute_error: 33.296356, mean_q: 67.273026\n",
      "  7973/50000: episode: 76, duration: 0.553s, episode steps: 200, steps per second: 362, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.252 [-0.685, 1.722], loss: 8.218623, mean_absolute_error: 33.764328, mean_q: 68.221306\n",
      "  8173/50000: episode: 77, duration: 0.520s, episode steps: 200, steps per second: 384, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.232 [-2.181, 1.049], loss: 7.442721, mean_absolute_error: 34.480972, mean_q: 69.708076\n",
      "  8373/50000: episode: 78, duration: 0.497s, episode steps: 200, steps per second: 403, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.239 [-0.842, 1.687], loss: 7.259170, mean_absolute_error: 35.085739, mean_q: 70.913162\n",
      "  8573/50000: episode: 79, duration: 0.494s, episode steps: 200, steps per second: 405, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.102 [-1.074, 0.829], loss: 6.012482, mean_absolute_error: 35.689693, mean_q: 72.164848\n",
      "  8773/50000: episode: 80, duration: 0.502s, episode steps: 200, steps per second: 398, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.231 [-2.191, 1.140], loss: 6.767237, mean_absolute_error: 36.662529, mean_q: 73.967133\n",
      "  8973/50000: episode: 81, duration: 0.494s, episode steps: 200, steps per second: 405, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.110 [-0.751, 0.945], loss: 7.906239, mean_absolute_error: 37.103344, mean_q: 74.846046\n",
      "  9173/50000: episode: 82, duration: 0.500s, episode steps: 200, steps per second: 400, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.188 [-1.807, 1.020], loss: 9.304667, mean_absolute_error: 37.677349, mean_q: 75.905525\n",
      "  9373/50000: episode: 83, duration: 0.500s, episode steps: 200, steps per second: 400, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.005 [-0.796, 0.893], loss: 6.726295, mean_absolute_error: 38.183437, mean_q: 77.127609\n",
      "  9573/50000: episode: 84, duration: 0.494s, episode steps: 200, steps per second: 405, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.000 [-0.833, 1.040], loss: 7.748731, mean_absolute_error: 38.809181, mean_q: 78.385330\n",
      "  9773/50000: episode: 85, duration: 0.500s, episode steps: 200, steps per second: 400, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: 0.239 [-0.739, 1.647], loss: 8.026562, mean_absolute_error: 39.438046, mean_q: 79.712753\n",
      "  9973/50000: episode: 86, duration: 0.492s, episode steps: 200, steps per second: 406, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.028 [-0.795, 1.090], loss: 12.664936, mean_absolute_error: 39.867985, mean_q: 80.314362\n",
      " 10173/50000: episode: 87, duration: 0.506s, episode steps: 200, steps per second: 396, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.122 [-1.442, 1.198], loss: 8.262025, mean_absolute_error: 40.355488, mean_q: 81.464813\n",
      " 10373/50000: episode: 88, duration: 0.497s, episode steps: 200, steps per second: 403, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.216 [-2.250, 1.108], loss: 11.022417, mean_absolute_error: 40.900806, mean_q: 82.448280\n",
      " 10573/50000: episode: 89, duration: 0.507s, episode steps: 200, steps per second: 395, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.015 [-0.799, 1.036], loss: 11.535652, mean_absolute_error: 41.319805, mean_q: 83.261482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10753/50000: episode: 90, duration: 0.461s, episode steps: 180, steps per second: 390, episode reward: 180.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: -0.233 [-2.004, 0.950], loss: 8.544808, mean_absolute_error: 41.889278, mean_q: 84.515106\n",
      " 10953/50000: episode: 91, duration: 0.501s, episode steps: 200, steps per second: 399, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.210 [-2.187, 1.172], loss: 11.538610, mean_absolute_error: 42.213535, mean_q: 85.128868\n",
      " 11153/50000: episode: 92, duration: 0.494s, episode steps: 200, steps per second: 405, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.244 [-2.606, 1.055], loss: 9.913503, mean_absolute_error: 42.373016, mean_q: 85.632698\n",
      " 11344/50000: episode: 93, duration: 0.475s, episode steps: 191, steps per second: 402, episode reward: 191.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.487 [0.000, 1.000], mean observation: -0.325 [-2.595, 1.010], loss: 8.821898, mean_absolute_error: 42.930901, mean_q: 86.812241\n",
      " 11519/50000: episode: 94, duration: 0.431s, episode steps: 175, steps per second: 406, episode reward: 175.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.451 [0.000, 1.000], mean observation: -0.345 [-3.169, 1.245], loss: 9.475930, mean_absolute_error: 43.468204, mean_q: 87.745064\n",
      " 11719/50000: episode: 95, duration: 0.493s, episode steps: 200, steps per second: 406, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.525 [0.000, 1.000], mean observation: 0.350 [-0.636, 2.358], loss: 9.277790, mean_absolute_error: 43.566563, mean_q: 87.996033\n",
      " 11919/50000: episode: 96, duration: 0.503s, episode steps: 200, steps per second: 398, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.091 [-0.574, 0.858], loss: 9.416293, mean_absolute_error: 43.966103, mean_q: 88.747246\n",
      " 12116/50000: episode: 97, duration: 0.486s, episode steps: 197, steps per second: 405, episode reward: 197.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.477 [0.000, 1.000], mean observation: -0.293 [-2.994, 1.547], loss: 10.777882, mean_absolute_error: 44.319420, mean_q: 89.308418\n",
      " 12316/50000: episode: 98, duration: 0.495s, episode steps: 200, steps per second: 404, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.081 [-0.802, 0.845], loss: 9.716342, mean_absolute_error: 44.642189, mean_q: 90.020447\n",
      " 12516/50000: episode: 99, duration: 0.497s, episode steps: 200, steps per second: 402, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.164 [-0.866, 1.289], loss: 11.517240, mean_absolute_error: 45.220509, mean_q: 91.063347\n",
      " 12687/50000: episode: 100, duration: 0.427s, episode steps: 171, steps per second: 401, episode reward: 171.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.456 [0.000, 1.000], mean observation: -0.336 [-3.410, 2.064], loss: 12.339921, mean_absolute_error: 45.358303, mean_q: 91.261322\n",
      " 12868/50000: episode: 101, duration: 0.447s, episode steps: 181, steps per second: 405, episode reward: 181.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.344 [-2.421, 0.923], loss: 14.000990, mean_absolute_error: 45.493969, mean_q: 91.688286\n",
      " 13068/50000: episode: 102, duration: 0.491s, episode steps: 200, steps per second: 407, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.143 [-0.789, 1.090], loss: 11.062680, mean_absolute_error: 45.465927, mean_q: 91.674980\n",
      " 13268/50000: episode: 103, duration: 0.491s, episode steps: 200, steps per second: 408, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.188 [-0.619, 1.317], loss: 10.046198, mean_absolute_error: 46.063656, mean_q: 92.968674\n",
      " 13468/50000: episode: 104, duration: 0.495s, episode steps: 200, steps per second: 404, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.180 [-0.566, 1.289], loss: 7.431184, mean_absolute_error: 46.243309, mean_q: 93.571678\n",
      " 13668/50000: episode: 105, duration: 0.498s, episode steps: 200, steps per second: 402, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.133 [-0.599, 0.952], loss: 8.949926, mean_absolute_error: 46.745636, mean_q: 94.248932\n",
      " 13868/50000: episode: 106, duration: 0.497s, episode steps: 200, steps per second: 402, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.126 [-0.729, 1.114], loss: 7.671316, mean_absolute_error: 47.343185, mean_q: 95.515808\n",
      " 14068/50000: episode: 107, duration: 0.497s, episode steps: 200, steps per second: 402, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.137 [-0.839, 1.132], loss: 11.194507, mean_absolute_error: 47.397518, mean_q: 95.487198\n",
      " 14268/50000: episode: 108, duration: 0.517s, episode steps: 200, steps per second: 387, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: 0.255 [-0.714, 1.764], loss: 11.450104, mean_absolute_error: 47.416714, mean_q: 95.521057\n",
      " 14468/50000: episode: 109, duration: 0.554s, episode steps: 200, steps per second: 361, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.206 [-0.728, 1.512], loss: 11.245857, mean_absolute_error: 47.350933, mean_q: 95.403137\n",
      " 14668/50000: episode: 110, duration: 0.496s, episode steps: 200, steps per second: 403, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.102 [-0.769, 1.128], loss: 8.729577, mean_absolute_error: 48.089020, mean_q: 96.977966\n",
      " 14868/50000: episode: 111, duration: 0.494s, episode steps: 200, steps per second: 405, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.123 [-0.600, 1.104], loss: 10.508393, mean_absolute_error: 48.166485, mean_q: 96.999199\n",
      " 15068/50000: episode: 112, duration: 0.497s, episode steps: 200, steps per second: 402, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.134 [-0.733, 1.323], loss: 9.628586, mean_absolute_error: 48.281075, mean_q: 97.388611\n",
      " 15259/50000: episode: 113, duration: 0.511s, episode steps: 191, steps per second: 374, episode reward: 191.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.529 [0.000, 1.000], mean observation: 0.358 [-0.654, 2.429], loss: 12.638754, mean_absolute_error: 48.673923, mean_q: 98.083260\n",
      " 15459/50000: episode: 114, duration: 0.492s, episode steps: 200, steps per second: 406, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.133 [-0.693, 1.083], loss: 8.712318, mean_absolute_error: 48.960567, mean_q: 98.676521\n",
      " 15659/50000: episode: 115, duration: 0.498s, episode steps: 200, steps per second: 402, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.525 [0.000, 1.000], mean observation: 0.298 [-0.579, 2.137], loss: 10.557317, mean_absolute_error: 49.189220, mean_q: 99.184784\n",
      " 15853/50000: episode: 116, duration: 0.487s, episode steps: 194, steps per second: 398, episode reward: 194.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.526 [0.000, 1.000], mean observation: 0.354 [-0.660, 2.422], loss: 8.128817, mean_absolute_error: 49.088799, mean_q: 99.048164\n",
      " 16053/50000: episode: 117, duration: 0.502s, episode steps: 200, steps per second: 398, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.138 [-0.769, 1.081], loss: 8.801009, mean_absolute_error: 49.298389, mean_q: 99.534821\n",
      " 16253/50000: episode: 118, duration: 0.499s, episode steps: 200, steps per second: 401, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.109 [-0.702, 0.915], loss: 6.588578, mean_absolute_error: 49.392059, mean_q: 99.545105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16453/50000: episode: 119, duration: 0.493s, episode steps: 200, steps per second: 406, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.124 [-1.488, 0.931], loss: 9.331537, mean_absolute_error: 49.983784, mean_q: 100.746231\n",
      " 16653/50000: episode: 120, duration: 0.503s, episode steps: 200, steps per second: 397, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.055 [-0.899, 0.993], loss: 9.274826, mean_absolute_error: 50.307362, mean_q: 101.467644\n",
      " 16853/50000: episode: 121, duration: 0.493s, episode steps: 200, steps per second: 405, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.051 [-0.697, 0.898], loss: 8.821600, mean_absolute_error: 50.120811, mean_q: 100.935410\n",
      " 17050/50000: episode: 122, duration: 0.497s, episode steps: 197, steps per second: 396, episode reward: 197.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.528 [0.000, 1.000], mean observation: 0.353 [-0.734, 2.402], loss: 11.926875, mean_absolute_error: 50.345196, mean_q: 101.386917\n",
      " 17250/50000: episode: 123, duration: 0.496s, episode steps: 200, steps per second: 403, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.271 [-2.249, 1.069], loss: 6.210632, mean_absolute_error: 50.366837, mean_q: 101.587776\n",
      " 17450/50000: episode: 124, duration: 0.498s, episode steps: 200, steps per second: 402, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: 0.239 [-1.091, 1.686], loss: 10.481712, mean_absolute_error: 50.520920, mean_q: 101.704277\n",
      " 17650/50000: episode: 125, duration: 0.493s, episode steps: 200, steps per second: 406, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.153 [-0.676, 1.297], loss: 10.606231, mean_absolute_error: 50.303448, mean_q: 101.198143\n",
      " 17850/50000: episode: 126, duration: 0.498s, episode steps: 200, steps per second: 401, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.083 [-0.895, 0.922], loss: 10.923982, mean_absolute_error: 50.771534, mean_q: 102.203537\n",
      " 18050/50000: episode: 127, duration: 0.494s, episode steps: 200, steps per second: 405, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.177 [-0.716, 1.324], loss: 7.003215, mean_absolute_error: 50.809593, mean_q: 102.342110\n",
      " 18250/50000: episode: 128, duration: 0.500s, episode steps: 200, steps per second: 400, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: 0.262 [-0.689, 1.832], loss: 7.013090, mean_absolute_error: 50.940342, mean_q: 102.616325\n",
      " 18450/50000: episode: 129, duration: 0.497s, episode steps: 200, steps per second: 403, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: 0.197 [-0.791, 1.462], loss: 10.284396, mean_absolute_error: 50.647110, mean_q: 101.872383\n",
      " 18647/50000: episode: 130, duration: 0.493s, episode steps: 197, steps per second: 400, episode reward: 197.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.528 [0.000, 1.000], mean observation: 0.357 [-0.625, 2.429], loss: 11.028925, mean_absolute_error: 50.658016, mean_q: 101.928398\n",
      " 18847/50000: episode: 131, duration: 0.492s, episode steps: 200, steps per second: 406, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.072 [-0.764, 0.772], loss: 8.106367, mean_absolute_error: 50.785728, mean_q: 102.207336\n",
      " 19045/50000: episode: 132, duration: 0.494s, episode steps: 198, steps per second: 400, episode reward: 198.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.525 [0.000, 1.000], mean observation: 0.353 [-0.840, 2.432], loss: 10.277830, mean_absolute_error: 50.998825, mean_q: 102.587791\n",
      " 19245/50000: episode: 133, duration: 0.494s, episode steps: 200, steps per second: 405, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: 0.318 [-0.713, 2.242], loss: 5.736524, mean_absolute_error: 50.654995, mean_q: 102.003487\n",
      " 19445/50000: episode: 134, duration: 0.495s, episode steps: 200, steps per second: 404, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.131 [-0.822, 1.332], loss: 7.806647, mean_absolute_error: 50.770775, mean_q: 102.196404\n",
      " 19645/50000: episode: 135, duration: 0.491s, episode steps: 200, steps per second: 408, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.144 [-0.882, 1.296], loss: 7.517440, mean_absolute_error: 51.044579, mean_q: 102.636620\n",
      " 19845/50000: episode: 136, duration: 0.496s, episode steps: 200, steps per second: 404, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.525 [0.000, 1.000], mean observation: 0.271 [-0.893, 1.877], loss: 5.766678, mean_absolute_error: 51.200584, mean_q: 102.931618\n",
      " 20045/50000: episode: 137, duration: 0.496s, episode steps: 200, steps per second: 403, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.154 [-0.796, 1.311], loss: 8.145304, mean_absolute_error: 50.998070, mean_q: 102.617340\n",
      " 20245/50000: episode: 138, duration: 0.513s, episode steps: 200, steps per second: 390, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.100 [-0.794, 0.843], loss: 10.513777, mean_absolute_error: 50.648720, mean_q: 101.718994\n",
      " 20445/50000: episode: 139, duration: 0.492s, episode steps: 200, steps per second: 406, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.525 [0.000, 1.000], mean observation: 0.181 [-1.034, 1.814], loss: 9.767699, mean_absolute_error: 50.838661, mean_q: 102.222092\n",
      " 20640/50000: episode: 140, duration: 0.492s, episode steps: 195, steps per second: 397, episode reward: 195.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.299 [-3.154, 1.461], loss: 7.860837, mean_absolute_error: 50.415714, mean_q: 101.341827\n",
      "done, took 54.371 seconds\n",
      "Testing for 5 episodes ...\n",
      "Episode 1: reward: 200.000, steps: 200\n",
      "Episode 2: reward: 176.000, steps: 176\n",
      "Episode 3: reward: 200.000, steps: 200\n",
      "Episode 4: reward: 200.000, steps: 200\n",
      "Episode 5: reward: 200.000, steps: 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4ccc41fd30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "\n",
    "\n",
    "ENV_NAME = 'CartPole-v0'\n",
    "\n",
    "\n",
    "# Get the environment and extract the number of actions.\n",
    "env = gym.make(ENV_NAME)\n",
    "np.random.seed(123)\n",
    "env.seed(123)\n",
    "nb_actions = env.action_space.n\n",
    "\n",
    "# Next, we build a very simple model regardless of the dueling architecture\n",
    "# if you enable dueling network in DQN , DQN will build a dueling network base on your model automatically\n",
    "# Also, you can build a dueling network by yourself and turn off the dueling network in DQN.\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions, activation='linear'))\n",
    "print(model.summary())\n",
    "\n",
    "# Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
    "# even the metrics!\n",
    "memory = SequentialMemory(limit=50000, window_length=1)\n",
    "policy = BoltzmannQPolicy()\n",
    "# enable the dueling network\n",
    "# you can specify the dueling_type to one of {'avg','max','naive'}\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=10,\n",
    "               enable_dueling_network=True, dueling_type='avg', target_model_update=1e-2, policy=policy)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
    "\n",
    "# Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# Ctrl + C.\n",
    "dqn.fit(env, nb_steps=50000, visualize=False, verbose=2)\n",
    "\n",
    "# After training is done, we save the final weights.\n",
    "dqn.save_weights('./modelos_Q5/duel_dqn_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\n",
    "\n",
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "dqn.test(env, nb_episodes=5, visualize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodo 4: SARSA\n",
    "\n",
    "### Desempenho\n",
    "\n",
    "* Para uma medida mais justa, o treinamento desta rede foi encerrado proximo do decorrer de 52 segundos \n",
    "    * Tempo de treinamento: 52.714 seconds\n",
    "    * Recompensas:\n",
    "        * Episode 1: reward: 105.000, steps: 105\n",
    "        * Episode 2: reward: 157.000, steps: 157\n",
    "        * Episode 3: reward: 148.000, steps: 148\n",
    "        * Episode 4: reward: 195.000, steps: 195\n",
    "        * Episode 5: reward: 97.000, steps: 97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 658\n",
      "Trainable params: 658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training for 50000 steps ...\n",
      "    22/50000: episode: 1, duration: 1.209s, episode steps: 22, steps per second: 18, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: -0.105 [-0.935, 0.391], loss: 0.501390, mean_absolute_error: 0.514470, mean_q: 0.021517\n",
      "    53/50000: episode: 2, duration: 0.051s, episode steps: 31, steps per second: 606, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.419 [0.000, 1.000], mean observation: 0.128 [-0.955, 2.162], loss: 0.497603, mean_absolute_error: 0.569573, mean_q: 0.159180\n",
      "    74/50000: episode: 3, duration: 0.035s, episode steps: 21, steps per second: 597, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: 0.087 [-0.551, 1.254], loss: 0.506023, mean_absolute_error: 0.698357, mean_q: 0.459803\n",
      "   101/50000: episode: 4, duration: 0.045s, episode steps: 27, steps per second: 606, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.444 [0.000, 1.000], mean observation: 0.062 [-0.630, 1.390], loss: 0.517083, mean_absolute_error: 0.840237, mean_q: 0.718756\n",
      "   111/50000: episode: 5, duration: 0.018s, episode steps: 10, steps per second: 558, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.107 [-1.564, 1.016], loss: 0.439281, mean_absolute_error: 0.716970, mean_q: 0.560648\n",
      "   132/50000: episode: 6, duration: 0.035s, episode steps: 21, steps per second: 603, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.571 [0.000, 1.000], mean observation: -0.066 [-1.337, 0.613], loss: 0.471944, mean_absolute_error: 0.825634, mean_q: 0.734388\n",
      "   145/50000: episode: 7, duration: 0.025s, episode steps: 13, steps per second: 525, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.385 [0.000, 1.000], mean observation: 0.097 [-1.131, 1.829], loss: 1.023579, mean_absolute_error: 1.887908, mean_q: 2.495835\n",
      "   154/50000: episode: 8, duration: 0.023s, episode steps: 9, steps per second: 393, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.139 [-1.763, 2.739], loss: 2.462092, mean_absolute_error: 2.474105, mean_q: 3.362302\n",
      "   166/50000: episode: 9, duration: 0.022s, episode steps: 12, steps per second: 545, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.250 [0.000, 1.000], mean observation: 0.117 [-1.133, 1.972], loss: 1.497650, mean_absolute_error: 2.278099, mean_q: 3.350619\n",
      "   183/50000: episode: 10, duration: 0.029s, episode steps: 17, steps per second: 593, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.353 [0.000, 1.000], mean observation: 0.086 [-1.200, 2.107], loss: 1.757339, mean_absolute_error: 2.122758, mean_q: 3.214070\n",
      "   203/50000: episode: 11, duration: 0.033s, episode steps: 20, steps per second: 597, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.300 [0.000, 1.000], mean observation: 0.076 [-1.598, 2.609], loss: 1.944662, mean_absolute_error: 2.311000, mean_q: 3.661614\n",
      "   214/50000: episode: 12, duration: 0.018s, episode steps: 11, steps per second: 602, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.091 [0.000, 1.000], mean observation: 0.128 [-1.720, 2.798], loss: 4.045606, mean_absolute_error: 3.136924, mean_q: 5.071907\n",
      "   226/50000: episode: 13, duration: 0.020s, episode steps: 12, steps per second: 595, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.083 [0.000, 1.000], mean observation: 0.116 [-1.911, 2.970], loss: 4.533197, mean_absolute_error: 3.227454, mean_q: 5.228045\n",
      "   238/50000: episode: 14, duration: 0.020s, episode steps: 12, steps per second: 598, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.083 [0.000, 1.000], mean observation: 0.118 [-1.937, 3.043], loss: 4.950334, mean_absolute_error: 3.420145, mean_q: 5.654641\n",
      "   253/50000: episode: 15, duration: 0.024s, episode steps: 15, steps per second: 615, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.267 [0.000, 1.000], mean observation: 0.079 [-1.382, 2.313], loss: 2.611557, mean_absolute_error: 2.882545, mean_q: 4.844665\n",
      "   266/50000: episode: 16, duration: 0.027s, episode steps: 13, steps per second: 474, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.308 [0.000, 1.000], mean observation: 0.104 [-0.979, 1.775], loss: 2.106768, mean_absolute_error: 3.024301, mean_q: 5.137880\n",
      "   294/50000: episode: 17, duration: 0.052s, episode steps: 28, steps per second: 542, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.286 [0.000, 1.000], mean observation: -0.030 [-2.299, 2.988], loss: 3.183763, mean_absolute_error: 3.118914, mean_q: 5.479202\n",
      "   310/50000: episode: 18, duration: 0.028s, episode steps: 16, steps per second: 580, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.312 [0.000, 1.000], mean observation: 0.080 [-1.188, 1.940], loss: 2.452974, mean_absolute_error: 3.576596, mean_q: 6.327610\n",
      "   322/50000: episode: 19, duration: 0.022s, episode steps: 12, steps per second: 544, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.167 [0.000, 1.000], mean observation: 0.134 [-1.544, 2.559], loss: 4.678564, mean_absolute_error: 3.806494, mean_q: 6.553102\n",
      "   333/50000: episode: 20, duration: 0.020s, episode steps: 11, steps per second: 558, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.091 [0.000, 1.000], mean observation: 0.125 [-1.756, 2.806], loss: 6.359454, mean_absolute_error: 4.001143, mean_q: 6.760579\n",
      "   343/50000: episode: 21, duration: 0.019s, episode steps: 10, steps per second: 518, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.100 [0.000, 1.000], mean observation: 0.144 [-1.547, 2.575], loss: 5.958042, mean_absolute_error: 3.895927, mean_q: 6.496379\n",
      "   353/50000: episode: 22, duration: 0.021s, episode steps: 10, steps per second: 480, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.100 [0.000, 1.000], mean observation: 0.130 [-1.579, 2.551], loss: 5.998308, mean_absolute_error: 4.205295, mean_q: 7.320818\n",
      "   363/50000: episode: 23, duration: 0.019s, episode steps: 10, steps per second: 538, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.100 [0.000, 1.000], mean observation: 0.133 [-1.532, 2.572], loss: 6.085086, mean_absolute_error: 4.012945, mean_q: 6.761258\n",
      "   372/50000: episode: 24, duration: 0.017s, episode steps: 9, steps per second: 525, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.158 [-1.746, 2.798], loss: 7.719575, mean_absolute_error: 4.441015, mean_q: 7.614055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   384/50000: episode: 25, duration: 0.041s, episode steps: 12, steps per second: 295, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.083 [0.000, 1.000], mean observation: 0.096 [-1.968, 3.028], loss: 6.932177, mean_absolute_error: 4.398385, mean_q: 7.840063\n",
      "   398/50000: episode: 26, duration: 0.025s, episode steps: 14, steps per second: 566, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.286 [0.000, 1.000], mean observation: 0.100 [-1.168, 2.113], loss: 3.178526, mean_absolute_error: 3.673799, mean_q: 6.587134\n",
      "   408/50000: episode: 27, duration: 0.017s, episode steps: 10, steps per second: 572, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.118 [-1.964, 3.004], loss: 8.180417, mean_absolute_error: 4.807690, mean_q: 8.486847\n",
      "   423/50000: episode: 28, duration: 0.025s, episode steps: 15, steps per second: 589, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.070 [-1.223, 1.910], loss: 2.595726, mean_absolute_error: 3.966339, mean_q: 7.307521\n",
      "   433/50000: episode: 29, duration: 0.017s, episode steps: 10, steps per second: 593, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.100 [0.000, 1.000], mean observation: 0.149 [-1.521, 2.513], loss: 5.967652, mean_absolute_error: 4.542570, mean_q: 8.157724\n",
      "   443/50000: episode: 30, duration: 0.016s, episode steps: 10, steps per second: 612, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.100 [0.000, 1.000], mean observation: 0.138 [-1.524, 2.546], loss: 6.204166, mean_absolute_error: 4.665538, mean_q: 8.493491\n",
      "   457/50000: episode: 31, duration: 0.023s, episode steps: 14, steps per second: 601, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.214 [0.000, 1.000], mean observation: 0.088 [-1.597, 2.484], loss: 4.682568, mean_absolute_error: 4.663521, mean_q: 8.582665\n",
      "   466/50000: episode: 32, duration: 0.015s, episode steps: 9, steps per second: 592, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.141 [-1.807, 2.880], loss: 8.537172, mean_absolute_error: 5.047544, mean_q: 9.024950\n",
      "   476/50000: episode: 33, duration: 0.017s, episode steps: 10, steps per second: 591, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.300 [0.000, 1.000], mean observation: 0.123 [-1.151, 1.838], loss: 4.213750, mean_absolute_error: 4.687828, mean_q: 8.686946\n",
      "   489/50000: episode: 34, duration: 0.021s, episode steps: 13, steps per second: 612, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.154 [0.000, 1.000], mean observation: 0.117 [-1.712, 2.854], loss: 5.784394, mean_absolute_error: 4.669399, mean_q: 8.640879\n",
      "   504/50000: episode: 35, duration: 0.030s, episode steps: 15, steps per second: 500, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.106 [-1.017, 1.955], loss: 3.435780, mean_absolute_error: 4.393314, mean_q: 8.186254\n",
      "   527/50000: episode: 36, duration: 0.053s, episode steps: 23, steps per second: 431, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.348 [0.000, 1.000], mean observation: 0.026 [-1.388, 2.090], loss: 3.021445, mean_absolute_error: 4.770472, mean_q: 9.005413\n",
      "   547/50000: episode: 37, duration: 0.036s, episode steps: 20, steps per second: 561, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.350 [0.000, 1.000], mean observation: 0.055 [-1.159, 1.878], loss: 2.910131, mean_absolute_error: 4.971609, mean_q: 9.313808\n",
      "   557/50000: episode: 38, duration: 0.018s, episode steps: 10, steps per second: 555, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.200 [0.000, 1.000], mean observation: 0.124 [-1.161, 2.038], loss: 5.706411, mean_absolute_error: 5.289177, mean_q: 9.632221\n",
      "   567/50000: episode: 39, duration: 0.017s, episode steps: 10, steps per second: 588, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.100 [0.000, 1.000], mean observation: 0.127 [-1.568, 2.471], loss: 6.518003, mean_absolute_error: 5.760475, mean_q: 10.728002\n",
      "   576/50000: episode: 40, duration: 0.016s, episode steps: 9, steps per second: 566, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.111 [0.000, 1.000], mean observation: 0.127 [-1.384, 2.237], loss: 6.939544, mean_absolute_error: 5.511028, mean_q: 10.167917\n",
      "   587/50000: episode: 41, duration: 0.021s, episode steps: 11, steps per second: 515, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.182 [0.000, 1.000], mean observation: 0.139 [-1.373, 2.353], loss: 5.682258, mean_absolute_error: 5.260405, mean_q: 9.705408\n",
      "   596/50000: episode: 42, duration: 0.019s, episode steps: 9, steps per second: 483, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.135 [-1.809, 2.812], loss: 8.066348, mean_absolute_error: 5.502885, mean_q: 10.304704\n",
      "   605/50000: episode: 43, duration: 0.016s, episode steps: 9, steps per second: 570, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.111 [0.000, 1.000], mean observation: 0.157 [-1.336, 2.328], loss: 6.256400, mean_absolute_error: 5.281650, mean_q: 9.795425\n",
      "   624/50000: episode: 44, duration: 0.041s, episode steps: 19, steps per second: 466, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.368 [0.000, 1.000], mean observation: 0.075 [-1.135, 1.864], loss: 3.258944, mean_absolute_error: 5.264676, mean_q: 9.923756\n",
      "   634/50000: episode: 45, duration: 0.021s, episode steps: 10, steps per second: 475, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.100 [0.000, 1.000], mean observation: 0.147 [-1.528, 2.572], loss: 5.663883, mean_absolute_error: 5.398454, mean_q: 9.937730\n",
      "   644/50000: episode: 46, duration: 0.017s, episode steps: 10, steps per second: 572, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.200 [0.000, 1.000], mean observation: 0.147 [-1.145, 2.045], loss: 4.775665, mean_absolute_error: 5.299132, mean_q: 9.700305\n",
      "   656/50000: episode: 47, duration: 0.021s, episode steps: 12, steps per second: 572, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.250 [0.000, 1.000], mean observation: 0.127 [-1.140, 1.994], loss: 3.873836, mean_absolute_error: 5.270885, mean_q: 9.633668\n",
      "   670/50000: episode: 48, duration: 0.023s, episode steps: 14, steps per second: 603, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.286 [0.000, 1.000], mean observation: 0.083 [-1.215, 2.060], loss: 3.472311, mean_absolute_error: 5.447448, mean_q: 9.925717\n",
      "   690/50000: episode: 49, duration: 0.035s, episode steps: 20, steps per second: 568, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.400 [0.000, 1.000], mean observation: 0.064 [-0.992, 1.695], loss: 2.589354, mean_absolute_error: 5.537653, mean_q: 10.147604\n",
      "   704/50000: episode: 50, duration: 0.024s, episode steps: 14, steps per second: 577, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.286 [0.000, 1.000], mean observation: 0.085 [-1.395, 2.221], loss: 3.772437, mean_absolute_error: 5.739891, mean_q: 10.223601\n",
      "   718/50000: episode: 51, duration: 0.024s, episode steps: 14, steps per second: 573, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.571 [0.000, 1.000], mean observation: -0.095 [-1.256, 0.818], loss: 8.568885, mean_absolute_error: 7.884521, mean_q: 13.684788\n",
      "   744/50000: episode: 52, duration: 0.054s, episode steps: 26, steps per second: 485, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: -0.109 [-1.362, 0.390], loss: 4.180698, mean_absolute_error: 7.010605, mean_q: 12.624450\n",
      "   753/50000: episode: 53, duration: 0.018s, episode steps: 9, steps per second: 496, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.129 [-1.857, 1.133], loss: 19.500859, mean_absolute_error: 9.493154, mean_q: 15.572629\n",
      "   771/50000: episode: 54, duration: 0.030s, episode steps: 18, steps per second: 592, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.778 [0.000, 1.000], mean observation: -0.059 [-2.941, 1.944], loss: 12.935879, mean_absolute_error: 7.803898, mean_q: 13.942612\n",
      "   788/50000: episode: 55, duration: 0.029s, episode steps: 17, steps per second: 592, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.765 [0.000, 1.000], mean observation: -0.075 [-2.759, 1.779], loss: 11.092205, mean_absolute_error: 7.780816, mean_q: 14.044588\n",
      "   802/50000: episode: 56, duration: 0.024s, episode steps: 14, steps per second: 589, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.786 [0.000, 1.000], mean observation: -0.109 [-2.567, 1.539], loss: 11.236248, mean_absolute_error: 7.719535, mean_q: 13.643557\n",
      "   825/50000: episode: 57, duration: 0.038s, episode steps: 23, steps per second: 611, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.652 [0.000, 1.000], mean observation: -0.056 [-2.266, 1.360], loss: 5.640630, mean_absolute_error: 7.106621, mean_q: 12.904770\n",
      "   838/50000: episode: 58, duration: 0.022s, episode steps: 13, steps per second: 600, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.769 [0.000, 1.000], mean observation: -0.116 [-2.338, 1.406], loss: 9.819651, mean_absolute_error: 7.869283, mean_q: 13.805715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   885/50000: episode: 59, duration: 0.091s, episode steps: 47, steps per second: 515, episode reward: 47.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.532 [0.000, 1.000], mean observation: -0.120 [-2.097, 1.022], loss: 2.821156, mean_absolute_error: 7.106096, mean_q: 13.118107\n",
      "   918/50000: episode: 60, duration: 0.055s, episode steps: 33, steps per second: 595, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: -0.066 [-0.954, 0.565], loss: 3.241620, mean_absolute_error: 7.400217, mean_q: 13.564647\n",
      "   941/50000: episode: 61, duration: 0.037s, episode steps: 23, steps per second: 616, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.565 [0.000, 1.000], mean observation: -0.089 [-1.401, 0.595], loss: 4.968449, mean_absolute_error: 7.939588, mean_q: 14.503420\n",
      "   955/50000: episode: 62, duration: 0.023s, episode steps: 14, steps per second: 599, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.214 [0.000, 1.000], mean observation: 0.097 [-1.564, 2.591], loss: 8.319593, mean_absolute_error: 8.000326, mean_q: 14.261600\n",
      "   968/50000: episode: 63, duration: 0.021s, episode steps: 13, steps per second: 612, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.615 [0.000, 1.000], mean observation: -0.106 [-1.555, 0.835], loss: 10.178108, mean_absolute_error: 8.633882, mean_q: 15.195497\n",
      "   990/50000: episode: 64, duration: 0.037s, episode steps: 22, steps per second: 600, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.364 [0.000, 1.000], mean observation: 0.059 [-1.136, 1.970], loss: 4.516575, mean_absolute_error: 7.663579, mean_q: 14.061606\n",
      "  1001/50000: episode: 65, duration: 0.019s, episode steps: 11, steps per second: 591, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.091 [0.000, 1.000], mean observation: 0.106 [-1.774, 2.754], loss: 10.258883, mean_absolute_error: 8.205516, mean_q: 14.349272\n",
      "  1018/50000: episode: 66, duration: 0.039s, episode steps: 17, steps per second: 433, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.588 [0.000, 1.000], mean observation: -0.094 [-1.354, 0.623], loss: 6.715934, mean_absolute_error: 8.206818, mean_q: 14.787057\n",
      "  1035/50000: episode: 67, duration: 0.029s, episode steps: 17, steps per second: 588, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.588 [0.000, 1.000], mean observation: -0.103 [-1.584, 0.793], loss: 7.784725, mean_absolute_error: 8.278428, mean_q: 14.750081\n",
      "  1049/50000: episode: 68, duration: 0.024s, episode steps: 14, steps per second: 585, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.643 [0.000, 1.000], mean observation: -0.088 [-1.888, 1.198], loss: 11.503844, mean_absolute_error: 8.748558, mean_q: 15.208201\n",
      "  1067/50000: episode: 69, duration: 0.031s, episode steps: 18, steps per second: 574, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.389 [0.000, 1.000], mean observation: 0.065 [-1.164, 1.901], loss: 5.846412, mean_absolute_error: 7.599317, mean_q: 13.643812\n",
      "  1079/50000: episode: 70, duration: 0.020s, episode steps: 12, steps per second: 592, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.098 [-1.710, 1.001], loss: 10.252329, mean_absolute_error: 8.342319, mean_q: 14.551714\n",
      "  1102/50000: episode: 71, duration: 0.039s, episode steps: 23, steps per second: 597, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: 0.075 [-0.647, 1.277], loss: 3.634960, mean_absolute_error: 7.145966, mean_q: 12.964561\n",
      "  1114/50000: episode: 72, duration: 0.019s, episode steps: 12, steps per second: 621, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.117 [-0.764, 1.536], loss: 7.072806, mean_absolute_error: 7.466342, mean_q: 13.185298\n",
      "  1133/50000: episode: 73, duration: 0.032s, episode steps: 19, steps per second: 602, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.421 [0.000, 1.000], mean observation: 0.048 [-1.027, 1.653], loss: 4.707535, mean_absolute_error: 7.404380, mean_q: 13.617267\n",
      "  1143/50000: episode: 74, duration: 0.023s, episode steps: 10, steps per second: 429, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.300 [0.000, 1.000], mean observation: 0.133 [-1.141, 1.918], loss: 8.220001, mean_absolute_error: 7.451192, mean_q: 13.342616\n",
      "  1155/50000: episode: 75, duration: 0.023s, episode steps: 12, steps per second: 531, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.115 [-0.773, 1.486], loss: 5.829531, mean_absolute_error: 7.090370, mean_q: 13.039410\n",
      "  1165/50000: episode: 76, duration: 0.017s, episode steps: 10, steps per second: 581, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.200 [0.000, 1.000], mean observation: 0.161 [-1.328, 2.223], loss: 7.999166, mean_absolute_error: 7.098072, mean_q: 13.058014\n",
      "  1180/50000: episode: 77, duration: 0.026s, episode steps: 15, steps per second: 583, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.200 [0.000, 1.000], mean observation: 0.075 [-1.733, 2.677], loss: 5.500558, mean_absolute_error: 7.136008, mean_q: 13.326710\n",
      "  1191/50000: episode: 78, duration: 0.019s, episode steps: 11, steps per second: 581, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.273 [0.000, 1.000], mean observation: 0.120 [-0.944, 1.730], loss: 5.730136, mean_absolute_error: 6.870696, mean_q: 12.588202\n",
      "  1204/50000: episode: 79, duration: 0.022s, episode steps: 13, steps per second: 595, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.308 [0.000, 1.000], mean observation: 0.117 [-1.145, 2.003], loss: 5.204135, mean_absolute_error: 6.689942, mean_q: 12.404084\n",
      "  1218/50000: episode: 80, duration: 0.023s, episode steps: 14, steps per second: 609, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.286 [0.000, 1.000], mean observation: 0.113 [-1.332, 2.282], loss: 4.625204, mean_absolute_error: 6.632394, mean_q: 12.293557\n",
      "  1231/50000: episode: 81, duration: 0.022s, episode steps: 13, steps per second: 589, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.308 [0.000, 1.000], mean observation: 0.113 [-0.973, 1.754], loss: 4.222106, mean_absolute_error: 6.538543, mean_q: 11.982249\n",
      "  1285/50000: episode: 82, duration: 0.103s, episode steps: 54, steps per second: 524, episode reward: 54.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.463 [0.000, 1.000], mean observation: -0.002 [-1.150, 1.407], loss: 1.746811, mean_absolute_error: 7.113573, mean_q: 13.380096\n",
      "  1317/50000: episode: 83, duration: 0.053s, episode steps: 32, steps per second: 600, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.531 [0.000, 1.000], mean observation: -0.091 [-1.386, 0.568], loss: 4.587543, mean_absolute_error: 8.288881, mean_q: 15.251172\n",
      "  1342/50000: episode: 84, duration: 0.041s, episode steps: 25, steps per second: 611, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.066 [-1.895, 1.036], loss: 6.967403, mean_absolute_error: 8.825096, mean_q: 16.084391\n",
      "  1380/50000: episode: 85, duration: 0.062s, episode steps: 38, steps per second: 613, episode reward: 38.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: -0.052 [-1.204, 0.768], loss: 4.078866, mean_absolute_error: 8.583086, mean_q: 15.928204\n",
      "  1416/50000: episode: 86, duration: 0.068s, episode steps: 36, steps per second: 526, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.084 [-0.983, 0.596], loss: 4.525257, mean_absolute_error: 9.004013, mean_q: 17.029467\n",
      "  1427/50000: episode: 87, duration: 0.020s, episode steps: 11, steps per second: 539, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.114 [-2.329, 1.422], loss: 21.381212, mean_absolute_error: 10.736106, mean_q: 18.827613\n",
      "  1440/50000: episode: 88, duration: 0.024s, episode steps: 13, steps per second: 534, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.615 [0.000, 1.000], mean observation: -0.119 [-1.325, 0.752], loss: 13.286078, mean_absolute_error: 10.022066, mean_q: 17.839305\n",
      "  1457/50000: episode: 89, duration: 0.029s, episode steps: 17, steps per second: 590, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.706 [0.000, 1.000], mean observation: -0.091 [-2.376, 1.354], loss: 11.045859, mean_absolute_error: 9.351752, mean_q: 17.001445\n",
      "  1476/50000: episode: 90, duration: 0.031s, episode steps: 19, steps per second: 609, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.526 [0.000, 1.000], mean observation: 0.085 [-0.934, 1.408], loss: 5.406592, mean_absolute_error: 8.031794, mean_q: 14.875231\n",
      "  1485/50000: episode: 91, duration: 0.015s, episode steps: 9, steps per second: 583, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.778 [0.000, 1.000], mean observation: -0.126 [-1.998, 1.228], loss: 18.699016, mean_absolute_error: 9.809171, mean_q: 16.873298\n",
      "  1503/50000: episode: 92, duration: 0.029s, episode steps: 18, steps per second: 615, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.556 [0.000, 1.000], mean observation: -0.101 [-1.215, 0.564], loss: 6.818232, mean_absolute_error: 8.700783, mean_q: 15.793711\n",
      "  1529/50000: episode: 93, duration: 0.043s, episode steps: 26, steps per second: 600, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.113 [-1.288, 0.780], loss: 5.537584, mean_absolute_error: 8.607787, mean_q: 15.853948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1555/50000: episode: 94, duration: 0.051s, episode steps: 26, steps per second: 507, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.065 [-0.614, 1.068], loss: 4.027338, mean_absolute_error: 8.099714, mean_q: 14.986073\n",
      "  1599/50000: episode: 95, duration: 0.073s, episode steps: 44, steps per second: 601, episode reward: 44.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: 0.093 [-0.950, 1.786], loss: 2.544381, mean_absolute_error: 8.312652, mean_q: 15.558463\n",
      "  1615/50000: episode: 96, duration: 0.026s, episode steps: 16, steps per second: 606, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.625 [0.000, 1.000], mean observation: -0.077 [-1.520, 0.841], loss: 9.835479, mean_absolute_error: 9.501923, mean_q: 17.074131\n",
      "  1632/50000: episode: 97, duration: 0.028s, episode steps: 17, steps per second: 604, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.647 [0.000, 1.000], mean observation: -0.112 [-1.966, 0.982], loss: 9.134319, mean_absolute_error: 9.371558, mean_q: 17.209987\n",
      "  1660/50000: episode: 98, duration: 0.045s, episode steps: 28, steps per second: 616, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.607 [0.000, 1.000], mean observation: -0.023 [-2.281, 1.587], loss: 5.620073, mean_absolute_error: 8.957880, mean_q: 16.772556\n",
      "  1675/50000: episode: 99, duration: 0.031s, episode steps: 15, steps per second: 480, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.733 [0.000, 1.000], mean observation: -0.096 [-2.444, 1.555], loss: 9.544339, mean_absolute_error: 9.026601, mean_q: 16.739036\n",
      "  1695/50000: episode: 100, duration: 0.040s, episode steps: 20, steps per second: 496, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.550 [0.000, 1.000], mean observation: -0.114 [-1.358, 0.563], loss: 6.629896, mean_absolute_error: 8.922058, mean_q: 16.563727\n",
      "  1709/50000: episode: 101, duration: 0.024s, episode steps: 14, steps per second: 586, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.786 [0.000, 1.000], mean observation: -0.124 [-2.674, 1.579], loss: 7.905835, mean_absolute_error: 8.867903, mean_q: 16.093904\n",
      "  1737/50000: episode: 102, duration: 0.046s, episode steps: 28, steps per second: 608, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.357 [0.000, 1.000], mean observation: -0.017 [-1.751, 2.270], loss: 5.836377, mean_absolute_error: 8.922214, mean_q: 16.511376\n",
      "  1771/50000: episode: 103, duration: 0.057s, episode steps: 34, steps per second: 601, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.075 [-0.576, 0.964], loss: 3.852314, mean_absolute_error: 8.777068, mean_q: 16.403233\n",
      "  1808/50000: episode: 104, duration: 0.069s, episode steps: 37, steps per second: 533, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.459 [0.000, 1.000], mean observation: 0.027 [-0.975, 1.500], loss: 3.780063, mean_absolute_error: 9.054837, mean_q: 16.969772\n",
      "  1844/50000: episode: 105, duration: 0.060s, episode steps: 36, steps per second: 599, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.528 [0.000, 1.000], mean observation: -0.075 [-1.406, 0.590], loss: 4.331088, mean_absolute_error: 9.415272, mean_q: 17.708771\n",
      "  1869/50000: episode: 106, duration: 0.041s, episode steps: 25, steps per second: 615, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.560 [0.000, 1.000], mean observation: -0.082 [-1.608, 0.792], loss: 5.654587, mean_absolute_error: 9.694982, mean_q: 18.097307\n",
      "  1897/50000: episode: 107, duration: 0.046s, episode steps: 28, steps per second: 613, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.464 [0.000, 1.000], mean observation: 0.076 [-0.581, 1.142], loss: 5.861624, mean_absolute_error: 9.729159, mean_q: 18.311696\n",
      "  1919/50000: episode: 108, duration: 0.037s, episode steps: 22, steps per second: 595, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.409 [0.000, 1.000], mean observation: 0.100 [-0.755, 1.621], loss: 7.069585, mean_absolute_error: 9.859982, mean_q: 18.313932\n",
      "  1927/50000: episode: 109, duration: 0.013s, episode steps: 8, steps per second: 608, episode reward: 8.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.250 [0.000, 1.000], mean observation: 0.142 [-1.141, 1.920], loss: 23.796770, mean_absolute_error: 10.925619, mean_q: 18.517802\n",
      "  1944/50000: episode: 110, duration: 0.040s, episode steps: 17, steps per second: 430, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.353 [0.000, 1.000], mean observation: 0.075 [-0.987, 1.796], loss: 8.163490, mean_absolute_error: 9.647363, mean_q: 17.661291\n",
      "  1959/50000: episode: 111, duration: 0.025s, episode steps: 15, steps per second: 589, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.118 [-1.882, 0.981], loss: 9.054033, mean_absolute_error: 9.518187, mean_q: 17.369941\n",
      "  2013/50000: episode: 112, duration: 0.089s, episode steps: 54, steps per second: 608, episode reward: 54.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.444 [0.000, 1.000], mean observation: -0.076 [-1.516, 1.776], loss: 3.491456, mean_absolute_error: 9.573100, mean_q: 18.176278\n",
      "  2027/50000: episode: 113, duration: 0.024s, episode steps: 14, steps per second: 593, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.357 [0.000, 1.000], mean observation: 0.116 [-1.152, 1.937], loss: 10.017802, mean_absolute_error: 9.731210, mean_q: 17.923748\n",
      "  2047/50000: episode: 114, duration: 0.033s, episode steps: 20, steps per second: 601, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.450 [0.000, 1.000], mean observation: 0.098 [-0.622, 1.357], loss: 7.706513, mean_absolute_error: 9.611851, mean_q: 17.857228\n",
      "  2061/50000: episode: 115, duration: 0.023s, episode steps: 14, steps per second: 608, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.357 [0.000, 1.000], mean observation: 0.096 [-0.834, 1.599], loss: 9.364100, mean_absolute_error: 9.302098, mean_q: 17.065626\n",
      "  2106/50000: episode: 116, duration: 0.083s, episode steps: 45, steps per second: 541, episode reward: 45.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.556 [0.000, 1.000], mean observation: 0.141 [-0.473, 0.937], loss: 3.310721, mean_absolute_error: 9.173369, mean_q: 17.337376\n",
      "  2132/50000: episode: 117, duration: 0.043s, episode steps: 26, steps per second: 609, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.069 [-0.581, 0.937], loss: 5.719769, mean_absolute_error: 9.529193, mean_q: 17.781322\n",
      "  2149/50000: episode: 118, duration: 0.028s, episode steps: 17, steps per second: 606, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.529 [0.000, 1.000], mean observation: -0.101 [-1.081, 0.569], loss: 10.621352, mean_absolute_error: 10.421501, mean_q: 19.096910\n",
      "  2164/50000: episode: 119, duration: 0.024s, episode steps: 15, steps per second: 629, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.104 [-1.518, 0.804], loss: 11.582548, mean_absolute_error: 10.332104, mean_q: 19.101822\n",
      "  2179/50000: episode: 120, duration: 0.025s, episode steps: 15, steps per second: 604, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.533 [0.000, 1.000], mean observation: -0.092 [-1.457, 0.836], loss: 10.197066, mean_absolute_error: 10.030118, mean_q: 18.410095\n",
      "  2199/50000: episode: 121, duration: 0.032s, episode steps: 20, steps per second: 621, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.550 [0.000, 1.000], mean observation: -0.096 [-1.666, 0.947], loss: 6.570394, mean_absolute_error: 9.451269, mean_q: 17.696458\n",
      "  2210/50000: episode: 122, duration: 0.019s, episode steps: 11, steps per second: 586, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.909 [0.000, 1.000], mean observation: -0.125 [-2.790, 1.747], loss: 9.301185, mean_absolute_error: 8.632928, mean_q: 15.920135\n",
      "  2224/50000: episode: 123, duration: 0.023s, episode steps: 14, steps per second: 597, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: -0.122 [-1.218, 0.744], loss: 10.513197, mean_absolute_error: 9.316143, mean_q: 16.805517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2239/50000: episode: 124, duration: 0.034s, episode steps: 15, steps per second: 439, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.085 [-1.383, 0.975], loss: 7.514233, mean_absolute_error: 8.453080, mean_q: 15.518541\n",
      "  2257/50000: episode: 125, duration: 0.032s, episode steps: 18, steps per second: 565, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.778 [0.000, 1.000], mean observation: -0.078 [-3.078, 1.950], loss: 3.786198, mean_absolute_error: 8.263674, mean_q: 15.550490\n",
      "  2282/50000: episode: 126, duration: 0.041s, episode steps: 25, steps per second: 603, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.440 [0.000, 1.000], mean observation: 0.037 [-0.752, 1.195], loss: 5.534819, mean_absolute_error: 9.218963, mean_q: 17.133625\n",
      "  2310/50000: episode: 127, duration: 0.046s, episode steps: 28, steps per second: 615, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.464 [0.000, 1.000], mean observation: -0.089 [-0.763, 0.523], loss: 5.772648, mean_absolute_error: 8.958450, mean_q: 16.473286\n",
      "  2349/50000: episode: 128, duration: 0.063s, episode steps: 39, steps per second: 615, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.308 [0.000, 1.000], mean observation: -0.056 [-2.833, 3.438], loss: 5.236012, mean_absolute_error: 9.125616, mean_q: 17.328941\n",
      "  2417/50000: episode: 129, duration: 0.125s, episode steps: 68, steps per second: 545, episode reward: 68.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.456 [0.000, 1.000], mean observation: -0.005 [-1.195, 1.921], loss: 2.745642, mean_absolute_error: 9.664364, mean_q: 18.603120\n",
      "  2516/50000: episode: 130, duration: 0.158s, episode steps: 99, steps per second: 626, episode reward: 99.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.586 [0.000, 1.000], mean observation: 0.551 [-0.890, 3.104], loss: 5.132294, mean_absolute_error: 10.845612, mean_q: 20.815217\n",
      "  2554/50000: episode: 131, duration: 0.071s, episode steps: 38, steps per second: 535, episode reward: 38.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.368 [0.000, 1.000], mean observation: -0.111 [-1.926, 2.005], loss: 5.195190, mean_absolute_error: 11.451357, mean_q: 22.107332\n",
      "  2576/50000: episode: 132, duration: 0.036s, episode steps: 22, steps per second: 608, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: 0.108 [-0.771, 1.294], loss: 9.862605, mean_absolute_error: 11.474948, mean_q: 21.492783\n",
      "  2585/50000: episode: 133, duration: 0.018s, episode steps: 9, steps per second: 497, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.128 [-1.143, 1.826], loss: 20.536177, mean_absolute_error: 11.471128, mean_q: 20.501676\n",
      "  2609/50000: episode: 134, duration: 0.040s, episode steps: 24, steps per second: 601, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.583 [0.000, 1.000], mean observation: -0.078 [-1.692, 0.824], loss: 10.047876, mean_absolute_error: 11.917180, mean_q: 22.295822\n",
      "  2669/50000: episode: 135, duration: 0.099s, episode steps: 60, steps per second: 606, episode reward: 60.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.008 [-1.087, 0.816], loss: 4.890235, mean_absolute_error: 11.521626, mean_q: 21.992225\n",
      "  2714/50000: episode: 136, duration: 0.081s, episode steps: 45, steps per second: 555, episode reward: 45.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.489 [0.000, 1.000], mean observation: -0.186 [-1.596, 1.165], loss: 5.899513, mean_absolute_error: 11.872842, mean_q: 22.716482\n",
      "  2731/50000: episode: 137, duration: 0.028s, episode steps: 17, steps per second: 599, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.588 [0.000, 1.000], mean observation: -0.094 [-1.329, 0.607], loss: 15.310616, mean_absolute_error: 12.604594, mean_q: 23.410927\n",
      "  2778/50000: episode: 138, duration: 0.077s, episode steps: 47, steps per second: 612, episode reward: 47.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.468 [0.000, 1.000], mean observation: -0.117 [-0.899, 0.720], loss: 6.082327, mean_absolute_error: 12.088460, mean_q: 23.068953\n",
      "  2798/50000: episode: 139, duration: 0.032s, episode steps: 20, steps per second: 622, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.550 [0.000, 1.000], mean observation: -0.093 [-1.319, 0.735], loss: 12.197236, mean_absolute_error: 12.398270, mean_q: 23.086101\n",
      "  2829/50000: episode: 140, duration: 0.050s, episode steps: 31, steps per second: 620, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.452 [0.000, 1.000], mean observation: 0.061 [-0.776, 1.547], loss: 7.397968, mean_absolute_error: 11.775676, mean_q: 22.257993\n",
      "  2849/50000: episode: 141, duration: 0.043s, episode steps: 20, steps per second: 467, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.090 [-0.943, 0.568], loss: 12.902249, mean_absolute_error: 11.968767, mean_q: 22.219198\n",
      "  2885/50000: episode: 142, duration: 0.061s, episode steps: 36, steps per second: 586, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.417 [0.000, 1.000], mean observation: -0.025 [-1.564, 2.113], loss: 5.714348, mean_absolute_error: 11.617663, mean_q: 22.153390\n",
      "  2900/50000: episode: 143, duration: 0.024s, episode steps: 15, steps per second: 615, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.267 [0.000, 1.000], mean observation: 0.139 [-1.334, 2.439], loss: 12.172184, mean_absolute_error: 11.598539, mean_q: 21.634990\n",
      "  2934/50000: episode: 144, duration: 0.056s, episode steps: 34, steps per second: 608, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.441 [0.000, 1.000], mean observation: 0.050 [-1.009, 1.729], loss: 5.061423, mean_absolute_error: 11.357463, mean_q: 21.684165\n",
      "  2956/50000: episode: 145, duration: 0.036s, episode steps: 22, steps per second: 613, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: -0.041 [-1.110, 0.797], loss: 11.656958, mean_absolute_error: 12.262450, mean_q: 23.064445\n",
      "  2970/50000: episode: 146, duration: 0.025s, episode steps: 14, steps per second: 568, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.124 [-1.121, 0.574], loss: 18.208001, mean_absolute_error: 12.352859, mean_q: 22.843246\n",
      "  2987/50000: episode: 147, duration: 0.039s, episode steps: 17, steps per second: 439, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.353 [0.000, 1.000], mean observation: 0.067 [-1.023, 1.773], loss: 9.240484, mean_absolute_error: 10.630904, mean_q: 19.735243\n",
      "  3004/50000: episode: 148, duration: 0.028s, episode steps: 17, steps per second: 604, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.529 [0.000, 1.000], mean observation: -0.070 [-1.175, 0.784], loss: 12.098876, mean_absolute_error: 11.286503, mean_q: 20.838164\n",
      "  3040/50000: episode: 149, duration: 0.058s, episode steps: 36, steps per second: 616, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.556 [0.000, 1.000], mean observation: -0.015 [-1.630, 1.163], loss: 5.573292, mean_absolute_error: 10.671735, mean_q: 20.419193\n",
      "  3057/50000: episode: 150, duration: 0.028s, episode steps: 17, steps per second: 608, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.097 [-1.337, 0.777], loss: 12.166599, mean_absolute_error: 11.006474, mean_q: 20.339106\n",
      "  3072/50000: episode: 151, duration: 0.025s, episode steps: 15, steps per second: 600, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.096 [-1.795, 0.990], loss: 10.270850, mean_absolute_error: 10.529051, mean_q: 19.526252\n",
      "  3103/50000: episode: 152, duration: 0.061s, episode steps: 31, steps per second: 511, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.516 [0.000, 1.000], mean observation: -0.098 [-1.214, 0.372], loss: 5.510048, mean_absolute_error: 10.601033, mean_q: 19.903344\n",
      "  3183/50000: episode: 153, duration: 0.134s, episode steps: 80, steps per second: 599, episode reward: 80.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.412 [0.000, 1.000], mean observation: -0.338 [-2.795, 1.659], loss: 3.020609, mean_absolute_error: 10.591253, mean_q: 20.358980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3275/50000: episode: 154, duration: 0.164s, episode steps: 92, steps per second: 559, episode reward: 92.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.533 [0.000, 1.000], mean observation: -0.005 [-1.576, 1.501], loss: 3.095918, mean_absolute_error: 11.895923, mean_q: 22.949371\n",
      "  3325/50000: episode: 155, duration: 0.082s, episode steps: 50, steps per second: 608, episode reward: 50.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.440 [0.000, 1.000], mean observation: -0.061 [-1.329, 1.502], loss: 5.500806, mean_absolute_error: 12.752299, mean_q: 24.694273\n",
      "  3361/50000: episode: 156, duration: 0.058s, episode steps: 36, steps per second: 620, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.417 [0.000, 1.000], mean observation: -0.029 [-1.751, 2.094], loss: 6.712268, mean_absolute_error: 13.051313, mean_q: 25.109001\n",
      "  3375/50000: episode: 157, duration: 0.023s, episode steps: 14, steps per second: 606, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: 0.096 [-0.816, 1.543], loss: 15.927781, mean_absolute_error: 13.099625, mean_q: 24.272158\n",
      "  3399/50000: episode: 158, duration: 0.041s, episode steps: 24, steps per second: 586, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.375 [0.000, 1.000], mean observation: 0.043 [-1.552, 2.334], loss: 7.298539, mean_absolute_error: 12.632099, mean_q: 24.047820\n",
      "  3416/50000: episode: 159, duration: 0.035s, episode steps: 17, steps per second: 479, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.353 [0.000, 1.000], mean observation: 0.098 [-0.961, 1.848], loss: 9.675967, mean_absolute_error: 12.397053, mean_q: 23.184567\n",
      "  3431/50000: episode: 160, duration: 0.025s, episode steps: 15, steps per second: 590, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.109 [-0.937, 1.770], loss: 12.558466, mean_absolute_error: 11.467525, mean_q: 20.881696\n",
      "  3450/50000: episode: 161, duration: 0.032s, episode steps: 19, steps per second: 602, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.684 [0.000, 1.000], mean observation: -0.046 [-2.329, 1.551], loss: 13.896183, mean_absolute_error: 13.067675, mean_q: 24.268737\n",
      "  3471/50000: episode: 162, duration: 0.035s, episode steps: 21, steps per second: 608, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: 0.095 [-0.790, 1.348], loss: 9.656689, mean_absolute_error: 11.538263, mean_q: 21.381144\n",
      "  3500/50000: episode: 163, duration: 0.048s, episode steps: 29, steps per second: 607, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.552 [0.000, 1.000], mean observation: -0.062 [-1.400, 0.752], loss: 8.183896, mean_absolute_error: 11.958246, mean_q: 22.689167\n",
      "  3513/50000: episode: 164, duration: 0.022s, episode steps: 13, steps per second: 604, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.769 [0.000, 1.000], mean observation: -0.085 [-2.395, 1.586], loss: 12.593319, mean_absolute_error: 11.440260, mean_q: 21.384882\n",
      "  3530/50000: episode: 165, duration: 0.036s, episode steps: 17, steps per second: 470, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.103 [-1.054, 0.568], loss: 12.674316, mean_absolute_error: 11.424034, mean_q: 21.042771\n",
      "  3546/50000: episode: 166, duration: 0.027s, episode steps: 16, steps per second: 599, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.625 [0.000, 1.000], mean observation: -0.094 [-1.707, 0.937], loss: 8.790699, mean_absolute_error: 10.683890, mean_q: 19.743830\n",
      "  3633/50000: episode: 167, duration: 0.142s, episode steps: 87, steps per second: 614, episode reward: 87.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.483 [0.000, 1.000], mean observation: -0.109 [-1.295, 0.987], loss: 2.827007, mean_absolute_error: 11.001019, mean_q: 21.234877\n",
      "  3658/50000: episode: 168, duration: 0.048s, episode steps: 25, steps per second: 526, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: 0.072 [-0.745, 1.307], loss: 8.954774, mean_absolute_error: 11.798015, mean_q: 22.124398\n",
      "  3690/50000: episode: 169, duration: 0.055s, episode steps: 32, steps per second: 586, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.119 [-1.359, 0.971], loss: 6.047976, mean_absolute_error: 11.618984, mean_q: 22.221001\n",
      "  3729/50000: episode: 170, duration: 0.064s, episode steps: 39, steps per second: 605, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.513 [0.000, 1.000], mean observation: -0.024 [-1.218, 0.797], loss: 5.396334, mean_absolute_error: 11.840303, mean_q: 22.532868\n",
      "  3758/50000: episode: 171, duration: 0.049s, episode steps: 29, steps per second: 587, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.483 [0.000, 1.000], mean observation: -0.091 [-0.970, 0.552], loss: 7.455371, mean_absolute_error: 11.910910, mean_q: 22.513043\n",
      "  3778/50000: episode: 172, duration: 0.033s, episode steps: 20, steps per second: 599, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.450 [0.000, 1.000], mean observation: 0.106 [-0.552, 1.118], loss: 11.725027, mean_absolute_error: 12.009805, mean_q: 22.553959\n",
      "  3791/50000: episode: 173, duration: 0.025s, episode steps: 13, steps per second: 518, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: -0.091 [-1.364, 0.832], loss: 16.272355, mean_absolute_error: 11.634889, mean_q: 20.916235\n",
      "  3889/50000: episode: 174, duration: 0.161s, episode steps: 98, steps per second: 610, episode reward: 98.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.449 [0.000, 1.000], mean observation: -0.144 [-2.123, 1.610], loss: 2.563449, mean_absolute_error: 11.636130, mean_q: 22.566742\n",
      "  3903/50000: episode: 175, duration: 0.028s, episode steps: 14, steps per second: 505, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.357 [0.000, 1.000], mean observation: 0.100 [-0.959, 1.683], loss: 15.824317, mean_absolute_error: 12.812250, mean_q: 23.751081\n",
      "  3967/50000: episode: 176, duration: 0.110s, episode steps: 64, steps per second: 580, episode reward: 64.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.438 [0.000, 1.000], mean observation: -0.222 [-2.279, 1.619], loss: 3.318844, mean_absolute_error: 11.999853, mean_q: 23.252622\n",
      "  3988/50000: episode: 177, duration: 0.034s, episode steps: 21, steps per second: 621, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.060 [-1.349, 2.097], loss: 8.153494, mean_absolute_error: 12.737429, mean_q: 24.219064\n",
      "  4008/50000: episode: 178, duration: 0.036s, episode steps: 20, steps per second: 563, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.400 [0.000, 1.000], mean observation: 0.072 [-0.996, 1.626], loss: 8.971325, mean_absolute_error: 12.360272, mean_q: 23.136677\n",
      "  4021/50000: episode: 179, duration: 0.026s, episode steps: 13, steps per second: 491, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.385 [0.000, 1.000], mean observation: 0.112 [-0.797, 1.491], loss: 14.243992, mean_absolute_error: 12.062768, mean_q: 21.765673\n",
      "  4039/50000: episode: 180, duration: 0.040s, episode steps: 18, steps per second: 456, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.090 [-1.084, 0.608], loss: 15.386759, mean_absolute_error: 13.139169, mean_q: 24.585388\n",
      "  4105/50000: episode: 181, duration: 0.107s, episode steps: 66, steps per second: 614, episode reward: 66.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.021 [-1.230, 1.141], loss: 4.675903, mean_absolute_error: 12.404014, mean_q: 23.906366\n",
      "  4121/50000: episode: 182, duration: 0.026s, episode steps: 16, steps per second: 607, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.102 [-1.231, 0.748], loss: 17.365457, mean_absolute_error: 12.968009, mean_q: 24.031508\n",
      "  4134/50000: episode: 183, duration: 0.021s, episode steps: 13, steps per second: 632, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: -0.096 [-1.309, 0.769], loss: 17.756889, mean_absolute_error: 12.772417, mean_q: 23.485082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4154/50000: episode: 184, duration: 0.041s, episode steps: 20, steps per second: 484, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.122 [-0.974, 0.539], loss: 15.205692, mean_absolute_error: 12.437235, mean_q: 22.837117\n",
      "  4182/50000: episode: 185, duration: 0.046s, episode steps: 28, steps per second: 604, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.049 [-1.062, 0.603], loss: 7.602037, mean_absolute_error: 11.842877, mean_q: 22.367790\n",
      "  4193/50000: episode: 186, duration: 0.019s, episode steps: 11, steps per second: 592, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.364 [0.000, 1.000], mean observation: 0.096 [-0.984, 1.610], loss: 11.820322, mean_absolute_error: 10.808317, mean_q: 19.792373\n",
      "  4233/50000: episode: 187, duration: 0.065s, episode steps: 40, steps per second: 614, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.450 [0.000, 1.000], mean observation: -0.062 [-1.147, 1.391], loss: 3.335927, mean_absolute_error: 10.641513, mean_q: 20.276621\n",
      "  4285/50000: episode: 188, duration: 0.089s, episode steps: 52, steps per second: 582, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.481 [0.000, 1.000], mean observation: -0.118 [-0.956, 0.544], loss: 4.960864, mean_absolute_error: 11.651912, mean_q: 22.459845\n",
      "  4306/50000: episode: 189, duration: 0.037s, episode steps: 21, steps per second: 566, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: 0.102 [-0.818, 1.640], loss: 7.598949, mean_absolute_error: 11.880116, mean_q: 22.003405\n",
      "  4354/50000: episode: 190, duration: 0.082s, episode steps: 48, steps per second: 589, episode reward: 48.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.479 [0.000, 1.000], mean observation: -0.138 [-1.123, 0.610], loss: 4.928375, mean_absolute_error: 12.047900, mean_q: 23.186465\n",
      "  4444/50000: episode: 191, duration: 0.156s, episode steps: 90, steps per second: 576, episode reward: 90.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: -0.186 [-1.857, 0.893], loss: 3.726734, mean_absolute_error: 12.403072, mean_q: 24.041697\n",
      "  4470/50000: episode: 192, duration: 0.043s, episode steps: 26, steps per second: 607, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.050 [-0.961, 1.366], loss: 11.372910, mean_absolute_error: 12.882463, mean_q: 23.909941\n",
      "  4489/50000: episode: 193, duration: 0.032s, episode steps: 19, steps per second: 603, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.579 [0.000, 1.000], mean observation: -0.104 [-1.478, 0.593], loss: 14.930741, mean_absolute_error: 13.795002, mean_q: 25.823727\n",
      "  4541/50000: episode: 194, duration: 0.083s, episode steps: 52, steps per second: 624, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.043 [-1.564, 1.890], loss: 4.277139, mean_absolute_error: 12.503888, mean_q: 24.006176\n",
      "  4559/50000: episode: 195, duration: 0.030s, episode steps: 18, steps per second: 596, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.556 [0.000, 1.000], mean observation: -0.084 [-1.351, 0.653], loss: 14.102424, mean_absolute_error: 13.844652, mean_q: 26.099940\n",
      "  4595/50000: episode: 196, duration: 0.072s, episode steps: 36, steps per second: 503, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.472 [0.000, 1.000], mean observation: 0.066 [-1.044, 1.605], loss: 6.826884, mean_absolute_error: 12.914040, mean_q: 24.442729\n",
      "  4642/50000: episode: 197, duration: 0.078s, episode steps: 47, steps per second: 602, episode reward: 47.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.511 [0.000, 1.000], mean observation: -0.041 [-1.185, 0.755], loss: 5.957727, mean_absolute_error: 13.200939, mean_q: 25.468212\n",
      "  4663/50000: episode: 198, duration: 0.035s, episode steps: 21, steps per second: 603, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: 0.079 [-0.812, 1.260], loss: 12.073890, mean_absolute_error: 12.714271, mean_q: 23.725567\n",
      "  4686/50000: episode: 199, duration: 0.037s, episode steps: 23, steps per second: 619, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.522 [0.000, 1.000], mean observation: 0.124 [-0.369, 0.895], loss: 12.471037, mean_absolute_error: 12.967282, mean_q: 23.912845\n",
      "  4718/50000: episode: 200, duration: 0.058s, episode steps: 32, steps per second: 548, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.079 [-1.175, 0.569], loss: 8.151485, mean_absolute_error: 12.848806, mean_q: 24.601097\n",
      "  4844/50000: episode: 201, duration: 0.213s, episode steps: 126, steps per second: 591, episode reward: 126.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: -0.085 [-1.285, 0.912], loss: 2.979777, mean_absolute_error: 13.385794, mean_q: 26.232695\n",
      "  4860/50000: episode: 202, duration: 0.031s, episode steps: 16, steps per second: 518, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.090 [-0.829, 1.166], loss: 17.865409, mean_absolute_error: 14.108858, mean_q: 25.762072\n",
      "  4885/50000: episode: 203, duration: 0.041s, episode steps: 25, steps per second: 604, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: 0.069 [-0.607, 1.241], loss: 9.508558, mean_absolute_error: 13.953286, mean_q: 26.182172\n",
      "  4903/50000: episode: 204, duration: 0.040s, episode steps: 18, steps per second: 447, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.112 [-0.738, 1.276], loss: 17.474488, mean_absolute_error: 13.581992, mean_q: 24.611750\n",
      "  4929/50000: episode: 205, duration: 0.043s, episode steps: 26, steps per second: 598, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.028 [-1.058, 0.754], loss: 13.849226, mean_absolute_error: 13.932372, mean_q: 26.516949\n",
      "  4959/50000: episode: 206, duration: 0.051s, episode steps: 30, steps per second: 586, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.027 [-1.237, 0.648], loss: 10.418587, mean_absolute_error: 13.907964, mean_q: 26.633294\n",
      "  4973/50000: episode: 207, duration: 0.030s, episode steps: 14, steps per second: 468, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.571 [0.000, 1.000], mean observation: -0.085 [-1.524, 0.958], loss: 20.313860, mean_absolute_error: 13.248090, mean_q: 24.413505\n",
      "  4998/50000: episode: 208, duration: 0.042s, episode steps: 25, steps per second: 600, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.440 [0.000, 1.000], mean observation: -0.117 [-1.043, 0.587], loss: 10.884776, mean_absolute_error: 12.605909, mean_q: 23.956774\n",
      "  5068/50000: episode: 209, duration: 0.114s, episode steps: 70, steps per second: 613, episode reward: 70.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.457 [0.000, 1.000], mean observation: -0.169 [-1.064, 0.573], loss: 3.838077, mean_absolute_error: 12.230722, mean_q: 23.973497\n",
      "  5081/50000: episode: 210, duration: 0.027s, episode steps: 13, steps per second: 490, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.308 [0.000, 1.000], mean observation: 0.105 [-1.229, 2.040], loss: 10.897822, mean_absolute_error: 12.383979, mean_q: 22.641913\n",
      "  5105/50000: episode: 211, duration: 0.048s, episode steps: 24, steps per second: 502, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.458 [0.000, 1.000], mean observation: 0.039 [-1.206, 1.709], loss: 6.753675, mean_absolute_error: 12.118772, mean_q: 22.987997\n",
      "  5190/50000: episode: 212, duration: 0.137s, episode steps: 85, steps per second: 619, episode reward: 85.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.447 [0.000, 1.000], mean observation: -0.367 [-2.074, 0.740], loss: 3.591273, mean_absolute_error: 11.547234, mean_q: 22.535565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5249/50000: episode: 213, duration: 0.107s, episode steps: 59, steps per second: 549, episode reward: 59.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.172 [-1.200, 0.469], loss: 5.229940, mean_absolute_error: 13.725474, mean_q: 26.811776\n",
      "  5333/50000: episode: 214, duration: 0.135s, episode steps: 84, steps per second: 622, episode reward: 84.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.091 [-0.938, 1.148], loss: 7.206359, mean_absolute_error: 15.925575, mean_q: 30.975300\n",
      "  5351/50000: episode: 215, duration: 0.030s, episode steps: 18, steps per second: 602, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.072 [-1.076, 0.624], loss: 24.992291, mean_absolute_error: 16.108582, mean_q: 30.359860\n",
      "  5407/50000: episode: 216, duration: 0.101s, episode steps: 56, steps per second: 556, episode reward: 56.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.482 [0.000, 1.000], mean observation: -0.001 [-1.235, 0.968], loss: 7.860139, mean_absolute_error: 14.799782, mean_q: 28.813084\n",
      "  5431/50000: episode: 217, duration: 0.040s, episode steps: 24, steps per second: 602, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.458 [0.000, 1.000], mean observation: -0.068 [-1.184, 0.760], loss: 15.949291, mean_absolute_error: 14.877677, mean_q: 28.216677\n",
      "  5453/50000: episode: 218, duration: 0.035s, episode steps: 22, steps per second: 623, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: -0.110 [-1.511, 0.567], loss: 11.368150, mean_absolute_error: 14.491279, mean_q: 27.271966\n",
      "  5483/50000: episode: 219, duration: 0.051s, episode steps: 30, steps per second: 593, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.115 [-0.939, 0.410], loss: 8.786065, mean_absolute_error: 13.648251, mean_q: 26.259105\n",
      "  5573/50000: episode: 220, duration: 0.158s, episode steps: 90, steps per second: 570, episode reward: 90.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.456 [0.000, 1.000], mean observation: -0.240 [-1.843, 0.673], loss: 2.794090, mean_absolute_error: 12.718566, mean_q: 25.037960\n",
      "  5697/50000: episode: 221, duration: 0.200s, episode steps: 124, steps per second: 619, episode reward: 124.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: -0.089 [-1.504, 1.102], loss: 3.048908, mean_absolute_error: 14.840231, mean_q: 29.266841\n",
      "  5770/50000: episode: 222, duration: 0.129s, episode steps: 73, steps per second: 567, episode reward: 73.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.521 [0.000, 1.000], mean observation: 0.110 [-1.168, 1.313], loss: 10.628696, mean_absolute_error: 18.559861, mean_q: 35.990077\n",
      "  5801/50000: episode: 223, duration: 0.051s, episode steps: 31, steps per second: 605, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.484 [0.000, 1.000], mean observation: -0.070 [-0.990, 0.633], loss: 13.831888, mean_absolute_error: 17.359482, mean_q: 33.143807\n",
      "  5945/50000: episode: 224, duration: 0.247s, episode steps: 144, steps per second: 583, episode reward: 144.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.493 [0.000, 1.000], mean observation: 0.170 [-1.088, 1.482], loss: 4.897758, mean_absolute_error: 18.961380, mean_q: 37.423545\n",
      "  5966/50000: episode: 225, duration: 0.034s, episode steps: 21, steps per second: 620, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.381 [0.000, 1.000], mean observation: 0.047 [-1.123, 1.802], loss: 17.148624, mean_absolute_error: 18.025426, mean_q: 33.825227\n",
      "  6016/50000: episode: 226, duration: 0.081s, episode steps: 50, steps per second: 617, episode reward: 50.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.026 [-1.074, 0.958], loss: 12.834469, mean_absolute_error: 19.239488, mean_q: 37.368159\n",
      "  6031/50000: episode: 227, duration: 0.025s, episode steps: 15, steps per second: 612, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.533 [0.000, 1.000], mean observation: -0.109 [-1.096, 0.620], loss: 31.684442, mean_absolute_error: 18.494000, mean_q: 34.631246\n",
      "  6088/50000: episode: 228, duration: 0.105s, episode steps: 57, steps per second: 543, episode reward: 57.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.421 [0.000, 1.000], mean observation: -0.271 [-1.657, 0.572], loss: 4.154006, mean_absolute_error: 13.857589, mean_q: 27.394798\n",
      "  6148/50000: episode: 229, duration: 0.100s, episode steps: 60, steps per second: 600, episode reward: 60.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.450 [0.000, 1.000], mean observation: -0.165 [-2.048, 1.501], loss: 3.521372, mean_absolute_error: 14.147038, mean_q: 27.859123\n",
      "  6233/50000: episode: 230, duration: 0.150s, episode steps: 85, steps per second: 567, episode reward: 85.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.482 [0.000, 1.000], mean observation: -0.147 [-0.989, 0.893], loss: 4.472871, mean_absolute_error: 16.406937, mean_q: 32.173952\n",
      "  6268/50000: episode: 231, duration: 0.058s, episode steps: 35, steps per second: 609, episode reward: 35.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: -0.000 [-1.225, 1.855], loss: 8.770108, mean_absolute_error: 17.315158, mean_q: 33.264315\n",
      "  6309/50000: episode: 232, duration: 0.067s, episode steps: 41, steps per second: 609, episode reward: 41.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: -0.013 [-1.064, 0.807], loss: 12.551620, mean_absolute_error: 18.576215, mean_q: 36.163469\n",
      "  6335/50000: episode: 233, duration: 0.043s, episode steps: 26, steps per second: 611, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.136 [-0.814, 0.352], loss: 13.000400, mean_absolute_error: 16.376976, mean_q: 31.602167\n",
      "  6475/50000: episode: 234, duration: 0.235s, episode steps: 140, steps per second: 595, episode reward: 140.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.486 [0.000, 1.000], mean observation: -0.237 [-1.319, 0.872], loss: 3.562817, mean_absolute_error: 15.231253, mean_q: 30.070889\n",
      "  6502/50000: episode: 235, duration: 0.044s, episode steps: 27, steps per second: 617, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.481 [0.000, 1.000], mean observation: -0.080 [-1.096, 0.613], loss: 18.888021, mean_absolute_error: 18.528514, mean_q: 35.597174\n",
      "  6536/50000: episode: 236, duration: 0.055s, episode steps: 34, steps per second: 619, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.035 [-1.006, 0.724], loss: 14.160034, mean_absolute_error: 17.672591, mean_q: 34.311208\n",
      "  6562/50000: episode: 237, duration: 0.042s, episode steps: 26, steps per second: 619, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.065 [-0.944, 0.615], loss: 16.978711, mean_absolute_error: 16.733051, mean_q: 32.126092\n",
      "  6641/50000: episode: 238, duration: 0.139s, episode steps: 79, steps per second: 570, episode reward: 79.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.506 [0.000, 1.000], mean observation: 0.117 [-1.049, 1.278], loss: 8.216306, mean_absolute_error: 18.968771, mean_q: 37.333604\n",
      "  6786/50000: episode: 239, duration: 0.247s, episode steps: 145, steps per second: 587, episode reward: 145.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.483 [0.000, 1.000], mean observation: -0.251 [-1.907, 1.228], loss: 3.566184, mean_absolute_error: 15.208426, mean_q: 30.041084\n",
      "  6799/50000: episode: 240, duration: 0.022s, episode steps: 13, steps per second: 585, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.095 [-1.292, 0.788], loss: 39.928333, mean_absolute_error: 18.377586, mean_q: 34.251436\n",
      "  6883/50000: episode: 241, duration: 0.136s, episode steps: 84, steps per second: 620, episode reward: 84.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.452 [0.000, 1.000], mean observation: -0.327 [-1.664, 0.680], loss: 3.332272, mean_absolute_error: 14.282150, mean_q: 27.984526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6911/50000: episode: 242, duration: 0.048s, episode steps: 28, steps per second: 578, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: 0.019 [-1.224, 1.883], loss: 14.682121, mean_absolute_error: 18.432653, mean_q: 35.433227\n",
      "  6924/50000: episode: 243, duration: 0.030s, episode steps: 13, steps per second: 436, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: 0.122 [-0.936, 1.503], loss: 38.736599, mean_absolute_error: 17.955500, mean_q: 32.476982\n",
      "  6949/50000: episode: 244, duration: 0.041s, episode steps: 25, steps per second: 603, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.440 [0.000, 1.000], mean observation: 0.073 [-0.653, 1.577], loss: 20.718245, mean_absolute_error: 18.137517, mean_q: 33.511546\n",
      "  7095/50000: episode: 245, duration: 0.250s, episode steps: 146, steps per second: 585, episode reward: 146.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.486 [0.000, 1.000], mean observation: -0.144 [-1.177, 0.774], loss: 2.721187, mean_absolute_error: 15.905066, mean_q: 31.544900\n",
      "  7126/50000: episode: 246, duration: 0.050s, episode steps: 31, steps per second: 625, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.452 [0.000, 1.000], mean observation: -0.081 [-0.984, 0.551], loss: 14.760166, mean_absolute_error: 18.053691, mean_q: 35.274684\n",
      "  7243/50000: episode: 247, duration: 0.196s, episode steps: 117, steps per second: 597, episode reward: 117.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.479 [0.000, 1.000], mean observation: -0.165 [-1.053, 0.838], loss: 3.859165, mean_absolute_error: 17.271370, mean_q: 34.186983\n",
      "  7290/50000: episode: 248, duration: 0.077s, episode steps: 47, steps per second: 614, episode reward: 47.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.447 [0.000, 1.000], mean observation: -0.156 [-1.399, 0.932], loss: 5.496491, mean_absolute_error: 16.746025, mean_q: 33.200875\n",
      "  7381/50000: episode: 249, duration: 0.159s, episode steps: 91, steps per second: 573, episode reward: 91.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.451 [0.000, 1.000], mean observation: -0.370 [-1.665, 0.766], loss: 2.525383, mean_absolute_error: 14.527635, mean_q: 28.959785\n",
      "  7413/50000: episode: 250, duration: 0.053s, episode steps: 32, steps per second: 598, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.438 [0.000, 1.000], mean observation: -0.115 [-0.930, 0.426], loss: 12.566924, mean_absolute_error: 18.505589, mean_q: 36.464101\n",
      "  7472/50000: episode: 251, duration: 0.093s, episode steps: 59, steps per second: 631, episode reward: 59.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.559 [0.000, 1.000], mean observation: 0.115 [-1.738, 1.909], loss: 20.089569, mean_absolute_error: 22.643175, mean_q: 44.099493\n",
      "  7556/50000: episode: 252, duration: 0.151s, episode steps: 84, steps per second: 558, episode reward: 84.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: -0.164 [-1.324, 1.341], loss: 6.923076, mean_absolute_error: 16.865665, mean_q: 33.221897\n",
      "  7604/50000: episode: 253, duration: 0.079s, episode steps: 48, steps per second: 611, episode reward: 48.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.542 [0.000, 1.000], mean observation: 0.125 [-0.394, 0.797], loss: 21.688495, mean_absolute_error: 21.293840, mean_q: 41.373360\n",
      "  7752/50000: episode: 254, duration: 0.250s, episode steps: 148, steps per second: 592, episode reward: 148.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.507 [0.000, 1.000], mean observation: 0.258 [-0.726, 1.161], loss: 9.225569, mean_absolute_error: 22.862715, mean_q: 45.161173\n",
      "  7869/50000: episode: 255, duration: 0.190s, episode steps: 117, steps per second: 617, episode reward: 117.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.444 [0.000, 1.000], mean observation: -0.463 [-2.906, 0.812], loss: 4.213577, mean_absolute_error: 15.765430, mean_q: 31.049383\n",
      "  7896/50000: episode: 256, duration: 0.053s, episode steps: 27, steps per second: 512, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.481 [0.000, 1.000], mean observation: 0.056 [-0.747, 1.122], loss: 29.901727, mean_absolute_error: 21.842588, mean_q: 41.073344\n",
      "  7922/50000: episode: 257, duration: 0.043s, episode steps: 26, steps per second: 598, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.049 [-1.222, 0.820], loss: 25.369865, mean_absolute_error: 20.823490, mean_q: 40.268237\n",
      "  8086/50000: episode: 258, duration: 0.274s, episode steps: 164, steps per second: 599, episode reward: 164.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.457 [0.000, 1.000], mean observation: -0.333 [-2.522, 0.697], loss: 2.391699, mean_absolute_error: 16.987419, mean_q: 33.844066\n",
      "  8240/50000: episode: 259, duration: 0.256s, episode steps: 154, steps per second: 601, episode reward: 154.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: -0.246 [-1.660, 0.780], loss: 3.306107, mean_absolute_error: 20.060168, mean_q: 40.004629\n",
      "  8390/50000: episode: 260, duration: 0.253s, episode steps: 150, steps per second: 593, episode reward: 150.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.473 [0.000, 1.000], mean observation: -0.255 [-1.661, 0.729], loss: 4.199133, mean_absolute_error: 21.659925, mean_q: 43.063107\n",
      "  8415/50000: episode: 261, duration: 0.044s, episode steps: 25, steps per second: 570, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.056 [-1.127, 0.581], loss: 41.072190, mean_absolute_error: 25.968556, mean_q: 50.190803\n",
      "  8434/50000: episode: 262, duration: 0.032s, episode steps: 19, steps per second: 597, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: -0.086 [-1.166, 0.753], loss: 41.186059, mean_absolute_error: 23.316152, mean_q: 44.662330\n",
      "  8453/50000: episode: 263, duration: 0.031s, episode steps: 19, steps per second: 605, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.526 [0.000, 1.000], mean observation: -0.078 [-1.343, 0.783], loss: 31.144853, mean_absolute_error: 21.618667, mean_q: 40.864660\n",
      "  8551/50000: episode: 264, duration: 0.167s, episode steps: 98, steps per second: 588, episode reward: 98.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.418 [0.000, 1.000], mean observation: -0.549 [-2.975, 0.987], loss: 5.282958, mean_absolute_error: 13.789327, mean_q: 26.624789\n",
      "  8751/50000: episode: 265, duration: 0.332s, episode steps: 200, steps per second: 602, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.332 [-1.105, 2.094], loss: 11.019239, mean_absolute_error: 26.764110, mean_q: 53.150056\n",
      "  8766/50000: episode: 266, duration: 0.026s, episode steps: 15, steps per second: 584, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.267 [0.000, 1.000], mean observation: 0.087 [-1.370, 2.249], loss: 49.556537, mean_absolute_error: 24.588963, mean_q: 45.620470\n",
      "  8786/50000: episode: 267, duration: 0.033s, episode steps: 20, steps per second: 614, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.059 [-0.798, 1.183], loss: 48.433319, mean_absolute_error: 22.138207, mean_q: 40.378463\n",
      "  8804/50000: episode: 268, duration: 0.028s, episode steps: 18, steps per second: 632, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.082 [-0.596, 1.023], loss: 38.130558, mean_absolute_error: 21.715013, mean_q: 39.790184\n",
      "  8819/50000: episode: 269, duration: 0.025s, episode steps: 15, steps per second: 601, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.400 [0.000, 1.000], mean observation: 0.077 [-1.192, 1.737], loss: 33.676717, mean_absolute_error: 18.423552, mean_q: 33.577261\n",
      "  9019/50000: episode: 270, duration: 0.339s, episode steps: 200, steps per second: 591, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.045 [-1.302, 1.139], loss: 2.723793, mean_absolute_error: 18.552298, mean_q: 36.970922\n",
      "  9099/50000: episode: 271, duration: 0.133s, episode steps: 80, steps per second: 601, episode reward: 80.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.425 [0.000, 1.000], mean observation: -0.430 [-2.188, 0.775], loss: 2.524594, mean_absolute_error: 14.900279, mean_q: 29.728283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9229/50000: episode: 272, duration: 0.221s, episode steps: 130, steps per second: 587, episode reward: 130.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: -0.243 [-1.634, 0.791], loss: 2.156288, mean_absolute_error: 19.088095, mean_q: 38.217058\n",
      "  9346/50000: episode: 273, duration: 0.195s, episode steps: 117, steps per second: 600, episode reward: 117.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.453 [0.000, 1.000], mean observation: -0.367 [-2.044, 0.562], loss: 2.430857, mean_absolute_error: 18.113903, mean_q: 36.166303\n",
      "  9484/50000: episode: 274, duration: 0.234s, episode steps: 138, steps per second: 590, episode reward: 138.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.449 [0.000, 1.000], mean observation: -0.424 [-2.590, 0.765], loss: 3.157897, mean_absolute_error: 19.215049, mean_q: 38.350293\n",
      "  9620/50000: episode: 275, duration: 0.233s, episode steps: 136, steps per second: 583, episode reward: 136.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.441 [0.000, 1.000], mean observation: -0.404 [-3.088, 0.609], loss: 2.940938, mean_absolute_error: 20.499102, mean_q: 40.925477\n",
      "  9650/50000: episode: 276, duration: 0.051s, episode steps: 30, steps per second: 589, episode reward: 30.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.433 [0.000, 1.000], mean observation: -0.101 [-1.241, 0.748], loss: 34.233355, mean_absolute_error: 26.396148, mean_q: 51.833433\n",
      "  9686/50000: episode: 277, duration: 0.059s, episode steps: 36, steps per second: 611, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.472 [0.000, 1.000], mean observation: -0.113 [-1.008, 0.553], loss: 15.581456, mean_absolute_error: 23.573761, mean_q: 46.224610\n",
      "  9791/50000: episode: 278, duration: 0.179s, episode steps: 105, steps per second: 587, episode reward: 105.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.438 [0.000, 1.000], mean observation: -0.519 [-2.514, 0.822], loss: 2.475096, mean_absolute_error: 15.741894, mean_q: 31.608459\n",
      "  9921/50000: episode: 279, duration: 0.219s, episode steps: 130, steps per second: 593, episode reward: 130.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.454 [0.000, 1.000], mean observation: -0.443 [-2.415, 1.116], loss: 3.033524, mean_absolute_error: 18.234511, mean_q: 36.530315\n",
      " 10057/50000: episode: 280, duration: 0.226s, episode steps: 136, steps per second: 602, episode reward: 136.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.456 [0.000, 1.000], mean observation: -0.440 [-2.434, 0.848], loss: 3.468097, mean_absolute_error: 20.053736, mean_q: 40.071633\n",
      " 10079/50000: episode: 281, duration: 0.038s, episode steps: 22, steps per second: 577, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: -0.121 [-0.948, 0.634], loss: 41.316341, mean_absolute_error: 25.852040, mean_q: 50.101226\n",
      " 10279/50000: episode: 282, duration: 0.339s, episode steps: 200, steps per second: 589, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.108 [-1.147, 1.123], loss: 5.694081, mean_absolute_error: 24.707959, mean_q: 49.280247\n",
      " 10479/50000: episode: 283, duration: 0.332s, episode steps: 200, steps per second: 602, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.294 [-0.933, 1.806], loss: 14.245891, mean_absolute_error: 33.698425, mean_q: 66.991983\n",
      " 10497/50000: episode: 284, duration: 0.029s, episode steps: 18, steps per second: 620, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.444 [0.000, 1.000], mean observation: 0.071 [-0.805, 1.400], loss: 64.654441, mean_absolute_error: 29.620141, mean_q: 55.199203\n",
      " 10521/50000: episode: 285, duration: 0.044s, episode steps: 24, steps per second: 546, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.067 [-0.761, 1.099], loss: 47.650490, mean_absolute_error: 26.480643, mean_q: 49.335571\n",
      " 10720/50000: episode: 286, duration: 0.332s, episode steps: 199, steps per second: 600, episode reward: 199.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.477 [0.000, 1.000], mean observation: -0.244 [-1.938, 0.808], loss: 2.270064, mean_absolute_error: 21.634878, mean_q: 43.237110\n",
      " 10832/50000: episode: 287, duration: 0.183s, episode steps: 112, steps per second: 611, episode reward: 112.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.438 [0.000, 1.000], mean observation: -0.489 [-2.776, 0.546], loss: 2.050323, mean_absolute_error: 18.561920, mean_q: 37.261411\n",
      " 10965/50000: episode: 288, duration: 0.225s, episode steps: 133, steps per second: 590, episode reward: 133.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.459 [0.000, 1.000], mean observation: -0.467 [-2.435, 0.779], loss: 3.055957, mean_absolute_error: 20.481478, mean_q: 41.097990\n",
      " 11085/50000: episode: 289, duration: 0.200s, episode steps: 120, steps per second: 599, episode reward: 120.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.450 [0.000, 1.000], mean observation: -0.443 [-2.171, 0.703], loss: 2.717188, mean_absolute_error: 21.017157, mean_q: 42.185937\n",
      " 11184/50000: episode: 290, duration: 0.168s, episode steps: 99, steps per second: 588, episode reward: 99.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.434 [0.000, 1.000], mean observation: -0.547 [-2.580, 0.687], loss: 2.320875, mean_absolute_error: 18.401109, mean_q: 37.037410\n",
      " 11290/50000: episode: 291, duration: 0.182s, episode steps: 106, steps per second: 581, episode reward: 106.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.434 [0.000, 1.000], mean observation: -0.501 [-3.081, 0.705], loss: 1.393448, mean_absolute_error: 19.395850, mean_q: 38.999330\n",
      " 11410/50000: episode: 292, duration: 0.196s, episode steps: 120, steps per second: 613, episode reward: 120.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.450 [0.000, 1.000], mean observation: -0.484 [-2.421, 0.787], loss: 2.563344, mean_absolute_error: 20.822177, mean_q: 41.686219\n",
      " 11544/50000: episode: 293, duration: 0.224s, episode steps: 134, steps per second: 597, episode reward: 134.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: -0.459 [-2.447, 0.817], loss: 2.212400, mean_absolute_error: 21.918118, mean_q: 44.001354\n",
      " 11561/50000: episode: 294, duration: 0.028s, episode steps: 17, steps per second: 606, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.529 [0.000, 1.000], mean observation: -0.087 [-1.421, 0.955], loss: 92.632782, mean_absolute_error: 31.655923, mean_q: 60.593146\n",
      " 11574/50000: episode: 295, duration: 0.022s, episode steps: 13, steps per second: 601, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: -0.124 [-1.208, 0.734], loss: 80.842340, mean_absolute_error: 27.718007, mean_q: 52.030985\n",
      " 11685/50000: episode: 296, duration: 0.192s, episode steps: 111, steps per second: 578, episode reward: 111.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.468 [0.000, 1.000], mean observation: -0.487 [-2.404, 0.976], loss: 3.638288, mean_absolute_error: 16.590358, mean_q: 32.764636\n",
      " 11808/50000: episode: 297, duration: 0.199s, episode steps: 123, steps per second: 619, episode reward: 123.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.504 [0.000, 1.000], mean observation: 0.215 [-1.113, 1.499], loss: 14.629819, mean_absolute_error: 29.077637, mean_q: 57.607521\n",
      " 11829/50000: episode: 298, duration: 0.052s, episode steps: 21, steps per second: 404, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: 0.099 [-0.750, 1.430], loss: 48.699172, mean_absolute_error: 27.459990, mean_q: 51.131359\n",
      " 11843/50000: episode: 299, duration: 0.024s, episode steps: 14, steps per second: 578, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: 0.108 [-0.945, 1.590], loss: 66.537476, mean_absolute_error: 24.972592, mean_q: 44.948085\n",
      " 11996/50000: episode: 300, duration: 0.273s, episode steps: 153, steps per second: 561, episode reward: 153.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.464 [0.000, 1.000], mean observation: -0.384 [-2.435, 0.670], loss: 1.222618, mean_absolute_error: 17.382914, mean_q: 34.972013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12139/50000: episode: 301, duration: 0.246s, episode steps: 143, steps per second: 582, episode reward: 143.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: -0.425 [-2.422, 0.747], loss: 2.201093, mean_absolute_error: 18.428147, mean_q: 36.926607\n",
      " 12298/50000: episode: 302, duration: 0.266s, episode steps: 159, steps per second: 599, episode reward: 159.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.484 [0.000, 1.000], mean observation: -0.431 [-2.419, 0.864], loss: 3.012517, mean_absolute_error: 20.080100, mean_q: 40.167188\n",
      " 12435/50000: episode: 303, duration: 0.230s, episode steps: 137, steps per second: 597, episode reward: 137.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.460 [-2.402, 0.663], loss: 2.688533, mean_absolute_error: 21.278178, mean_q: 42.695134\n",
      " 12549/50000: episode: 304, duration: 0.188s, episode steps: 114, steps per second: 607, episode reward: 114.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.439 [0.000, 1.000], mean observation: -0.480 [-2.701, 0.627], loss: 1.934429, mean_absolute_error: 20.781505, mean_q: 41.778990\n",
      " 12691/50000: episode: 305, duration: 0.240s, episode steps: 142, steps per second: 591, episode reward: 142.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.458 [0.000, 1.000], mean observation: -0.292 [-2.587, 0.754], loss: 1.958225, mean_absolute_error: 24.690252, mean_q: 49.499441\n",
      " 12846/50000: episode: 306, duration: 0.262s, episode steps: 155, steps per second: 591, episode reward: 155.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.477 [0.000, 1.000], mean observation: -0.393 [-2.404, 0.742], loss: 2.780221, mean_absolute_error: 23.184232, mean_q: 46.530613\n",
      " 12978/50000: episode: 307, duration: 0.217s, episode steps: 132, steps per second: 609, episode reward: 132.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.436 [-2.402, 0.930], loss: 1.543484, mean_absolute_error: 22.894870, mean_q: 46.000013\n",
      " 13110/50000: episode: 308, duration: 0.228s, episode steps: 132, steps per second: 580, episode reward: 132.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.384 [-2.232, 1.346], loss: 3.796171, mean_absolute_error: 23.751488, mean_q: 47.490924\n",
      " 13252/50000: episode: 309, duration: 0.243s, episode steps: 142, steps per second: 583, episode reward: 142.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.472 [0.000, 1.000], mean observation: -0.381 [-2.412, 0.805], loss: 1.125790, mean_absolute_error: 24.164822, mean_q: 48.530810\n",
      " 13376/50000: episode: 310, duration: 0.200s, episode steps: 124, steps per second: 620, episode reward: 124.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.452 [0.000, 1.000], mean observation: -0.454 [-2.424, 0.885], loss: 1.854652, mean_absolute_error: 22.756406, mean_q: 45.679570\n",
      " 13496/50000: episode: 311, duration: 0.205s, episode steps: 120, steps per second: 586, episode reward: 120.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.458 [0.000, 1.000], mean observation: -0.437 [-2.407, 0.762], loss: 2.254877, mean_absolute_error: 23.157605, mean_q: 46.476948\n",
      " 13662/50000: episode: 312, duration: 0.275s, episode steps: 166, steps per second: 603, episode reward: 166.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: -0.428 [-2.401, 0.840], loss: 2.986516, mean_absolute_error: 24.609904, mean_q: 49.189801\n",
      " 13765/50000: episode: 313, duration: 0.171s, episode steps: 103, steps per second: 602, episode reward: 103.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.456 [0.000, 1.000], mean observation: -0.493 [-2.428, 0.904], loss: 2.765953, mean_absolute_error: 22.330530, mean_q: 44.735591\n",
      " 13905/50000: episode: 314, duration: 0.234s, episode steps: 140, steps per second: 599, episode reward: 140.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.479 [0.000, 1.000], mean observation: -0.394 [-2.409, 0.979], loss: 2.360102, mean_absolute_error: 24.613083, mean_q: 49.337249\n",
      " 13929/50000: episode: 315, duration: 0.039s, episode steps: 24, steps per second: 621, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.062 [-1.145, 0.808], loss: 83.258314, mean_absolute_error: 34.935503, mean_q: 67.729695\n",
      " 14129/50000: episode: 316, duration: 0.332s, episode steps: 200, steps per second: 603, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.069 [-0.754, 0.658], loss: 7.881658, mean_absolute_error: 30.194765, mean_q: 60.343431\n",
      " 14153/50000: episode: 317, duration: 0.039s, episode steps: 24, steps per second: 613, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.029 [-0.818, 1.247], loss: 66.612322, mean_absolute_error: 31.017955, mean_q: 58.632368\n",
      " 14337/50000: episode: 318, duration: 0.311s, episode steps: 184, steps per second: 592, episode reward: 184.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.228 [-1.627, 1.037], loss: 4.144082, mean_absolute_error: 23.681761, mean_q: 47.386808\n",
      " 14443/50000: episode: 319, duration: 0.169s, episode steps: 106, steps per second: 625, episode reward: 106.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.453 [0.000, 1.000], mean observation: -0.476 [-2.737, 1.104], loss: 1.013454, mean_absolute_error: 18.348762, mean_q: 36.926104\n",
      " 14595/50000: episode: 320, duration: 0.255s, episode steps: 152, steps per second: 595, episode reward: 152.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.487 [0.000, 1.000], mean observation: -0.307 [-1.742, 1.227], loss: 5.080300, mean_absolute_error: 23.153301, mean_q: 46.324551\n",
      " 14729/50000: episode: 321, duration: 0.226s, episode steps: 134, steps per second: 593, episode reward: 134.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.427 [-2.409, 0.737], loss: 0.891152, mean_absolute_error: 21.357137, mean_q: 42.994400\n",
      " 14900/50000: episode: 322, duration: 0.289s, episode steps: 171, steps per second: 592, episode reward: 171.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.491 [0.000, 1.000], mean observation: -0.368 [-1.703, 0.837], loss: 3.940744, mean_absolute_error: 23.480819, mean_q: 47.013271\n",
      " 15058/50000: episode: 323, duration: 0.268s, episode steps: 158, steps per second: 589, episode reward: 158.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.487 [0.000, 1.000], mean observation: -0.423 [-2.405, 0.727], loss: 3.040552, mean_absolute_error: 22.824207, mean_q: 45.787492\n",
      " 15258/50000: episode: 324, duration: 0.332s, episode steps: 200, steps per second: 603, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.397 [-2.374, 1.165], loss: 4.730837, mean_absolute_error: 24.970417, mean_q: 49.909959\n",
      " 15389/50000: episode: 325, duration: 0.214s, episode steps: 131, steps per second: 613, episode reward: 131.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.443 [0.000, 1.000], mean observation: -0.353 [-3.178, 1.185], loss: 2.744240, mean_absolute_error: 29.184035, mean_q: 58.237769\n",
      " 15503/50000: episode: 326, duration: 0.193s, episode steps: 114, steps per second: 589, episode reward: 114.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.439 [0.000, 1.000], mean observation: -0.487 [-2.717, 0.817], loss: 1.193560, mean_absolute_error: 24.030927, mean_q: 48.294031\n",
      " 15608/50000: episode: 327, duration: 0.183s, episode steps: 105, steps per second: 574, episode reward: 105.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.438 [0.000, 1.000], mean observation: -0.509 [-2.543, 0.806], loss: 0.553331, mean_absolute_error: 22.181410, mean_q: 44.568924\n",
      " 15620/50000: episode: 328, duration: 0.020s, episode steps: 12, steps per second: 594, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.097 [-1.326, 0.783], loss: 173.509195, mean_absolute_error: 35.764608, mean_q: 66.599405\n",
      " 15636/50000: episode: 329, duration: 0.027s, episode steps: 16, steps per second: 598, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.625 [0.000, 1.000], mean observation: -0.090 [-1.505, 0.804], loss: 72.792039, mean_absolute_error: 30.944730, mean_q: 58.523833\n",
      " 15650/50000: episode: 330, duration: 0.024s, episode steps: 14, steps per second: 593, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.571 [0.000, 1.000], mean observation: -0.114 [-1.737, 1.124], loss: 70.565091, mean_absolute_error: 24.257001, mean_q: 45.568409\n",
      " 15709/50000: episode: 331, duration: 0.095s, episode steps: 59, steps per second: 624, episode reward: 59.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.508 [0.000, 1.000], mean observation: -0.015 [-0.853, 1.157], loss: 21.778314, mean_absolute_error: 23.813233, mean_q: 46.278277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15808/50000: episode: 332, duration: 0.172s, episode steps: 99, steps per second: 576, episode reward: 99.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.535 [0.000, 1.000], mean observation: 0.319 [-0.860, 1.468], loss: 28.028540, mean_absolute_error: 28.534396, mean_q: 56.271570\n",
      " 15823/50000: episode: 333, duration: 0.025s, episode steps: 15, steps per second: 590, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.267 [0.000, 1.000], mean observation: 0.096 [-1.385, 2.354], loss: 55.414574, mean_absolute_error: 24.597846, mean_q: 46.196704\n",
      " 15836/50000: episode: 334, duration: 0.021s, episode steps: 13, steps per second: 606, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.231 [0.000, 1.000], mean observation: 0.094 [-1.404, 2.206], loss: 49.662984, mean_absolute_error: 21.919701, mean_q: 40.757824\n",
      " 15854/50000: episode: 335, duration: 0.029s, episode steps: 18, steps per second: 614, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.444 [0.000, 1.000], mean observation: 0.082 [-0.773, 1.272], loss: 37.956813, mean_absolute_error: 21.322363, mean_q: 39.747129\n",
      " 15977/50000: episode: 336, duration: 0.207s, episode steps: 123, steps per second: 596, episode reward: 123.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.553 [0.000, 1.000], mean observation: 0.472 [-0.624, 2.412], loss: 21.519288, mean_absolute_error: 26.583608, mean_q: 52.520569\n",
      " 16169/50000: episode: 337, duration: 0.319s, episode steps: 192, steps per second: 602, episode reward: 192.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.479 [0.000, 1.000], mean observation: -0.432 [-2.418, 1.010], loss: 1.804910, mean_absolute_error: 13.570050, mean_q: 26.729662\n",
      " 16369/50000: episode: 338, duration: 0.337s, episode steps: 200, steps per second: 593, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.291 [-1.030, 1.767], loss: 9.807511, mean_absolute_error: 25.208097, mean_q: 50.286763\n",
      " 16466/50000: episode: 339, duration: 0.159s, episode steps: 97, steps per second: 609, episode reward: 97.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.423 [0.000, 1.000], mean observation: -0.505 [-2.957, 1.092], loss: 1.486978, mean_absolute_error: 15.499989, mean_q: 31.046297\n",
      " 16612/50000: episode: 340, duration: 0.245s, episode steps: 146, steps per second: 596, episode reward: 146.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.473 [0.000, 1.000], mean observation: -0.420 [-2.426, 0.971], loss: 1.873106, mean_absolute_error: 17.817030, mean_q: 35.797458\n",
      " 16812/50000: episode: 341, duration: 0.338s, episode steps: 200, steps per second: 592, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.333 [-2.060, 0.877], loss: 2.959157, mean_absolute_error: 21.182521, mean_q: 42.401878\n",
      " 17012/50000: episode: 342, duration: 0.332s, episode steps: 200, steps per second: 602, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.233 [-1.814, 0.748], loss: 3.515986, mean_absolute_error: 25.093163, mean_q: 50.300503\n",
      " 17202/50000: episode: 343, duration: 0.317s, episode steps: 190, steps per second: 599, episode reward: 190.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.484 [0.000, 1.000], mean observation: -0.322 [-2.413, 0.927], loss: 2.790814, mean_absolute_error: 24.942321, mean_q: 50.044953\n",
      " 17356/50000: episode: 344, duration: 0.260s, episode steps: 154, steps per second: 592, episode reward: 154.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: -0.380 [-2.404, 0.996], loss: 2.495161, mean_absolute_error: 25.155409, mean_q: 50.567034\n",
      " 17479/50000: episode: 345, duration: 0.199s, episode steps: 123, steps per second: 618, episode reward: 123.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.447 [0.000, 1.000], mean observation: -0.446 [-2.576, 0.931], loss: 1.832666, mean_absolute_error: 24.680123, mean_q: 49.605767\n",
      " 17496/50000: episode: 346, duration: 0.035s, episode steps: 17, steps per second: 481, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.081 [-1.102, 0.635], loss: 112.104913, mean_absolute_error: 33.786156, mean_q: 64.247497\n",
      " 17516/50000: episode: 347, duration: 0.033s, episode steps: 20, steps per second: 604, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.066 [-1.157, 0.798], loss: 66.504113, mean_absolute_error: 30.124000, mean_q: 57.641106\n",
      " 17716/50000: episode: 348, duration: 0.330s, episode steps: 200, steps per second: 605, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.203 [-1.035, 0.822], loss: 5.137355, mean_absolute_error: 23.814321, mean_q: 47.707007\n",
      " 17916/50000: episode: 349, duration: 0.339s, episode steps: 200, steps per second: 590, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.382 [-1.939, 0.697], loss: 3.376960, mean_absolute_error: 21.609103, mean_q: 43.366403\n",
      " 18115/50000: episode: 350, duration: 0.330s, episode steps: 199, steps per second: 604, episode reward: 199.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.487 [0.000, 1.000], mean observation: -0.389 [-2.415, 0.811], loss: 3.267753, mean_absolute_error: 23.986057, mean_q: 48.128276\n",
      " 18288/50000: episode: 351, duration: 0.296s, episode steps: 173, steps per second: 585, episode reward: 173.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.375 [-2.421, 0.649], loss: 2.511340, mean_absolute_error: 26.483932, mean_q: 53.197492\n",
      " 18422/50000: episode: 352, duration: 0.231s, episode steps: 134, steps per second: 579, episode reward: 134.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.463 [0.000, 1.000], mean observation: -0.461 [-2.422, 0.679], loss: 2.682234, mean_absolute_error: 24.848352, mean_q: 49.802219\n",
      " 18560/50000: episode: 353, duration: 0.240s, episode steps: 138, steps per second: 575, episode reward: 138.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.424 [-2.406, 0.766], loss: 2.108876, mean_absolute_error: 24.936481, mean_q: 50.131256\n",
      " 18700/50000: episode: 354, duration: 0.238s, episode steps: 140, steps per second: 588, episode reward: 140.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.464 [0.000, 1.000], mean observation: -0.428 [-2.422, 0.957], loss: 1.524955, mean_absolute_error: 24.943762, mean_q: 50.050327\n",
      " 18819/50000: episode: 355, duration: 0.193s, episode steps: 119, steps per second: 618, episode reward: 119.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.496 [-2.417, 0.802], loss: 1.123030, mean_absolute_error: 22.527957, mean_q: 45.274713\n",
      " 18925/50000: episode: 356, duration: 0.185s, episode steps: 106, steps per second: 573, episode reward: 106.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.531 [-2.587, 1.275], loss: 1.128653, mean_absolute_error: 21.031274, mean_q: 42.231950\n",
      " 19054/50000: episode: 357, duration: 0.209s, episode steps: 129, steps per second: 618, episode reward: 129.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.457 [0.000, 1.000], mean observation: -0.482 [-2.421, 0.768], loss: 0.482190, mean_absolute_error: 21.783875, mean_q: 43.863978\n",
      " 19176/50000: episode: 358, duration: 0.208s, episode steps: 122, steps per second: 586, episode reward: 122.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.515 [-2.395, 0.641], loss: 0.781517, mean_absolute_error: 20.902623, mean_q: 41.918399\n",
      " 19191/50000: episode: 359, duration: 0.035s, episode steps: 15, steps per second: 434, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.082 [-1.220, 0.809], loss: 130.498886, mean_absolute_error: 34.091541, mean_q: 64.308064\n",
      " 19391/50000: episode: 360, duration: 0.333s, episode steps: 200, steps per second: 600, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: 0.007 [-1.047, 1.001], loss: 10.422725, mean_absolute_error: 31.429603, mean_q: 62.687060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19516/50000: episode: 361, duration: 0.205s, episode steps: 125, steps per second: 611, episode reward: 125.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.472 [0.000, 1.000], mean observation: -0.486 [-2.413, 0.848], loss: 0.653389, mean_absolute_error: 17.910489, mean_q: 35.796764\n",
      " 19716/50000: episode: 362, duration: 0.346s, episode steps: 200, steps per second: 579, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.180 [-0.971, 0.889], loss: 6.366505, mean_absolute_error: 28.295175, mean_q: 56.552166\n",
      " 19916/50000: episode: 363, duration: 0.332s, episode steps: 200, steps per second: 602, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: -0.076 [-1.151, 1.294], loss: 15.220215, mean_absolute_error: 31.917316, mean_q: 63.441918\n",
      " 19942/50000: episode: 364, duration: 0.043s, episode steps: 26, steps per second: 600, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.088 [-0.555, 1.064], loss: 95.693565, mean_absolute_error: 35.834785, mean_q: 67.961365\n",
      " 20119/50000: episode: 365, duration: 0.294s, episode steps: 177, steps per second: 603, episode reward: 177.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: 0.268 [-0.991, 1.907], loss: 24.524502, mean_absolute_error: 34.681205, mean_q: 68.932394\n",
      " 20142/50000: episode: 366, duration: 0.038s, episode steps: 23, steps per second: 601, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.522 [0.000, 1.000], mean observation: -0.084 [-1.306, 0.616], loss: 42.231637, mean_absolute_error: 28.869325, mean_q: 55.552213\n",
      " 20342/50000: episode: 367, duration: 0.334s, episode steps: 200, steps per second: 600, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: 0.072 [-0.896, 1.891], loss: 13.872124, mean_absolute_error: 28.747138, mean_q: 56.830281\n",
      " 20436/50000: episode: 368, duration: 0.150s, episode steps: 94, steps per second: 625, episode reward: 94.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.543 [0.000, 1.000], mean observation: 0.128 [-0.483, 1.467], loss: 23.636371, mean_absolute_error: 29.602429, mean_q: 58.339762\n",
      " 20451/50000: episode: 369, duration: 0.025s, episode steps: 15, steps per second: 602, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: 0.099 [-0.752, 1.359], loss: 101.423889, mean_absolute_error: 29.702376, mean_q: 55.896225\n",
      " 20460/50000: episode: 370, duration: 0.015s, episode steps: 9, steps per second: 591, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.141 [-1.796, 2.826], loss: 129.243922, mean_absolute_error: 28.200525, mean_q: 51.810083\n",
      " 20470/50000: episode: 371, duration: 0.023s, episode steps: 10, steps per second: 427, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.200 [0.000, 1.000], mean observation: 0.109 [-1.166, 1.939], loss: 105.890598, mean_absolute_error: 25.966815, mean_q: 47.709524\n",
      " 20483/50000: episode: 372, duration: 0.023s, episode steps: 13, steps per second: 560, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.385 [0.000, 1.000], mean observation: 0.096 [-0.990, 1.518], loss: 68.405342, mean_absolute_error: 24.026109, mean_q: 44.266029\n",
      " 20494/50000: episode: 373, duration: 0.018s, episode steps: 11, steps per second: 597, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.364 [0.000, 1.000], mean observation: 0.102 [-0.769, 1.405], loss: 71.675770, mean_absolute_error: 23.540869, mean_q: 42.799716\n",
      " 20510/50000: episode: 374, duration: 0.027s, episode steps: 16, steps per second: 593, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.438 [0.000, 1.000], mean observation: 0.091 [-0.961, 1.446], loss: 49.156762, mean_absolute_error: 22.174551, mean_q: 41.364142\n",
      " 20625/50000: episode: 375, duration: 0.198s, episode steps: 115, steps per second: 582, episode reward: 115.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.557 [0.000, 1.000], mean observation: 0.515 [-0.752, 2.597], loss: 16.322243, mean_absolute_error: 25.444907, mean_q: 49.928305\n",
      " 20766/50000: episode: 376, duration: 0.236s, episode steps: 141, steps per second: 597, episode reward: 141.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.539 [0.000, 1.000], mean observation: 0.385 [-0.837, 2.126], loss: 11.073770, mean_absolute_error: 23.850918, mean_q: 47.326272\n",
      " 20909/50000: episode: 377, duration: 0.244s, episode steps: 143, steps per second: 586, episode reward: 143.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: 0.347 [-0.573, 2.154], loss: 10.454746, mean_absolute_error: 23.991672, mean_q: 47.654656\n",
      " 21069/50000: episode: 378, duration: 0.268s, episode steps: 160, steps per second: 597, episode reward: 160.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: -0.391 [-2.402, 0.679], loss: 1.327513, mean_absolute_error: 18.147303, mean_q: 36.280428\n",
      " 21217/50000: episode: 379, duration: 0.248s, episode steps: 148, steps per second: 598, episode reward: 148.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.473 [0.000, 1.000], mean observation: -0.322 [-1.690, 0.730], loss: 2.501248, mean_absolute_error: 20.811278, mean_q: 41.677616\n",
      " 21417/50000: episode: 380, duration: 0.330s, episode steps: 200, steps per second: 606, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.284 [-0.813, 1.642], loss: 8.899238, mean_absolute_error: 26.367045, mean_q: 52.486499\n",
      " 21437/50000: episode: 381, duration: 0.034s, episode steps: 20, steps per second: 596, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.099 [-1.109, 0.732], loss: 50.600330, mean_absolute_error: 25.952820, mean_q: 49.077372\n",
      " 21564/50000: episode: 382, duration: 0.216s, episode steps: 127, steps per second: 589, episode reward: 127.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.498 [-2.418, 0.748], loss: 3.295956, mean_absolute_error: 19.073554, mean_q: 37.735055\n",
      " 21764/50000: episode: 383, duration: 0.339s, episode steps: 200, steps per second: 590, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: 0.017 [-0.811, 0.834], loss: 7.597820, mean_absolute_error: 26.398829, mean_q: 52.788562\n",
      " 21886/50000: episode: 384, duration: 0.199s, episode steps: 122, steps per second: 614, episode reward: 122.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.541 [0.000, 1.000], mean observation: 0.396 [-0.874, 1.913], loss: 15.896226, mean_absolute_error: 28.791511, mean_q: 57.018609\n",
      " 22030/50000: episode: 385, duration: 0.241s, episode steps: 144, steps per second: 597, episode reward: 144.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.479 [0.000, 1.000], mean observation: -0.454 [-2.406, 0.785], loss: 4.110926, mean_absolute_error: 22.138710, mean_q: 44.000233\n",
      " 22230/50000: episode: 386, duration: 0.335s, episode steps: 200, steps per second: 597, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.307 [-1.982, 0.696], loss: 4.391852, mean_absolute_error: 25.019575, mean_q: 50.103060\n",
      " 22409/50000: episode: 387, duration: 0.299s, episode steps: 179, steps per second: 598, episode reward: 179.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.531 [0.000, 1.000], mean observation: 0.414 [-0.887, 2.422], loss: 13.271883, mean_absolute_error: 30.545729, mean_q: 60.676604\n",
      " 22426/50000: episode: 388, duration: 0.029s, episode steps: 17, steps per second: 596, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.529 [0.000, 1.000], mean observation: -0.086 [-1.158, 0.731], loss: 66.484556, mean_absolute_error: 28.994498, mean_q: 55.242159\n",
      " 22441/50000: episode: 389, duration: 0.024s, episode steps: 15, steps per second: 614, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.115 [-0.938, 0.563], loss: 63.247079, mean_absolute_error: 25.774906, mean_q: 47.916807\n",
      " 22462/50000: episode: 390, duration: 0.034s, episode steps: 21, steps per second: 624, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: -0.141 [-0.964, 0.552], loss: 47.531094, mean_absolute_error: 23.357108, mean_q: 43.144924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22603/50000: episode: 391, duration: 0.256s, episode steps: 141, steps per second: 552, episode reward: 141.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.525 [0.000, 1.000], mean observation: 0.133 [-0.781, 1.484], loss: 10.765982, mean_absolute_error: 25.052280, mean_q: 49.565352\n",
      " 22615/50000: episode: 392, duration: 0.022s, episode steps: 12, steps per second: 539, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.110 [-0.953, 1.715], loss: 86.051883, mean_absolute_error: 26.451688, mean_q: 48.810165\n",
      " 22628/50000: episode: 393, duration: 0.023s, episode steps: 13, steps per second: 555, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: 0.115 [-0.955, 1.526], loss: 82.036051, mean_absolute_error: 24.929697, mean_q: 46.032226\n",
      " 22720/50000: episode: 394, duration: 0.176s, episode steps: 92, steps per second: 524, episode reward: 92.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.554 [0.000, 1.000], mean observation: 0.464 [-0.787, 2.535], loss: 9.812802, mean_absolute_error: 22.835191, mean_q: 45.410760\n",
      " 22871/50000: episode: 395, duration: 0.288s, episode steps: 151, steps per second: 524, episode reward: 151.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.536 [0.000, 1.000], mean observation: 0.303 [-0.874, 1.988], loss: 7.000692, mean_absolute_error: 22.784113, mean_q: 45.455572\n",
      " 22993/50000: episode: 396, duration: 0.241s, episode steps: 122, steps per second: 505, episode reward: 122.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.533 [0.000, 1.000], mean observation: 0.247 [-0.766, 1.646], loss: 8.640621, mean_absolute_error: 23.834150, mean_q: 47.402790\n",
      " 23193/50000: episode: 397, duration: 0.341s, episode steps: 200, steps per second: 586, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.034 [-0.755, 0.941], loss: 7.312918, mean_absolute_error: 25.346764, mean_q: 50.626227\n",
      " 23329/50000: episode: 398, duration: 0.242s, episode steps: 136, steps per second: 563, episode reward: 136.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.544 [0.000, 1.000], mean observation: 0.391 [-0.848, 2.198], loss: 8.147686, mean_absolute_error: 25.298172, mean_q: 50.330251\n",
      " 23436/50000: episode: 399, duration: 0.175s, episode steps: 107, steps per second: 612, episode reward: 107.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.551 [0.000, 1.000], mean observation: 0.423 [-0.578, 2.167], loss: 8.937563, mean_absolute_error: 24.945559, mean_q: 49.604346\n",
      " 23600/50000: episode: 400, duration: 0.275s, episode steps: 164, steps per second: 596, episode reward: 164.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.530 [0.000, 1.000], mean observation: 0.265 [-1.026, 1.850], loss: 6.356595, mean_absolute_error: 25.714721, mean_q: 51.327698\n",
      " 23800/50000: episode: 401, duration: 0.338s, episode steps: 200, steps per second: 591, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.403 [-1.970, 1.074], loss: 7.716153, mean_absolute_error: 26.494733, mean_q: 52.979729\n",
      " 24000/50000: episode: 402, duration: 0.338s, episode steps: 200, steps per second: 591, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: -0.253 [-1.495, 0.733], loss: 8.497444, mean_absolute_error: 29.813304, mean_q: 59.571634\n",
      " 24038/50000: episode: 403, duration: 0.062s, episode steps: 38, steps per second: 615, episode reward: 38.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.553 [0.000, 1.000], mean observation: 0.119 [-0.384, 0.747], loss: 40.081399, mean_absolute_error: 30.123827, mean_q: 58.137002\n",
      " 24238/50000: episode: 404, duration: 0.332s, episode steps: 200, steps per second: 603, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.264 [-1.620, 0.981], loss: 7.787181, mean_absolute_error: 29.217856, mean_q: 58.329277\n",
      " 24409/50000: episode: 405, duration: 0.292s, episode steps: 171, steps per second: 586, episode reward: 171.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.394 [-2.414, 0.834], loss: 7.513777, mean_absolute_error: 29.742922, mean_q: 59.468548\n",
      " 24609/50000: episode: 406, duration: 0.334s, episode steps: 200, steps per second: 598, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: -0.382 [-2.030, 1.152], loss: 6.896684, mean_absolute_error: 28.131858, mean_q: 56.186470\n",
      " 24642/50000: episode: 407, duration: 0.054s, episode steps: 33, steps per second: 608, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: 0.040 [-0.646, 1.501], loss: 42.378951, mean_absolute_error: 31.596748, mean_q: 61.123141\n",
      " 24679/50000: episode: 408, duration: 0.063s, episode steps: 37, steps per second: 586, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.514 [0.000, 1.000], mean observation: 0.072 [-0.602, 0.983], loss: 31.501877, mean_absolute_error: 29.003708, mean_q: 55.861013\n",
      " 24840/50000: episode: 409, duration: 0.269s, episode steps: 161, steps per second: 599, episode reward: 161.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.484 [0.000, 1.000], mean observation: -0.401 [-2.410, 0.665], loss: 5.868438, mean_absolute_error: 28.108891, mean_q: 56.219995\n",
      " 24947/50000: episode: 410, duration: 0.179s, episode steps: 107, steps per second: 597, episode reward: 107.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.439 [0.000, 1.000], mean observation: -0.505 [-2.593, 0.724], loss: 11.081848, mean_absolute_error: 29.399298, mean_q: 58.715962\n",
      " 24967/50000: episode: 411, duration: 0.040s, episode steps: 20, steps per second: 495, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.105 [-1.242, 0.826], loss: 69.884630, mean_absolute_error: 29.818349, mean_q: 56.679230\n",
      " 25167/50000: episode: 412, duration: 0.334s, episode steps: 200, steps per second: 598, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.377 [-2.180, 1.122], loss: 2.645899, mean_absolute_error: 23.366857, mean_q: 46.796568\n",
      " 25311/50000: episode: 413, duration: 0.248s, episode steps: 144, steps per second: 580, episode reward: 144.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.486 [0.000, 1.000], mean observation: -0.423 [-2.400, 0.839], loss: 3.452341, mean_absolute_error: 25.923419, mean_q: 51.938650\n",
      " 25482/50000: episode: 414, duration: 0.286s, episode steps: 171, steps per second: 597, episode reward: 171.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.352 [-2.409, 0.734], loss: 3.220253, mean_absolute_error: 27.350321, mean_q: 54.788172\n",
      " 25682/50000: episode: 415, duration: 0.334s, episode steps: 200, steps per second: 599, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.244 [-0.951, 1.484], loss: 12.955968, mean_absolute_error: 31.005281, mean_q: 61.642224\n",
      " 25692/50000: episode: 416, duration: 0.017s, episode steps: 10, steps per second: 586, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.700 [0.000, 1.000], mean observation: -0.119 [-1.686, 1.005], loss: 152.221513, mean_absolute_error: 33.661690, mean_q: 62.203311\n",
      " 25710/50000: episode: 417, duration: 0.030s, episode steps: 18, steps per second: 601, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.444 [0.000, 1.000], mean observation: -0.068 [-1.258, 0.803], loss: 91.269237, mean_absolute_error: 27.946597, mean_q: 53.022453\n",
      " 25908/50000: episode: 418, duration: 0.334s, episode steps: 198, steps per second: 592, episode reward: 198.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.133 [-1.073, 1.287], loss: 6.805379, mean_absolute_error: 26.212188, mean_q: 52.367457\n",
      " 25928/50000: episode: 419, duration: 0.033s, episode steps: 20, steps per second: 600, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.550 [0.000, 1.000], mean observation: 0.107 [-0.551, 1.177], loss: 60.333145, mean_absolute_error: 27.552288, mean_q: 52.069936\n",
      " 25945/50000: episode: 420, duration: 0.028s, episode steps: 17, steps per second: 614, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: 0.083 [-0.626, 1.094], loss: 57.691357, mean_absolute_error: 25.795322, mean_q: 47.869930\n",
      " 25959/50000: episode: 421, duration: 0.023s, episode steps: 14, steps per second: 616, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: 0.124 [-0.762, 1.477], loss: 49.625579, mean_absolute_error: 24.574483, mean_q: 45.115950\n",
      " 25975/50000: episode: 422, duration: 0.026s, episode steps: 16, steps per second: 609, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.438 [0.000, 1.000], mean observation: 0.120 [-0.556, 1.188], loss: 44.158213, mean_absolute_error: 23.448878, mean_q: 42.939197\n",
      " 25990/50000: episode: 423, duration: 0.027s, episode steps: 15, steps per second: 559, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: 0.063 [-0.981, 1.487], loss: 38.462947, mean_absolute_error: 20.905731, mean_q: 38.244491\n",
      " 26005/50000: episode: 424, duration: 0.026s, episode steps: 15, steps per second: 585, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: 0.090 [-0.793, 1.370], loss: 32.457786, mean_absolute_error: 20.685973, mean_q: 37.554024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26111/50000: episode: 425, duration: 0.182s, episode steps: 106, steps per second: 582, episode reward: 106.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.557 [0.000, 1.000], mean observation: 0.520 [-0.977, 2.563], loss: 6.239708, mean_absolute_error: 18.605388, mean_q: 36.048623\n",
      " 26231/50000: episode: 426, duration: 0.196s, episode steps: 120, steps per second: 611, episode reward: 120.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.506 [-2.424, 0.717], loss: 1.651804, mean_absolute_error: 17.295588, mean_q: 34.716725\n",
      " 26381/50000: episode: 427, duration: 0.251s, episode steps: 150, steps per second: 596, episode reward: 150.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.473 [0.000, 1.000], mean observation: -0.435 [-2.421, 0.651], loss: 1.909631, mean_absolute_error: 19.005471, mean_q: 38.099575\n",
      " 26546/50000: episode: 428, duration: 0.275s, episode steps: 165, steps per second: 600, episode reward: 165.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.473 [0.000, 1.000], mean observation: -0.322 [-2.404, 0.887], loss: 2.606512, mean_absolute_error: 23.002230, mean_q: 46.074077\n",
      " 26702/50000: episode: 429, duration: 0.259s, episode steps: 156, steps per second: 602, episode reward: 156.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: -0.396 [-2.419, 0.715], loss: 1.945266, mean_absolute_error: 23.095815, mean_q: 46.372817\n",
      " 26819/50000: episode: 430, duration: 0.192s, episode steps: 117, steps per second: 608, episode reward: 117.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.493 [-2.405, 0.937], loss: 2.249869, mean_absolute_error: 23.324386, mean_q: 46.706374\n",
      " 26939/50000: episode: 431, duration: 0.206s, episode steps: 120, steps per second: 583, episode reward: 120.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.458 [-2.251, 0.781], loss: 1.980732, mean_absolute_error: 24.270529, mean_q: 48.636311\n",
      " 27076/50000: episode: 432, duration: 0.229s, episode steps: 137, steps per second: 598, episode reward: 137.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: -0.448 [-2.396, 0.802], loss: 0.942669, mean_absolute_error: 23.492794, mean_q: 46.987601\n",
      " 27220/50000: episode: 433, duration: 0.240s, episode steps: 144, steps per second: 601, episode reward: 144.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.465 [0.000, 1.000], mean observation: -0.411 [-2.401, 0.700], loss: 1.269619, mean_absolute_error: 24.449769, mean_q: 48.900332\n",
      " 27341/50000: episode: 434, duration: 0.201s, episode steps: 121, steps per second: 603, episode reward: 121.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.424 [-2.070, 0.788], loss: 1.400266, mean_absolute_error: 25.070081, mean_q: 50.143409\n",
      " 27474/50000: episode: 435, duration: 0.236s, episode steps: 133, steps per second: 563, episode reward: 133.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.489 [0.000, 1.000], mean observation: -0.421 [-2.120, 0.972], loss: 0.603268, mean_absolute_error: 23.521931, mean_q: 47.218522\n",
      " 27598/50000: episode: 436, duration: 0.200s, episode steps: 124, steps per second: 620, episode reward: 124.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.492 [0.000, 1.000], mean observation: -0.393 [-1.866, 1.141], loss: 1.321565, mean_absolute_error: 24.295911, mean_q: 48.533625\n",
      " 27798/50000: episode: 437, duration: 0.335s, episode steps: 200, steps per second: 597, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.372 [-2.099, 1.101], loss: 1.638845, mean_absolute_error: 21.967412, mean_q: 43.785327\n",
      " 27950/50000: episode: 438, duration: 0.259s, episode steps: 152, steps per second: 587, episode reward: 152.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.368 [-2.411, 1.330], loss: 1.208495, mean_absolute_error: 27.559314, mean_q: 55.122467\n",
      " 28070/50000: episode: 439, duration: 0.194s, episode steps: 120, steps per second: 620, episode reward: 120.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.483 [0.000, 1.000], mean observation: -0.485 [-2.252, 0.794], loss: 0.415888, mean_absolute_error: 24.523212, mean_q: 49.182450\n",
      " 28174/50000: episode: 440, duration: 0.178s, episode steps: 104, steps per second: 584, episode reward: 104.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.481 [0.000, 1.000], mean observation: -0.482 [-2.063, 0.893], loss: 0.777399, mean_absolute_error: 23.589563, mean_q: 47.233621\n",
      " 28279/50000: episode: 441, duration: 0.173s, episode steps: 105, steps per second: 606, episode reward: 105.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: -0.451 [-2.194, 1.064], loss: 0.551577, mean_absolute_error: 23.458151, mean_q: 47.024004\n",
      " 28363/50000: episode: 442, duration: 0.146s, episode steps: 84, steps per second: 575, episode reward: 84.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: -0.330 [-2.066, 0.678], loss: 2.566966, mean_absolute_error: 27.145208, mean_q: 54.221759\n",
      " 28427/50000: episode: 443, duration: 0.104s, episode steps: 64, steps per second: 615, episode reward: 64.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.422 [0.000, 1.000], mean observation: -0.271 [-2.084, 1.736], loss: 3.324880, mean_absolute_error: 23.234781, mean_q: 46.543513\n",
      " 28509/50000: episode: 444, duration: 0.143s, episode steps: 82, steps per second: 573, episode reward: 82.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.463 [0.000, 1.000], mean observation: -0.284 [-1.639, 0.747], loss: 1.189058, mean_absolute_error: 22.089996, mean_q: 44.166720\n",
      " 28524/50000: episode: 445, duration: 0.025s, episode steps: 15, steps per second: 602, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.082 [-1.554, 0.956], loss: 83.493685, mean_absolute_error: 30.205907, mean_q: 57.148182\n",
      " 28535/50000: episode: 446, duration: 0.019s, episode steps: 11, steps per second: 585, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.727 [0.000, 1.000], mean observation: -0.131 [-1.980, 1.213], loss: 38.288520, mean_absolute_error: 23.589602, mean_q: 44.005562\n",
      " 28599/50000: episode: 447, duration: 0.103s, episode steps: 64, steps per second: 622, episode reward: 64.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.438 [0.000, 1.000], mean observation: -0.148 [-1.709, 2.079], loss: 5.773321, mean_absolute_error: 18.198194, mean_q: 34.928061\n",
      " 28680/50000: episode: 448, duration: 0.144s, episode steps: 81, steps per second: 563, episode reward: 81.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.556 [0.000, 1.000], mean observation: 0.357 [-0.940, 1.990], loss: 18.969491, mean_absolute_error: 23.788110, mean_q: 46.605779\n",
      " 28880/50000: episode: 449, duration: 0.332s, episode steps: 200, steps per second: 602, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.017 [-1.088, 1.169], loss: 8.211814, mean_absolute_error: 22.482352, mean_q: 44.540555\n",
      " 28984/50000: episode: 450, duration: 0.169s, episode steps: 104, steps per second: 614, episode reward: 104.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.529 [0.000, 1.000], mean observation: 0.219 [-0.755, 1.152], loss: 13.074653, mean_absolute_error: 25.045143, mean_q: 49.753329\n",
      " 29184/50000: episode: 451, duration: 0.335s, episode steps: 200, steps per second: 597, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.040 [-0.731, 0.781], loss: 8.078097, mean_absolute_error: 24.820339, mean_q: 49.555529\n",
      " 29384/50000: episode: 452, duration: 0.330s, episode steps: 200, steps per second: 605, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.094 [-1.147, 0.679], loss: 5.032074, mean_absolute_error: 25.609144, mean_q: 51.304136\n",
      " 29584/50000: episode: 453, duration: 0.347s, episode steps: 200, steps per second: 577, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: -0.089 [-0.916, 0.972], loss: 10.223893, mean_absolute_error: 27.682005, mean_q: 55.142071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 29784/50000: episode: 454, duration: 0.336s, episode steps: 200, steps per second: 594, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: -0.019 [-1.182, 1.270], loss: 12.264725, mean_absolute_error: 29.885029, mean_q: 59.458164\n",
      " 29923/50000: episode: 455, duration: 0.234s, episode steps: 139, steps per second: 595, episode reward: 139.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.504 [0.000, 1.000], mean observation: -0.113 [-0.937, 1.242], loss: 7.379400, mean_absolute_error: 28.757403, mean_q: 57.264885\n",
      " 30123/50000: episode: 456, duration: 0.330s, episode steps: 200, steps per second: 606, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: -0.155 [-1.199, 0.874], loss: 5.972998, mean_absolute_error: 28.152809, mean_q: 56.417091\n",
      "done, took 52.714 seconds\n",
      "Testing for 5 episodes ...\n",
      "Episode 1: reward: 105.000, steps: 105\n",
      "Episode 2: reward: 157.000, steps: 157\n",
      "Episode 3: reward: 148.000, steps: 148\n",
      "Episode 4: reward: 195.000, steps: 195\n",
      "Episode 5: reward: 97.000, steps: 97\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4c77f90f98>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents import SARSAAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "\n",
    "\n",
    "ENV_NAME = 'CartPole-v0'\n",
    "\n",
    "# Get the environment and extract the number of actions.\n",
    "env = gym.make(ENV_NAME)\n",
    "np.random.seed(123)\n",
    "env.seed(123)\n",
    "nb_actions = env.action_space.n\n",
    "\n",
    "# Next, we build a very simple model.\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))\n",
    "print(model.summary())\n",
    "\n",
    "# SARSA does not require a memory.\n",
    "policy = BoltzmannQPolicy()\n",
    "sarsa = SARSAAgent(model=model, nb_actions=nb_actions, nb_steps_warmup=10, policy=policy)\n",
    "sarsa.compile(Adam(lr=1e-3), metrics=['mae'])\n",
    "\n",
    "# Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# Ctrl + C.\n",
    "sarsa.fit(env, nb_steps=50000, visualize=False, verbose=2)\n",
    "\n",
    "# After training is done, we save the final weights.\n",
    "sarsa.save_weights(r'./modelos_Q5/sarsa_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\n",
    "\n",
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "sarsa.test(env, nb_episodes=5, visualize=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
